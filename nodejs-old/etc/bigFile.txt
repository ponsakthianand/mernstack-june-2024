Node.js
About this documentation
Usage and example
Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Corepack
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib
Code repository and issue tracker
Node.js v22.4.1  Table of contents  Index  Other versions  Options
Table of contents
File system
Promise example
Callback example
Synchronous example
Promises API
Class: FileHandle
Event: 'close'
filehandle.appendFile(data[, options])
filehandle.chmod(mode)
filehandle.chown(uid, gid)
filehandle.close()
filehandle.createReadStream([options])
filehandle.createWriteStream([options])
filehandle.datasync()
filehandle.fd
filehandle.read(buffer, offset, length, position)
filehandle.read([options])
filehandle.read(buffer[, options])
filehandle.readableWebStream([options])
filehandle.readFile(options)
filehandle.readLines([options])
filehandle.readv(buffers[, position])
filehandle.stat([options])
filehandle.sync()
filehandle.truncate(len)
filehandle.utimes(atime, mtime)
filehandle.write(buffer, offset[, length[, position]])
filehandle.write(buffer[, options])
filehandle.write(string[, position[, encoding]])
filehandle.writeFile(data, options)
filehandle.writev(buffers[, position])
filehandle[Symbol.asyncDispose]()
fsPromises.access(path[, mode])
fsPromises.appendFile(path, data[, options])
fsPromises.chmod(path, mode)
fsPromises.chown(path, uid, gid)
fsPromises.copyFile(src, dest[, mode])
fsPromises.cp(src, dest[, options])
fsPromises.glob(pattern[, options])
fsPromises.lchmod(path, mode)
fsPromises.lchown(path, uid, gid)
fsPromises.lutimes(path, atime, mtime)
fsPromises.link(existingPath, newPath)
fsPromises.lstat(path[, options])
fsPromises.mkdir(path[, options])
fsPromises.mkdtemp(prefix[, options])
fsPromises.open(path, flags[, mode])
fsPromises.opendir(path[, options])
fsPromises.readdir(path[, options])
fsPromises.readFile(path[, options])
fsPromises.readlink(path[, options])
fsPromises.realpath(path[, options])
fsPromises.rename(oldPath, newPath)
fsPromises.rmdir(path[, options])
fsPromises.rm(path[, options])
fsPromises.stat(path[, options])
fsPromises.statfs(path[, options])
fsPromises.symlink(target, path[, type])
fsPromises.truncate(path[, len])
fsPromises.unlink(path)
fsPromises.utimes(path, atime, mtime)
fsPromises.watch(filename[, options])
fsPromises.writeFile(file, data[, options])
fsPromises.constants
Callback API
fs.access(path[, mode], callback)
fs.appendFile(path, data[, options], callback)
fs.chmod(path, mode, callback)
File modes
fs.chown(path, uid, gid, callback)
fs.close(fd[, callback])
fs.copyFile(src, dest[, mode], callback)
fs.cp(src, dest[, options], callback)
fs.createReadStream(path[, options])
fs.createWriteStream(path[, options])
fs.exists(path, callback)
fs.fchmod(fd, mode, callback)
fs.fchown(fd, uid, gid, callback)
fs.fdatasync(fd, callback)
fs.fstat(fd[, options], callback)
fs.fsync(fd, callback)
fs.ftruncate(fd[, len], callback)
fs.futimes(fd, atime, mtime, callback)
fs.glob(pattern[, options], callback)
fs.lchmod(path, mode, callback)
fs.lchown(path, uid, gid, callback)
fs.lutimes(path, atime, mtime, callback)
fs.link(existingPath, newPath, callback)
fs.lstat(path[, options], callback)
fs.mkdir(path[, options], callback)
fs.mkdtemp(prefix[, options], callback)
fs.open(path[, flags[, mode]], callback)
fs.openAsBlob(path[, options])
fs.opendir(path[, options], callback)
fs.read(fd, buffer, offset, length, position, callback)
fs.read(fd[, options], callback)
fs.read(fd, buffer[, options], callback)
fs.readdir(path[, options], callback)
fs.readFile(path[, options], callback)
File descriptors
Performance Considerations
fs.readlink(path[, options], callback)
fs.readv(fd, buffers[, position], callback)
fs.realpath(path[, options], callback)
fs.realpath.native(path[, options], callback)
fs.rename(oldPath, newPath, callback)
fs.rmdir(path[, options], callback)
fs.rm(path[, options], callback)
fs.stat(path[, options], callback)
fs.statfs(path[, options], callback)
fs.symlink(target, path[, type], callback)
fs.truncate(path[, len], callback)
fs.unlink(path, callback)
fs.unwatchFile(filename[, listener])
fs.utimes(path, atime, mtime, callback)
fs.watch(filename[, options][, listener])
Caveats
Availability
Inodes
Filename argument
fs.watchFile(filename[, options], listener)
fs.write(fd, buffer, offset[, length[, position]], callback)
fs.write(fd, buffer[, options], callback)
fs.write(fd, string[, position[, encoding]], callback)
fs.writeFile(file, data[, options], callback)
Using fs.writeFile() with file descriptors
fs.writev(fd, buffers[, position], callback)
Synchronous API
fs.accessSync(path[, mode])
fs.appendFileSync(path, data[, options])
fs.chmodSync(path, mode)
fs.chownSync(path, uid, gid)
fs.closeSync(fd)
fs.copyFileSync(src, dest[, mode])
fs.cpSync(src, dest[, options])
fs.existsSync(path)
fs.fchmodSync(fd, mode)
fs.fchownSync(fd, uid, gid)
fs.fdatasyncSync(fd)
fs.fstatSync(fd[, options])
fs.fsyncSync(fd)
fs.ftruncateSync(fd[, len])
fs.futimesSync(fd, atime, mtime)
fs.globSync(pattern[, options])
fs.lchmodSync(path, mode)
fs.lchownSync(path, uid, gid)
fs.lutimesSync(path, atime, mtime)
fs.linkSync(existingPath, newPath)
fs.lstatSync(path[, options])
fs.mkdirSync(path[, options])
fs.mkdtempSync(prefix[, options])
fs.opendirSync(path[, options])
fs.openSync(path[, flags[, mode]])
fs.readdirSync(path[, options])
fs.readFileSync(path[, options])
fs.readlinkSync(path[, options])
fs.readSync(fd, buffer, offset, length[, position])
fs.readSync(fd, buffer[, options])
fs.readvSync(fd, buffers[, position])
fs.realpathSync(path[, options])
fs.realpathSync.native(path[, options])
fs.renameSync(oldPath, newPath)
fs.rmdirSync(path[, options])
fs.rmSync(path[, options])
fs.statSync(path[, options])
fs.statfsSync(path[, options])
fs.symlinkSync(target, path[, type])
fs.truncateSync(path[, len])
fs.unlinkSync(path)
fs.utimesSync(path, atime, mtime)
fs.writeFileSync(file, data[, options])
fs.writeSync(fd, buffer, offset[, length[, position]])
fs.writeSync(fd, buffer[, options])
fs.writeSync(fd, string[, position[, encoding]])
fs.writevSync(fd, buffers[, position])
Common Objects
Class: fs.Dir
dir.close()
dir.close(callback)
dir.closeSync()
dir.path
dir.read()
dir.read(callback)
dir.readSync()
dir[Symbol.asyncIterator]()
Class: fs.Dirent
dirent.isBlockDevice()
dirent.isCharacterDevice()
dirent.isDirectory()
dirent.isFIFO()
dirent.isFile()
dirent.isSocket()
dirent.isSymbolicLink()
dirent.name
dirent.parentPath
dirent.path
Class: fs.FSWatcher
Event: 'change'
Event: 'close'
Event: 'error'
watcher.close()
watcher.ref()
watcher.unref()
Class: fs.StatWatcher
watcher.ref()
watcher.unref()
Class: fs.ReadStream
Event: 'close'
Event: 'open'
Event: 'ready'
readStream.bytesRead
readStream.path
readStream.pending
Class: fs.Stats
stats.isBlockDevice()
stats.isCharacterDevice()
stats.isDirectory()
stats.isFIFO()
stats.isFile()
stats.isSocket()
stats.isSymbolicLink()
stats.dev
stats.ino
stats.mode
stats.nlink
stats.uid
stats.gid
stats.rdev
stats.size
stats.blksize
stats.blocks
stats.atimeMs
stats.mtimeMs
stats.ctimeMs
stats.birthtimeMs
stats.atimeNs
stats.mtimeNs
stats.ctimeNs
stats.birthtimeNs
stats.atime
stats.mtime
stats.ctime
stats.birthtime
Stat time values
Class: fs.StatFs
statfs.bavail
statfs.bfree
statfs.blocks
statfs.bsize
statfs.ffree
statfs.files
statfs.type
Class: fs.WriteStream
Event: 'close'
Event: 'open'
Event: 'ready'
writeStream.bytesWritten
writeStream.close([callback])
writeStream.path
writeStream.pending
fs.constants
FS constants
File access constants
File copy constants
File open constants
File type constants
File mode constants
Notes
Ordering of callback and promise-based operations
File paths
String paths
File URL paths
Platform-specific considerations
Buffer paths
Per-drive working directories on Windows
File descriptors
Threadpool usage
File system flags
File system#
Stability: 2 - Stable
Source Code: lib/fs.js

The node:fs module enables interacting with the file system in a way modeled on standard POSIX functions.

To use the promise-based APIs:

const fs = require('node:fs/promises');COPY
To use the callback and sync APIs:

const fs = require('node:fs');COPY
All file system operations have synchronous, callback, and promise-based forms, and are accessible using both CommonJS syntax and ES6 Modules (ESM).

Promise example#
Promise-based operations return a promise that is fulfilled when the asynchronous operation is complete.

const { unlink } = require('node:fs/promises');

(async function(path) {
  try {
    await unlink(path);
    console.log(`successfully deleted ${path}`);
  } catch (error) {
    console.error('there was an error:', error.message);
  }
})('/tmp/hello');COPY
Callback example#
The callback form takes a completion callback function as its last argument and invokes the operation asynchronously. The arguments passed to the completion callback depend on the method, but the first argument is always reserved for an exception. If the operation is completed successfully, then the first argument is null or undefined.

const { unlink } = require('node:fs');

unlink('/tmp/hello', (err) => {
  if (err) throw err;
  console.log('successfully deleted /tmp/hello');
});COPY
The callback-based versions of the node:fs module APIs are preferable over the use of the promise APIs when maximal performance (both in terms of execution time and memory allocation) is required.

Synchronous example#
The synchronous APIs block the Node.js event loop and further JavaScript execution until the operation is complete. Exceptions are thrown immediately and can be handled using tryâ€¦catch, or can be allowed to bubble up.

const { unlinkSync } = require('node:fs');

try {
  unlinkSync('/tmp/hello');
  console.log('successfully deleted /tmp/hello');
} catch (err) {
  // handle the error
}COPY
Promises API#
History
The fs/promises API provides asynchronous file system methods that return promises.

The promise APIs use the underlying Node.js threadpool to perform file system operations off the event loop thread. These operations are not synchronized or threadsafe. Care must be taken when performing multiple concurrent modifications on the same file or data corruption may occur.

Class: FileHandle#
Added in: v10.0.0
A <FileHandle> object is an object wrapper for a numeric file descriptor.

Instances of the <FileHandle> object are created by the fsPromises.open() method.

All <FileHandle> objects are <EventEmitter>s.

If a <FileHandle> is not closed using the filehandle.close() method, it will try to automatically close the file descriptor and emit a process warning, helping to prevent memory leaks. Please do not rely on this behavior because it can be unreliable and the file may not be closed. Instead, always explicitly close <FileHandle>s. Node.js may change this behavior in the future.

Event: 'close'#
Added in: v15.4.0
The 'close' event is emitted when the <FileHandle> has been closed and can no longer be used.

filehandle.appendFile(data[, options])#
History
data <string> | <Buffer> | <TypedArray> | <DataView> | <AsyncIterable> | <Iterable> | <Stream>
options <Object> | <string>
encoding <string> | <null> Default: 'utf8'
flush <boolean> If true, the underlying file descriptor is flushed prior to closing it. Default: false.
Returns: <Promise> Fulfills with undefined upon success.
Alias of filehandle.writeFile().

When operating on file handles, the mode cannot be changed from what it was set to with fsPromises.open(). Therefore, this is equivalent to filehandle.writeFile().

filehandle.chmod(mode)#
Added in: v10.0.0
mode <integer> the file mode bit mask.
Returns: <Promise> Fulfills with undefined upon success.
Modifies the permissions on the file. See chmod(2).

filehandle.chown(uid, gid)#
Added in: v10.0.0
uid <integer> The file's new owner's user id.
gid <integer> The file's new group's group id.
Returns: <Promise> Fulfills with undefined upon success.
Changes the ownership of the file. A wrapper for chown(2).

filehandle.close()#
Added in: v10.0.0
Returns: <Promise> Fulfills with undefined upon success.
Closes the file handle after waiting for any pending operation on the handle to complete.

import { open } from 'node:fs/promises';

let filehandle;
try {
  filehandle = await open('thefile.txt', 'r');
} finally {
  await filehandle?.close();
} COPY
filehandle.createReadStream([options])#
Added in: v16.11.0
options <Object>
encoding <string> Default: null
autoClose <boolean> Default: true
emitClose <boolean> Default: true
start <integer>
end <integer> Default: Infinity
highWaterMark <integer> Default: 64 * 1024
Returns: <fs.ReadStream>
Unlike the 16 KiB default highWaterMark for a <stream.Readable>, the stream returned by this method has a default highWaterMark of 64 KiB.

options can include start and end values to read a range of bytes from the file instead of the entire file. Both start and end are inclusive and start counting at 0, allowed values are in the [0, Number.MAX_SAFE_INTEGER] range. If start is omitted or undefined, filehandle.createReadStream() reads sequentially from the current file position. The encoding can be any one of those accepted by <Buffer>.

If the FileHandle points to a character device that only supports blocking reads (such as keyboard or sound card), read operations do not finish until data is available. This can prevent the process from exiting and the stream from closing naturally.

By default, the stream will emit a 'close' event after it has been destroyed. Set the emitClose option to false to change this behavior.

import { open } from 'node:fs/promises';

const fd = await open('/dev/input/event0');
// Create a stream from some character device.
const stream = fd.createReadStream();
setTimeout(() => {
  stream.close(); // This may not close the stream.
  // Artificially marking end-of-stream, as if the underlying resource had
  // indicated end-of-file by itself, allows the stream to close.
  // This does not cancel pending read operations, and if there is such an
  // operation, the process may still not be able to exit successfully
  // until it finishes.
  stream.push(null);
  stream.read(0);
}, 100); COPY
If autoClose is false, then the file descriptor won't be closed, even if there's an error. It is the application's responsibility to close it and make sure there's no file descriptor leak. If autoClose is set to true (default behavior), on 'error' or 'end' the file descriptor will be closed automatically.

An example to read the last 10 bytes of a file which is 100 bytes long:

import { open } from 'node:fs/promises';

const fd = await open('sample.txt');
fd.createReadStream({ start: 90, end: 99 }); COPY
filehandle.createWriteStream([options])#
History
options <Object>
encoding <string> Default: 'utf8'
autoClose <boolean> Default: true
emitClose <boolean> Default: true
start <integer>
highWaterMark <number> Default: 16384
flush <boolean> If true, the underlying file descriptor is flushed prior to closing it. Default: false.
Returns: <fs.WriteStream>
options may also include a start option to allow writing data at some position past the beginning of the file, allowed values are in the [0, Number.MAX_SAFE_INTEGER] range. Modifying a file rather than replacing it may require the flags open option to be set to r+ rather than the default r. The encoding can be any one of those accepted by <Buffer>.

If autoClose is set to true (default behavior) on 'error' or 'finish' the file descriptor will be closed automatically. If autoClose is false, then the file descriptor won't be closed, even if there's an error. It is the application's responsibility to close it and make sure there's no file descriptor leak.

By default, the stream will emit a 'close' event after it has been destroyed. Set the emitClose option to false to change this behavior.

filehandle.datasync()#
Added in: v10.0.0
Returns: <Promise> Fulfills with undefined upon success.
Forces all currently queued I/O operations associated with the file to the operating system's synchronized I/O completion state. Refer to the POSIX fdatasync(2) documentation for details.

Unlike filehandle.sync this method does not flush modified metadata.

filehandle.fd#
Added in: v10.0.0
<number> The numeric file descriptor managed by the <FileHandle> object.
filehandle.read(buffer, offset, length, position)#
History
buffer <Buffer> | <TypedArray> | <DataView> A buffer that will be filled with the file data read.
offset <integer> The location in the buffer at which to start filling. Default: 0
length <integer> The number of bytes to read. Default: buffer.byteLength - offset
position <integer> | <bigint> | <null> The location where to begin reading data from the file. If null or -1, data will be read from the current file position, and the position will be updated. If position is a non-negative integer, the current file position will remain unchanged. Default:: null
Returns: <Promise> Fulfills upon success with an object with two properties:
bytesRead <integer> The number of bytes read
buffer <Buffer> | <TypedArray> | <DataView> A reference to the passed in buffer argument.
Reads data from the file and stores that in the given buffer.

If the file is not modified concurrently, the end-of-file is reached when the number of bytes read is zero.

filehandle.read([options])#
History
options <Object>
buffer <Buffer> | <TypedArray> | <DataView> A buffer that will be filled with the file data read. Default: Buffer.alloc(16384)
offset <integer> The location in the buffer at which to start filling. Default: 0
length <integer> The number of bytes to read. Default: buffer.byteLength - offset
position <integer> | <bigint> | <null> The location where to begin reading data from the file. If null or -1, data will be read from the current file position, and the position will be updated. If position is a non-negative integer, the current file position will remain unchanged. Default:: null
Returns: <Promise> Fulfills upon success with an object with two properties:
bytesRead <integer> The number of bytes read
buffer <Buffer> | <TypedArray> | <DataView> A reference to the passed in buffer argument.
Reads data from the file and stores that in the given buffer.

If the file is not modified concurrently, the end-of-file is reached when the number of bytes read is zero.

filehandle.read(buffer[, options])#
History
buffer <Buffer> | <TypedArray> | <DataView> A buffer that will be filled with the file data read.
options <Object>
offset <integer> The location in the buffer at which to start filling. Default: 0
length <integer> The number of bytes to read. Default: buffer.byteLength - offset
position <integer> | <bigint> | <null> The location where to begin reading data from the file. If null or -1, data will be read from the current file position, and the position will be updated. If position is a non-negative integer, the current file position will remain unchanged. Default:: null
Returns: <Promise> Fulfills upon success with an object with two properties:
bytesRead <integer> The number of bytes read
buffer <Buffer> | <TypedArray> | <DataView> A reference to the passed in buffer argument.
Reads data from the file and stores that in the given buffer.

If the file is not modified concurrently, the end-of-file is reached when the number of bytes read is zero.

filehandle.readableWebStream([options])#
History
Stability: 1 - Experimental
options <Object>

type <string> | <undefined> Whether to open a normal or a 'bytes' stream. Default: undefined
Returns: <ReadableStream>

Returns a ReadableStream that may be used to read the files data.

An error will be thrown if this method is called more than once or is called after the FileHandle is closed or closing.

const {
  open,
} = require('node:fs/promises');

(async () => {
  const file = await open('./some/file/to/read');

  for await (const chunk of file.readableWebStream())
    console.log(chunk);

  await file.close();
})();COPY
While the ReadableStream will read the file to completion, it will not close the FileHandle automatically. User code must still call the fileHandle.close() method.

filehandle.readFile(options)#
Added in: v10.0.0
options <Object> | <string>
encoding <string> | <null> Default: null
signal <AbortSignal> allows aborting an in-progress readFile
Returns: <Promise> Fulfills upon a successful read with the contents of the file. If no encoding is specified (using options.encoding), the data is returned as a <Buffer> object. Otherwise, the data will be a string.
Asynchronously reads the entire contents of a file.

If options is a string, then it specifies the encoding.

The <FileHandle> has to support reading.

If one or more filehandle.read() calls are made on a file handle and then a filehandle.readFile() call is made, the data will be read from the current position till the end of the file. It doesn't always read from the beginning of the file.

filehandle.readLines([options])#
Added in: v18.11.0
options <Object>
encoding <string> Default: null
autoClose <boolean> Default: true
emitClose <boolean> Default: true
start <integer>
end <integer> Default: Infinity
highWaterMark <integer> Default: 64 * 1024
Returns: <readline.InterfaceConstructor>
Convenience method to create a readline interface and stream over the file. See filehandle.createReadStream() for the options.

const { open } = require('node:fs/promises');

(async () => {
  const file = await open('./some/file/to/read');

  for await (const line of file.readLines()) {
    console.log(line);
  }
})();COPY
filehandle.readv(buffers[, position])#
Added in: v13.13.0, v12.17.0
buffers <Buffer[]> | <TypedArray[]> | <DataView[]>
position <integer> | <null> The offset from the beginning of the file where the data should be read from. If position is not a number, the data will be read from the current position. Default: null
Returns: <Promise> Fulfills upon success an object containing two properties:
bytesRead <integer> the number of bytes read
buffers <Buffer[]> | <TypedArray[]> | <DataView[]> property containing a reference to the buffers input.
Read from a file and write to an array of <ArrayBufferView>s

filehandle.stat([options])#
History
options <Object>
bigint <boolean> Whether the numeric values in the returned <fs.Stats> object should be bigint. Default: false.
Returns: <Promise> Fulfills with an <fs.Stats> for the file.
filehandle.sync()#
Added in: v10.0.0
Returns: <Promise> Fulfills with undefined upon success.
Request that all data for the open file descriptor is flushed to the storage device. The specific implementation is operating system and device specific. Refer to the POSIX fsync(2) documentation for more detail.

filehandle.truncate(len)#
Added in: v10.0.0
len <integer> Default: 0
Returns: <Promise> Fulfills with undefined upon success.
Truncates the file.

If the file was larger than len bytes, only the first len bytes will be retained in the file.

The following example retains only the first four bytes of the file:

import { open } from 'node:fs/promises';

let filehandle = null;
try {
  filehandle = await open('temp.txt', 'r+');
  await filehandle.truncate(4);
} finally {
  await filehandle?.close();
} COPY
If the file previously was shorter than len bytes, it is extended, and the extended part is filled with null bytes ('\0'):

If len is negative then 0 will be used.

filehandle.utimes(atime, mtime)#
Added in: v10.0.0
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
Returns: <Promise>
Change the file system timestamps of the object referenced by the <FileHandle> then fulfills the promise with no arguments upon success.

filehandle.write(buffer, offset[, length[, position]])#
History
buffer <Buffer> | <TypedArray> | <DataView>
offset <integer> The start position from within buffer where the data to write begins.
length <integer> The number of bytes from buffer to write. Default: buffer.byteLength - offset
position <integer> | <null> The offset from the beginning of the file where the data from buffer should be written. If position is not a number, the data will be written at the current position. See the POSIX pwrite(2) documentation for more detail. Default: null
Returns: <Promise>
Write buffer to the file.

The promise is fulfilled with an object containing two properties:

bytesWritten <integer> the number of bytes written
buffer <Buffer> | <TypedArray> | <DataView> a reference to the buffer written.
It is unsafe to use filehandle.write() multiple times on the same file without waiting for the promise to be fulfilled (or rejected). For this scenario, use filehandle.createWriteStream().

On Linux, positional writes do not work when the file is opened in append mode. The kernel ignores the position argument and always appends the data to the end of the file.

filehandle.write(buffer[, options])#
Added in: v18.3.0, v16.17.0
buffer <Buffer> | <TypedArray> | <DataView>
options <Object>
offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> Default: null
Returns: <Promise>
Write buffer to the file.

Similar to the above filehandle.write function, this version takes an optional options object. If no options object is specified, it will default with the above values.

filehandle.write(string[, position[, encoding]])#
History
string <string>
position <integer> | <null> The offset from the beginning of the file where the data from string should be written. If position is not a number the data will be written at the current position. See the POSIX pwrite(2) documentation for more detail. Default: null
encoding <string> The expected string encoding. Default: 'utf8'
Returns: <Promise>
Write string to the file. If string is not a string, the promise is rejected with an error.

The promise is fulfilled with an object containing two properties:

bytesWritten <integer> the number of bytes written
buffer <string> a reference to the string written.
It is unsafe to use filehandle.write() multiple times on the same file without waiting for the promise to be fulfilled (or rejected). For this scenario, use filehandle.createWriteStream().

On Linux, positional writes do not work when the file is opened in append mode. The kernel ignores the position argument and always appends the data to the end of the file.

filehandle.writeFile(data, options)#
History
data <string> | <Buffer> | <TypedArray> | <DataView> | <AsyncIterable> | <Iterable> | <Stream>
options <Object> | <string>
encoding <string> | <null> The expected character encoding when data is a string. Default: 'utf8'
Returns: <Promise>
Asynchronously writes data to a file, replacing the file if it already exists. data can be a string, a buffer, an <AsyncIterable>, or an <Iterable> object. The promise is fulfilled with no arguments upon success.

If options is a string, then it specifies the encoding.

The <FileHandle> has to support writing.

It is unsafe to use filehandle.writeFile() multiple times on the same file without waiting for the promise to be fulfilled (or rejected).

If one or more filehandle.write() calls are made on a file handle and then a filehandle.writeFile() call is made, the data will be written from the current position till the end of the file. It doesn't always write from the beginning of the file.

filehandle.writev(buffers[, position])#
Added in: v12.9.0
buffers <Buffer[]> | <TypedArray[]> | <DataView[]>
position <integer> | <null> The offset from the beginning of the file where the data from buffers should be written. If position is not a number, the data will be written at the current position. Default: null
Returns: <Promise>
Write an array of <ArrayBufferView>s to the file.

The promise is fulfilled with an object containing a two properties:

bytesWritten <integer> the number of bytes written
buffers <Buffer[]> | <TypedArray[]> | <DataView[]> a reference to the buffers input.
It is unsafe to call writev() multiple times on the same file without waiting for the promise to be fulfilled (or rejected).

On Linux, positional writes don't work when the file is opened in append mode. The kernel ignores the position argument and always appends the data to the end of the file.

filehandle[Symbol.asyncDispose]()#
Added in: v20.4.0, v18.18.0
Stability: 1 - Experimental
An alias for filehandle.close().

fsPromises.access(path[, mode])#
Added in: v10.0.0
path <string> | <Buffer> | <URL>
mode <integer> Default: fs.constants.F_OK
Returns: <Promise> Fulfills with undefined upon success.
Tests a user's permissions for the file or directory specified by path. The mode argument is an optional integer that specifies the accessibility checks to be performed. mode should be either the value fs.constants.F_OK or a mask consisting of the bitwise OR of any of fs.constants.R_OK, fs.constants.W_OK, and fs.constants.X_OK (e.g. fs.constants.W_OK | fs.constants.R_OK). Check File access constants for possible values of mode.

If the accessibility check is successful, the promise is fulfilled with no value. If any of the accessibility checks fail, the promise is rejected with an <Error> object. The following example checks if the file /etc/passwd can be read and written by the current process.

import { access, constants } from 'node:fs/promises';

try {
  await access('/etc/passwd', constants.R_OK | constants.W_OK);
  console.log('can access');
} catch {
  console.error('cannot access');
} COPY
Using fsPromises.access() to check for the accessibility of a file before calling fsPromises.open() is not recommended. Doing so introduces a race condition, since other processes may change the file's state between the two calls. Instead, user code should open/read/write the file directly and handle the error raised if the file is not accessible.

fsPromises.appendFile(path, data[, options])#
History
path <string> | <Buffer> | <URL> | <FileHandle> filename or <FileHandle>
data <string> | <Buffer>
options <Object> | <string>
encoding <string> | <null> Default: 'utf8'
mode <integer> Default: 0o666
flag <string> See support of file system flags. Default: 'a'.
flush <boolean> If true, the underlying file descriptor is flushed prior to closing it. Default: false.
Returns: <Promise> Fulfills with undefined upon success.
Asynchronously append data to a file, creating the file if it does not yet exist. data can be a string or a <Buffer>.

If options is a string, then it specifies the encoding.

The mode option only affects the newly created file. See fs.open() for more details.

The path may be specified as a <FileHandle> that has been opened for appending (using fsPromises.open()).

fsPromises.chmod(path, mode)#
Added in: v10.0.0
path <string> | <Buffer> | <URL>
mode <string> | <integer>
Returns: <Promise> Fulfills with undefined upon success.
Changes the permissions of a file.

fsPromises.chown(path, uid, gid)#
Added in: v10.0.0
path <string> | <Buffer> | <URL>
uid <integer>
gid <integer>
Returns: <Promise> Fulfills with undefined upon success.
Changes the ownership of a file.

fsPromises.copyFile(src, dest[, mode])#
History
src <string> | <Buffer> | <URL> source filename to copy
dest <string> | <Buffer> | <URL> destination filename of the copy operation
mode <integer> Optional modifiers that specify the behavior of the copy operation. It is possible to create a mask consisting of the bitwise OR of two or more values (e.g. fs.constants.COPYFILE_EXCL | fs.constants.COPYFILE_FICLONE) Default: 0.
fs.constants.COPYFILE_EXCL: The copy operation will fail if dest already exists.
fs.constants.COPYFILE_FICLONE: The copy operation will attempt to create a copy-on-write reflink. If the platform does not support copy-on-write, then a fallback copy mechanism is used.
fs.constants.COPYFILE_FICLONE_FORCE: The copy operation will attempt to create a copy-on-write reflink. If the platform does not support copy-on-write, then the operation will fail.
Returns: <Promise> Fulfills with undefined upon success.
Asynchronously copies src to dest. By default, dest is overwritten if it already exists.

No guarantees are made about the atomicity of the copy operation. If an error occurs after the destination file has been opened for writing, an attempt will be made to remove the destination.

import { copyFile, constants } from 'node:fs/promises';

try {
  await copyFile('source.txt', 'destination.txt');
  console.log('source.txt was copied to destination.txt');
} catch {
  console.error('The file could not be copied');
}

// By using COPYFILE_EXCL, the operation will fail if destination.txt exists.
try {
  await copyFile('source.txt', 'destination.txt', constants.COPYFILE_EXCL);
  console.log('source.txt was copied to destination.txt');
} catch {
  console.error('The file could not be copied');
} COPY
fsPromises.cp(src, dest[, options])#
History
src <string> | <URL> source path to copy.
dest <string> | <URL> destination path to copy to.
options <Object>
dereference <boolean> dereference symlinks. Default: false.
errorOnExist <boolean> when force is false, and the destination exists, throw an error. Default: false.
filter <Function> Function to filter copied files/directories. Return true to copy the item, false to ignore it. When ignoring a directory, all of its contents will be skipped as well. Can also return a Promise that resolves to true or false Default: undefined.
src <string> source path to copy.
dest <string> destination path to copy to.
Returns: <boolean> | <Promise> A value that is coercible to boolean or a Promise that fulfils with such value.
force <boolean> overwrite existing file or directory. The copy operation will ignore errors if you set this to false and the destination exists. Use the errorOnExist option to change this behavior. Default: true.
mode <integer> modifiers for copy operation. Default: 0. See mode flag of fsPromises.copyFile().
preserveTimestamps <boolean> When true timestamps from src will be preserved. Default: false.
recursive <boolean> copy directories recursively Default: false
verbatimSymlinks <boolean> When true, path resolution for symlinks will be skipped. Default: false
Returns: <Promise> Fulfills with undefined upon success.
Asynchronously copies the entire directory structure from src to dest, including subdirectories and files.

When copying a directory to another directory, globs are not supported and behavior is similar to cp dir1/ dir2/.

fsPromises.glob(pattern[, options])#
History
Stability: 1 - Experimental
pattern <string> | <string[]>
options <Object>
cwd <string> current working directory. Default: process.cwd()
exclude <Function> Function to filter out files/directories. Return true to exclude the item, false to include it. Default: undefined.
withFileTypes <boolean> true if the glob should return paths as Dirents, false otherwise. Default: false.
Returns: <AsyncIterator> An AsyncIterator that yields the paths of files that match the pattern.
const { glob } = require('node:fs/promises');

(async () => {
  for await (const entry of glob('**/*.js'))
    console.log(entry);
})();COPY
fsPromises.lchmod(path, mode)#
Deprecated since: v10.0.0
path <string> | <Buffer> | <URL>
mode <integer>
Returns: <Promise> Fulfills with undefined upon success.
Changes the permissions on a symbolic link.

This method is only implemented on macOS.

fsPromises.lchown(path, uid, gid)#
History
path <string> | <Buffer> | <URL>
uid <integer>
gid <integer>
Returns: <Promise> Fulfills with undefined upon success.
Changes the ownership on a symbolic link.

fsPromises.lutimes(path, atime, mtime)#
Added in: v14.5.0, v12.19.0
path <string> | <Buffer> | <URL>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
Returns: <Promise> Fulfills with undefined upon success.
Changes the access and modification times of a file in the same way as fsPromises.utimes(), with the difference that if the path refers to a symbolic link, then the link is not dereferenced: instead, the timestamps of the symbolic link itself are changed.

fsPromises.link(existingPath, newPath)#
Added in: v10.0.0
existingPath <string> | <Buffer> | <URL>
newPath <string> | <Buffer> | <URL>
Returns: <Promise> Fulfills with undefined upon success.
Creates a new link from the existingPath to the newPath. See the POSIX link(2) documentation for more detail.

fsPromises.lstat(path[, options])#
History
path <string> | <Buffer> | <URL>
options <Object>
bigint <boolean> Whether the numeric values in the returned <fs.Stats> object should be bigint. Default: false.
Returns: <Promise> Fulfills with the <fs.Stats> object for the given symbolic link path.
Equivalent to fsPromises.stat() unless path refers to a symbolic link, in which case the link itself is stat-ed, not the file that it refers to. Refer to the POSIX lstat(2) document for more detail.

fsPromises.mkdir(path[, options])#
Added in: v10.0.0
path <string> | <Buffer> | <URL>
options <Object> | <integer>
recursive <boolean> Default: false
mode <string> | <integer> Not supported on Windows. Default: 0o777.
Returns: <Promise> Upon success, fulfills with undefined if recursive is false, or the first directory path created if recursive is true.
Asynchronously creates a directory.

The optional options argument can be an integer specifying mode (permission and sticky bits), or an object with a mode property and a recursive property indicating whether parent directories should be created. Calling fsPromises.mkdir() when path is a directory that exists results in a rejection only when recursive is false.

const { mkdir } = require('node:fs/promises');
const { join } = require('node:path');

async function makeDirectory() {
  const projectFolder = join(__dirname, 'test', 'project');
  const dirCreation = await mkdir(projectFolder, { recursive: true });

  console.log(dirCreation);
  return dirCreation;
}

makeDirectory().catch(console.error);COPY
fsPromises.mkdtemp(prefix[, options])#
History
prefix <string> | <Buffer> | <URL>
options <string> | <Object>
encoding <string> Default: 'utf8'
Returns: <Promise> Fulfills with a string containing the file system path of the newly created temporary directory.
Creates a unique temporary directory. A unique directory name is generated by appending six random characters to the end of the provided prefix. Due to platform inconsistencies, avoid trailing X characters in prefix. Some platforms, notably the BSDs, can return more than six random characters, and replace trailing X characters in prefix with random characters.

The optional options argument can be a string specifying an encoding, or an object with an encoding property specifying the character encoding to use.

import { mkdtemp } from 'node:fs/promises';
import { join } from 'node:path';
import { tmpdir } from 'node:os';

try {
  await mkdtemp(join(tmpdir(), 'foo-'));
} catch (err) {
  console.error(err);
} COPY
The fsPromises.mkdtemp() method will append the six randomly selected characters directly to the prefix string. For instance, given a directory /tmp, if the intention is to create a temporary directory within /tmp, the prefix must end with a trailing platform-specific path separator (require('node:path').sep).

fsPromises.open(path, flags[, mode])#
History
path <string> | <Buffer> | <URL>
flags <string> | <number> See support of file system flags. Default: 'r'.
mode <string> | <integer> Sets the file mode (permission and sticky bits) if the file is created. Default: 0o666 (readable and writable)
Returns: <Promise> Fulfills with a <FileHandle> object.
Opens a <FileHandle>.

Refer to the POSIX open(2) documentation for more detail.

Some characters (< > : " / \ | ? *) are reserved under Windows as documented by Naming Files, Paths, and Namespaces. Under NTFS, if the filename contains a colon, Node.js will open a file system stream, as described by this MSDN page.

fsPromises.opendir(path[, options])#
History
path <string> | <Buffer> | <URL>
options <Object>
encoding <string> | <null> Default: 'utf8'
bufferSize <number> Number of directory entries that are buffered internally when reading from the directory. Higher values lead to better performance but higher memory usage. Default: 32
recursive <boolean> Resolved Dir will be an <AsyncIterable> containing all sub files and directories. Default: false
Returns: <Promise> Fulfills with an <fs.Dir>.
Asynchronously open a directory for iterative scanning. See the POSIX opendir(3) documentation for more detail.

Creates an <fs.Dir>, which contains all further functions for reading from and cleaning up the directory.

The encoding option sets the encoding for the path while opening the directory and subsequent read operations.

Example using async iteration:

import { opendir } from 'node:fs/promises';

try {
  const dir = await opendir('./');
  for await (const dirent of dir)
    console.log(dirent.name);
} catch (err) {
  console.error(err);
} COPY
When using the async iterator, the <fs.Dir> object will be automatically closed after the iterator exits.

fsPromises.readdir(path[, options])#
History
path <string> | <Buffer> | <URL>
options <string> | <Object>
encoding <string> Default: 'utf8'
withFileTypes <boolean> Default: false
recursive <boolean> If true, reads the contents of a directory recursively. In recursive mode, it will list all files, sub files, and directories. Default: false.
Returns: <Promise> Fulfills with an array of the names of the files in the directory excluding '.' and '..'.
Reads the contents of a directory.

The optional options argument can be a string specifying an encoding, or an object with an encoding property specifying the character encoding to use for the filenames. If the encoding is set to 'buffer', the filenames returned will be passed as <Buffer> objects.

If options.withFileTypes is set to true, the returned array will contain <fs.Dirent> objects.

import { readdir } from 'node:fs/promises';

try {
  const files = await readdir(path);
  for (const file of files)
    console.log(file);
} catch (err) {
  console.error(err);
} COPY
fsPromises.readFile(path[, options])#
History
path <string> | <Buffer> | <URL> | <FileHandle> filename or FileHandle
options <Object> | <string>
encoding <string> | <null> Default: null
flag <string> See support of file system flags. Default: 'r'.
signal <AbortSignal> allows aborting an in-progress readFile
Returns: <Promise> Fulfills with the contents of the file.
Asynchronously reads the entire contents of a file.

If no encoding is specified (using options.encoding), the data is returned as a <Buffer> object. Otherwise, the data will be a string.

If options is a string, then it specifies the encoding.

When the path is a directory, the behavior of fsPromises.readFile() is platform-specific. On macOS, Linux, and Windows, the promise will be rejected with an error. On FreeBSD, a representation of the directory's contents will be returned.

An example of reading a package.json file located in the same directory of the running code:

const { readFile } = require('node:fs/promises');
const { resolve } = require('node:path');
async function logFile() {
  try {
    const filePath = resolve('./package.json');
    const contents = await readFile(filePath, { encoding: 'utf8' });
    console.log(contents);
  } catch (err) {
    console.error(err.message);
  }
}
logFile();COPY
It is possible to abort an ongoing readFile using an <AbortSignal>. If a request is aborted the promise returned is rejected with an AbortError:

import { readFile } from 'node:fs/promises';

try {
  const controller = new AbortController();
  const { signal } = controller;
  const promise = readFile(fileName, { signal });

  // Abort the request before the promise settles.
  controller.abort();

  await promise;
} catch (err) {
  // When a request is aborted - err is an AbortError
  console.error(err);
} COPY
Aborting an ongoing request does not abort individual operating system requests but rather the internal buffering fs.readFile performs.

Any specified <FileHandle> has to support reading.

fsPromises.readlink(path[, options])#
Added in: v10.0.0
path <string> | <Buffer> | <URL>
options <string> | <Object>
encoding <string> Default: 'utf8'
Returns: <Promise> Fulfills with the linkString upon success.
Reads the contents of the symbolic link referred to by path. See the POSIX readlink(2) documentation for more detail. The promise is fulfilled with the linkString upon success.

The optional options argument can be a string specifying an encoding, or an object with an encoding property specifying the character encoding to use for the link path returned. If the encoding is set to 'buffer', the link path returned will be passed as a <Buffer> object.

fsPromises.realpath(path[, options])#
Added in: v10.0.0
path <string> | <Buffer> | <URL>
options <string> | <Object>
encoding <string> Default: 'utf8'
Returns: <Promise> Fulfills with the resolved path upon success.
Determines the actual location of path using the same semantics as the fs.realpath.native() function.

Only paths that can be converted to UTF8 strings are supported.

The optional options argument can be a string specifying an encoding, or an object with an encoding property specifying the character encoding to use for the path. If the encoding is set to 'buffer', the path returned will be passed as a <Buffer> object.

On Linux, when Node.js is linked against musl libc, the procfs file system must be mounted on /proc in order for this function to work. Glibc does not have this restriction.

fsPromises.rename(oldPath, newPath)#
Added in: v10.0.0
oldPath <string> | <Buffer> | <URL>
newPath <string> | <Buffer> | <URL>
Returns: <Promise> Fulfills with undefined upon success.
Renames oldPath to newPath.

fsPromises.rmdir(path[, options])#
History
path <string> | <Buffer> | <URL>
options <Object>
maxRetries <integer> If an EBUSY, EMFILE, ENFILE, ENOTEMPTY, or EPERM error is encountered, Node.js retries the operation with a linear backoff wait of retryDelay milliseconds longer on each try. This option represents the number of retries. This option is ignored if the recursive option is not true. Default: 0.
recursive <boolean> If true, perform a recursive directory removal. In recursive mode, operations are retried on failure. Default: false. Deprecated.
retryDelay <integer> The amount of time in milliseconds to wait between retries. This option is ignored if the recursive option is not true. Default: 100.
Returns: <Promise> Fulfills with undefined upon success.
Removes the directory identified by path.

Using fsPromises.rmdir() on a file (not a directory) results in the promise being rejected with an ENOENT error on Windows and an ENOTDIR error on POSIX.

To get a behavior similar to the rm -rf Unix command, use fsPromises.rm() with options { recursive: true, force: true }.

fsPromises.rm(path[, options])#
Added in: v14.14.0
path <string> | <Buffer> | <URL>
options <Object>
force <boolean> When true, exceptions will be ignored if path does not exist. Default: false.
maxRetries <integer> If an EBUSY, EMFILE, ENFILE, ENOTEMPTY, or EPERM error is encountered, Node.js will retry the operation with a linear backoff wait of retryDelay milliseconds longer on each try. This option represents the number of retries. This option is ignored if the recursive option is not true. Default: 0.
recursive <boolean> If true, perform a recursive directory removal. In recursive mode operations are retried on failure. Default: false.
retryDelay <integer> The amount of time in milliseconds to wait between retries. This option is ignored if the recursive option is not true. Default: 100.
Returns: <Promise> Fulfills with undefined upon success.
Removes files and directories (modeled on the standard POSIX rm utility).

fsPromises.stat(path[, options])#
History
path <string> | <Buffer> | <URL>
options <Object>
bigint <boolean> Whether the numeric values in the returned <fs.Stats> object should be bigint. Default: false.
Returns: <Promise> Fulfills with the <fs.Stats> object for the given path.
fsPromises.statfs(path[, options])#
Added in: v19.6.0, v18.15.0
path <string> | <Buffer> | <URL>
options <Object>
bigint <boolean> Whether the numeric values in the returned <fs.StatFs> object should be bigint. Default: false.
Returns: <Promise> Fulfills with the <fs.StatFs> object for the given path.
fsPromises.symlink(target, path[, type])#
History
target <string> | <Buffer> | <URL>
path <string> | <Buffer> | <URL>
type <string> | <null> Default: null
Returns: <Promise> Fulfills with undefined upon success.
Creates a symbolic link.

The type argument is only used on Windows platforms and can be one of 'dir', 'file', or 'junction'. If the type argument is not a string, Node.js will autodetect target type and use 'file' or 'dir'. If the target does not exist, 'file' will be used. Windows junction points require the destination path to be absolute. When using 'junction', the target argument will automatically be normalized to absolute path. Junction points on NTFS volumes can only point to directories.

fsPromises.truncate(path[, len])#
Added in: v10.0.0
path <string> | <Buffer> | <URL>
len <integer> Default: 0
Returns: <Promise> Fulfills with undefined upon success.
Truncates (shortens or extends the length) of the content at path to len bytes.

fsPromises.unlink(path)#
Added in: v10.0.0
path <string> | <Buffer> | <URL>
Returns: <Promise> Fulfills with undefined upon success.
If path refers to a symbolic link, then the link is removed without affecting the file or directory to which that link refers. If the path refers to a file path that is not a symbolic link, the file is deleted. See the POSIX unlink(2) documentation for more detail.

fsPromises.utimes(path, atime, mtime)#
Added in: v10.0.0
path <string> | <Buffer> | <URL>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
Returns: <Promise> Fulfills with undefined upon success.
Change the file system timestamps of the object referenced by path.

The atime and mtime arguments follow these rules:

Values can be either numbers representing Unix epoch time, Dates, or a numeric string like '123456789.0'.
If the value can not be converted to a number, or is NaN, Infinity, or -Infinity, an Error will be thrown.
fsPromises.watch(filename[, options])#
Added in: v15.9.0, v14.18.0
filename <string> | <Buffer> | <URL>
options <string> | <Object>
persistent <boolean> Indicates whether the process should continue to run as long as files are being watched. Default: true.
recursive <boolean> Indicates whether all subdirectories should be watched, or only the current directory. This applies when a directory is specified, and only on supported platforms (See caveats). Default: false.
encoding <string> Specifies the character encoding to be used for the filename passed to the listener. Default: 'utf8'.
signal <AbortSignal> An <AbortSignal> used to signal when the watcher should stop.
Returns: <AsyncIterator> of objects with the properties:
eventType <string> The type of change
filename <string> | <Buffer> | <null> The name of the file changed.
Returns an async iterator that watches for changes on filename, where filename is either a file or a directory.

const { watch } = require('node:fs/promises');

const ac = new AbortController();
const { signal } = ac;
setTimeout(() => ac.abort(), 10000);

(async () => {
  try {
    const watcher = watch(__filename, { signal });
    for await (const event of watcher)
      console.log(event);
  } catch (err) {
    if (err.name === 'AbortError')
      return;
    throw err;
  }
})(); COPY
On most platforms, 'rename' is emitted whenever a filename appears or disappears in the directory.

All the caveats for fs.watch() also apply to fsPromises.watch().

fsPromises.writeFile(file, data[, options])#
History
file <string> | <Buffer> | <URL> | <FileHandle> filename or FileHandle
data <string> | <Buffer> | <TypedArray> | <DataView> | <AsyncIterable> | <Iterable> | <Stream>
options <Object> | <string>
encoding <string> | <null> Default: 'utf8'
mode <integer> Default: 0o666
flag <string> See support of file system flags. Default: 'w'.
flush <boolean> If all data is successfully written to the file, and flush is true, filehandle.sync() is used to flush the data. Default: false.
signal <AbortSignal> allows aborting an in-progress writeFile
Returns: <Promise> Fulfills with undefined upon success.
Asynchronously writes data to a file, replacing the file if it already exists. data can be a string, a buffer, an <AsyncIterable>, or an <Iterable> object.

The encoding option is ignored if data is a buffer.

If options is a string, then it specifies the encoding.

The mode option only affects the newly created file. See fs.open() for more details.

Any specified <FileHandle> has to support writing.

It is unsafe to use fsPromises.writeFile() multiple times on the same file without waiting for the promise to be settled.

Similarly to fsPromises.readFile - fsPromises.writeFile is a convenience method that performs multiple write calls internally to write the buffer passed to it. For performance sensitive code consider using fs.createWriteStream() or filehandle.createWriteStream().

It is possible to use an <AbortSignal> to cancel an fsPromises.writeFile(). Cancelation is "best effort", and some amount of data is likely still to be written.

import { writeFile } from 'node:fs/promises';
import { Buffer } from 'node:buffer';

try {
  const controller = new AbortController();
  const { signal } = controller;
  const data = new Uint8Array(Buffer.from('Hello Node.js'));
  const promise = writeFile('message.txt', data, { signal });

  // Abort the request before the promise settles.
  controller.abort();

  await promise;
} catch (err) {
  // When a request is aborted - err is an AbortError
  console.error(err);
} COPY
Aborting an ongoing request does not abort individual operating system requests but rather the internal buffering fs.writeFile performs.

fsPromises.constants#
Added in: v18.4.0, v16.17.0
<Object>
Returns an object containing commonly used constants for file system operations. The object is the same as fs.constants. See FS constants for more details.

Callback API#
The callback APIs perform all operations asynchronously, without blocking the event loop, then invoke a callback function upon completion or error.

The callback APIs use the underlying Node.js threadpool to perform file system operations off the event loop thread. These operations are not synchronized or threadsafe. Care must be taken when performing multiple concurrent modifications on the same file or data corruption may occur.

fs.access(path[, mode], callback)#
History
path <string> | <Buffer> | <URL>
mode <integer> Default: fs.constants.F_OK
callback <Function>
err <Error>
Tests a user's permissions for the file or directory specified by path. The mode argument is an optional integer that specifies the accessibility checks to be performed. mode should be either the value fs.constants.F_OK or a mask consisting of the bitwise OR of any of fs.constants.R_OK, fs.constants.W_OK, and fs.constants.X_OK (e.g. fs.constants.W_OK | fs.constants.R_OK). Check File access constants for possible values of mode.

The final argument, callback, is a callback function that is invoked with a possible error argument. If any of the accessibility checks fail, the error argument will be an Error object. The following examples check if package.json exists, and if it is readable or writable.

import { access, constants } from 'node:fs';

const file = 'package.json';

// Check if the file exists in the current directory.
access(file, constants.F_OK, (err) => {
  console.log(`${file} ${err ? 'does not exist' : 'exists'}`);
});

// Check if the file is readable.
access(file, constants.R_OK, (err) => {
  console.log(`${file} ${err ? 'is not readable' : 'is readable'}`);
});

// Check if the file is writable.
access(file, constants.W_OK, (err) => {
  console.log(`${file} ${err ? 'is not writable' : 'is writable'}`);
});

// Check if the file is readable and writable.
access(file, constants.R_OK | constants.W_OK, (err) => {
  console.log(`${file} ${err ? 'is not' : 'is'} readable and writable`);
}); COPY
Do not use fs.access() to check for the accessibility of a file before calling fs.open(), fs.readFile(), or fs.writeFile(). Doing so introduces a race condition, since other processes may change the file's state between the two calls. Instead, user code should open/read/write the file directly and handle the error raised if the file is not accessible.

write (NOT RECOMMENDED)

import { access, open, close } from 'node:fs';

access('myfile', (err) => {
  if (!err) {
    console.error('myfile already exists');
    return;
  }

  open('myfile', 'wx', (err, fd) => {
    if (err) throw err;

    try {
      writeMyData(fd);
    } finally {
      close(fd, (err) => {
        if (err) throw err;
      });
    }
  });
}); COPY
write (RECOMMENDED)

import { open, close } from 'node:fs';

open('myfile', 'wx', (err, fd) => {
  if (err) {
    if (err.code === 'EEXIST') {
      console.error('myfile already exists');
      return;
    }

    throw err;
  }

  try {
    writeMyData(fd);
  } finally {
    close(fd, (err) => {
      if (err) throw err;
    });
  }
}); COPY
read (NOT RECOMMENDED)

import { access, open, close } from 'node:fs';
access('myfile', (err) => {
  if (err) {
    if (err.code === 'ENOENT') {
      console.error('myfile does not exist');
      return;
    }

    throw err;
  }

  open('myfile', 'r', (err, fd) => {
    if (err) throw err;

    try {
      readMyData(fd);
    } finally {
      close(fd, (err) => {
        if (err) throw err;
      });
    }
  });
}); COPY
read (RECOMMENDED)

import { open, close } from 'node:fs';

open('myfile', 'r', (err, fd) => {
  if (err) {
    if (err.code === 'ENOENT') {
      console.error('myfile does not exist');
      return;
    }

    throw err;
  }

  try {
    readMyData(fd);
  } finally {
    close(fd, (err) => {
      if (err) throw err;
    });
  }
}); COPY
The "not recommended" examples above check for accessibility and then use the file; the "recommended" examples are better because they use the file directly and handle the error, if any.

In general, check for the accessibility of a file only if the file will not be used directly, for example when its accessibility is a signal from another process.

On Windows, access-control policies (ACLs) on a directory may limit access to a file or directory. The fs.access() function, however, does not check the ACL and therefore may report that a path is accessible even if the ACL restricts the user from reading or writing to it.

fs.appendFile(path, data[, options], callback)#
History
path <string> | <Buffer> | <URL> | <number> filename or file descriptor
data <string> | <Buffer>
options <Object> | <string>
encoding <string> | <null> Default: 'utf8'
mode <integer> Default: 0o666
flag <string> See support of file system flags. Default: 'a'.
flush <boolean> If true, the underlying file descriptor is flushed prior to closing it. Default: false.
callback <Function>
err <Error>
Asynchronously append data to a file, creating the file if it does not yet exist. data can be a string or a <Buffer>.

The mode option only affects the newly created file. See fs.open() for more details.

import { appendFile } from 'node:fs';

appendFile('message.txt', 'data to append', (err) => {
  if (err) throw err;
  console.log('The "data to append" was appended to file!');
}); COPY
If options is a string, then it specifies the encoding:

import { appendFile } from 'node:fs';

appendFile('message.txt', 'data to append', 'utf8', callback); COPY
The path may be specified as a numeric file descriptor that has been opened for appending (using fs.open() or fs.openSync()). The file descriptor will not be closed automatically.

import { open, close, appendFile } from 'node:fs';

function closeFd(fd) {
  close(fd, (err) => {
    if (err) throw err;
  });
}

open('message.txt', 'a', (err, fd) => {
  if (err) throw err;

  try {
    appendFile(fd, 'data to append', 'utf8', (err) => {
      closeFd(fd);
      if (err) throw err;
    });
  } catch (err) {
    closeFd(fd);
    throw err;
  }
}); COPY
fs.chmod(path, mode, callback)#
History
path <string> | <Buffer> | <URL>
mode <string> | <integer>
callback <Function>
err <Error>
Asynchronously changes the permissions of a file. No arguments other than a possible exception are given to the completion callback.

See the POSIX chmod(2) documentation for more detail.

import { chmod } from 'node:fs';

chmod('my_file.txt', 0o775, (err) => {
  if (err) throw err;
  console.log('The permissions for file "my_file.txt" have been changed!');
}); COPY
File modes#
The mode argument used in both the fs.chmod() and fs.chmodSync() methods is a numeric bitmask created using a logical OR of the following constants:

Constant	Octal	Description
fs.constants.S_IRUSR	0o400	read by owner
fs.constants.S_IWUSR	0o200	write by owner
fs.constants.S_IXUSR	0o100	execute/search by owner
fs.constants.S_IRGRP	0o40	read by group
fs.constants.S_IWGRP	0o20	write by group
fs.constants.S_IXGRP	0o10	execute/search by group
fs.constants.S_IROTH	0o4	read by others
fs.constants.S_IWOTH	0o2	write by others
fs.constants.S_IXOTH	0o1	execute/search by others
An easier method of constructing the mode is to use a sequence of three octal digits (e.g. 765). The left-most digit (7 in the example), specifies the permissions for the file owner. The middle digit (6 in the example), specifies permissions for the group. The right-most digit (5 in the example), specifies the permissions for others.

Number	Description
7	read, write, and execute
6	read and write
5	read and execute
4	read only
3	write and execute
2	write only
1	execute only
0	no permission
For example, the octal value 0o765 means:

The owner may read, write, and execute the file.
The group may read and write the file.
Others may read and execute the file.
When using raw numbers where file modes are expected, any value larger than 0o777 may result in platform-specific behaviors that are not supported to work consistently. Therefore constants like S_ISVTX, S_ISGID, or S_ISUID are not exposed in fs.constants.

Caveats: on Windows only the write permission can be changed, and the distinction among the permissions of group, owner, or others is not implemented.

fs.chown(path, uid, gid, callback)#
History
path <string> | <Buffer> | <URL>
uid <integer>
gid <integer>
callback <Function>
err <Error>
Asynchronously changes owner and group of a file. No arguments other than a possible exception are given to the completion callback.

See the POSIX chown(2) documentation for more detail.

fs.close(fd[, callback])#
History
fd <integer>
callback <Function>
err <Error>
Closes the file descriptor. No arguments other than a possible exception are given to the completion callback.

Calling fs.close() on any file descriptor (fd) that is currently in use through any other fs operation may lead to undefined behavior.

See the POSIX close(2) documentation for more detail.

fs.copyFile(src, dest[, mode], callback)#
History
src <string> | <Buffer> | <URL> source filename to copy
dest <string> | <Buffer> | <URL> destination filename of the copy operation
mode <integer> modifiers for copy operation. Default: 0.
callback <Function>
err <Error>
Asynchronously copies src to dest. By default, dest is overwritten if it already exists. No arguments other than a possible exception are given to the callback function. Node.js makes no guarantees about the atomicity of the copy operation. If an error occurs after the destination file has been opened for writing, Node.js will attempt to remove the destination.

mode is an optional integer that specifies the behavior of the copy operation. It is possible to create a mask consisting of the bitwise OR of two or more values (e.g. fs.constants.COPYFILE_EXCL | fs.constants.COPYFILE_FICLONE).

fs.constants.COPYFILE_EXCL: The copy operation will fail if dest already exists.
fs.constants.COPYFILE_FICLONE: The copy operation will attempt to create a copy-on-write reflink. If the platform does not support copy-on-write, then a fallback copy mechanism is used.
fs.constants.COPYFILE_FICLONE_FORCE: The copy operation will attempt to create a copy-on-write reflink. If the platform does not support copy-on-write, then the operation will fail.
import { copyFile, constants } from 'node:fs';

function callback(err) {
  if (err) throw err;
  console.log('source.txt was copied to destination.txt');
}

// destination.txt will be created or overwritten by default.
copyFile('source.txt', 'destination.txt', callback);

// By using COPYFILE_EXCL, the operation will fail if destination.txt exists.
copyFile('source.txt', 'destination.txt', constants.COPYFILE_EXCL, callback); COPY
fs.cp(src, dest[, options], callback)#
History
src <string> | <URL> source path to copy.
dest <string> | <URL> destination path to copy to.
options <Object>
dereference <boolean> dereference symlinks. Default: false.
errorOnExist <boolean> when force is false, and the destination exists, throw an error. Default: false.
filter <Function> Function to filter copied files/directories. Return true to copy the item, false to ignore it. When ignoring a directory, all of its contents will be skipped as well. Can also return a Promise that resolves to true or false Default: undefined.
src <string> source path to copy.
dest <string> destination path to copy to.
Returns: <boolean> | <Promise> A value that is coercible to boolean or a Promise that fulfils with such value.
force <boolean> overwrite existing file or directory. The copy operation will ignore errors if you set this to false and the destination exists. Use the errorOnExist option to change this behavior. Default: true.
mode <integer> modifiers for copy operation. Default: 0. See mode flag of fs.copyFile().
preserveTimestamps <boolean> When true timestamps from src will be preserved. Default: false.
recursive <boolean> copy directories recursively Default: false
verbatimSymlinks <boolean> When true, path resolution for symlinks will be skipped. Default: false
callback <Function>
err <Error>
Asynchronously copies the entire directory structure from src to dest, including subdirectories and files.

When copying a directory to another directory, globs are not supported and behavior is similar to cp dir1/ dir2/.

fs.createReadStream(path[, options])#
History
path <string> | <Buffer> | <URL>
options <string> | <Object>
flags <string> See support of file system flags. Default: 'r'.
encoding <string> Default: null
fd <integer> | <FileHandle> Default: null
mode <integer> Default: 0o666
autoClose <boolean> Default: true
emitClose <boolean> Default: true
start <integer>
end <integer> Default: Infinity
highWaterMark <integer> Default: 64 * 1024
fs <Object> | <null> Default: null
signal <AbortSignal> | <null> Default: null
Returns: <fs.ReadStream>
Unlike the 16 KiB default highWaterMark for a <stream.Readable>, the stream returned by this method has a default highWaterMark of 64 KiB.

options can include start and end values to read a range of bytes from the file instead of the entire file. Both start and end are inclusive and start counting at 0, allowed values are in the [0, Number.MAX_SAFE_INTEGER] range. If fd is specified and start is omitted or undefined, fs.createReadStream() reads sequentially from the current file position. The encoding can be any one of those accepted by <Buffer>.

If fd is specified, ReadStream will ignore the path argument and will use the specified file descriptor. This means that no 'open' event will be emitted. fd should be blocking; non-blocking fds should be passed to <net.Socket>.

If fd points to a character device that only supports blocking reads (such as keyboard or sound card), read operations do not finish until data is available. This can prevent the process from exiting and the stream from closing naturally.

By default, the stream will emit a 'close' event after it has been destroyed. Set the emitClose option to false to change this behavior.

By providing the fs option, it is possible to override the corresponding fs implementations for open, read, and close. When providing the fs option, an override for read is required. If no fd is provided, an override for open is also required. If autoClose is true, an override for close is also required.

import { createReadStream } from 'node:fs';

// Create a stream from some character device.
const stream = createReadStream('/dev/input/event0');
setTimeout(() => {
  stream.close(); // This may not close the stream.
  // Artificially marking end-of-stream, as if the underlying resource had
  // indicated end-of-file by itself, allows the stream to close.
  // This does not cancel pending read operations, and if there is such an
  // operation, the process may still not be able to exit successfully
  // until it finishes.
  stream.push(null);
  stream.read(0);
}, 100); COPY
If autoClose is false, then the file descriptor won't be closed, even if there's an error. It is the application's responsibility to close it and make sure there's no file descriptor leak. If autoClose is set to true (default behavior), on 'error' or 'end' the file descriptor will be closed automatically.

mode sets the file mode (permission and sticky bits), but only if the file was created.

An example to read the last 10 bytes of a file which is 100 bytes long:

import { createReadStream } from 'node:fs';

createReadStream('sample.txt', { start: 90, end: 99 }); COPY
If options is a string, then it specifies the encoding.

fs.createWriteStream(path[, options])#
History
path <string> | <Buffer> | <URL>
options <string> | <Object>
flags <string> See support of file system flags. Default: 'w'.
encoding <string> Default: 'utf8'
fd <integer> | <FileHandle> Default: null
mode <integer> Default: 0o666
autoClose <boolean> Default: true
emitClose <boolean> Default: true
start <integer>
fs <Object> | <null> Default: null
signal <AbortSignal> | <null> Default: null
highWaterMark <number> Default: 16384
flush <boolean> If true, the underlying file descriptor is flushed prior to closing it. Default: false.
Returns: <fs.WriteStream>
options may also include a start option to allow writing data at some position past the beginning of the file, allowed values are in the [0, Number.MAX_SAFE_INTEGER] range. Modifying a file rather than replacing it may require the flags option to be set to r+ rather than the default w. The encoding can be any one of those accepted by <Buffer>.

If autoClose is set to true (default behavior) on 'error' or 'finish' the file descriptor will be closed automatically. If autoClose is false, then the file descriptor won't be closed, even if there's an error. It is the application's responsibility to close it and make sure there's no file descriptor leak.

By default, the stream will emit a 'close' event after it has been destroyed. Set the emitClose option to false to change this behavior.

By providing the fs option it is possible to override the corresponding fs implementations for open, write, writev, and close. Overriding write() without writev() can reduce performance as some optimizations (_writev()) will be disabled. When providing the fs option, overrides for at least one of write and writev are required. If no fd option is supplied, an override for open is also required. If autoClose is true, an override for close is also required.

Like <fs.ReadStream>, if fd is specified, <fs.WriteStream> will ignore the path argument and will use the specified file descriptor. This means that no 'open' event will be emitted. fd should be blocking; non-blocking fds should be passed to <net.Socket>.

If options is a string, then it specifies the encoding.

fs.exists(path, callback)#
History
Stability: 0 - Deprecated: Use fs.stat() or fs.access() instead.
path <string> | <Buffer> | <URL>
callback <Function>
exists <boolean>
Test whether or not the given path exists by checking with the file system. Then call the callback argument with either true or false:

import { exists } from 'node:fs';

exists('/etc/passwd', (e) => {
  console.log(e ? 'it exists' : 'no passwd!');
}); COPY
The parameters for this callback are not consistent with other Node.js callbacks. Normally, the first parameter to a Node.js callback is an err parameter, optionally followed by other parameters. The fs.exists() callback has only one boolean parameter. This is one reason fs.access() is recommended instead of fs.exists().

Using fs.exists() to check for the existence of a file before calling fs.open(), fs.readFile(), or fs.writeFile() is not recommended. Doing so introduces a race condition, since other processes may change the file's state between the two calls. Instead, user code should open/read/write the file directly and handle the error raised if the file does not exist.

write (NOT RECOMMENDED)

import { exists, open, close } from 'node:fs';

exists('myfile', (e) => {
  if (e) {
    console.error('myfile already exists');
  } else {
    open('myfile', 'wx', (err, fd) => {
      if (err) throw err;

      try {
        writeMyData(fd);
      } finally {
        close(fd, (err) => {
          if (err) throw err;
        });
      }
    });
  }
}); COPY
write (RECOMMENDED)

import { open, close } from 'node:fs';
open('myfile', 'wx', (err, fd) => {
  if (err) {
    if (err.code === 'EEXIST') {
      console.error('myfile already exists');
      return;
    }

    throw err;
  }

  try {
    writeMyData(fd);
  } finally {
    close(fd, (err) => {
      if (err) throw err;
    });
  }
}); COPY
read (NOT RECOMMENDED)

import { open, close, exists } from 'node:fs';

exists('myfile', (e) => {
  if (e) {
    open('myfile', 'r', (err, fd) => {
      if (err) throw err;

      try {
        readMyData(fd);
      } finally {
        close(fd, (err) => {
          if (err) throw err;
        });
      }
    });
  } else {
    console.error('myfile does not exist');
  }
}); COPY
read (RECOMMENDED)

import { open, close } from 'node:fs';

open('myfile', 'r', (err, fd) => {
  if (err) {
    if (err.code === 'ENOENT') {
      console.error('myfile does not exist');
      return;
    }

    throw err;
  }

  try {
    readMyData(fd);
  } finally {
    close(fd, (err) => {
      if (err) throw err;
    });
  }
}); COPY
The "not recommended" examples above check for existence and then use the file; the "recommended" examples are better because they use the file directly and handle the error, if any.

In general, check for the existence of a file only if the file won't be used directly, for example when its existence is a signal from another process.

fs.fchmod(fd, mode, callback)#
History
fd <integer>
mode <string> | <integer>
callback <Function>
err <Error>
Sets the permissions on the file. No arguments other than a possible exception are given to the completion callback.

See the POSIX fchmod(2) documentation for more detail.

fs.fchown(fd, uid, gid, callback)#
History
fd <integer>
uid <integer>
gid <integer>
callback <Function>
err <Error>
Sets the owner of the file. No arguments other than a possible exception are given to the completion callback.

See the POSIX fchown(2) documentation for more detail.

fs.fdatasync(fd, callback)#
History
fd <integer>
callback <Function>
err <Error>
Forces all currently queued I/O operations associated with the file to the operating system's synchronized I/O completion state. Refer to the POSIX fdatasync(2) documentation for details. No arguments other than a possible exception are given to the completion callback.

fs.fstat(fd[, options], callback)#
History
fd <integer>
options <Object>
bigint <boolean> Whether the numeric values in the returned <fs.Stats> object should be bigint. Default: false.
callback <Function>
err <Error>
stats <fs.Stats>
Invokes the callback with the <fs.Stats> for the file descriptor.

See the POSIX fstat(2) documentation for more detail.

fs.fsync(fd, callback)#
History
fd <integer>
callback <Function>
err <Error>
Request that all data for the open file descriptor is flushed to the storage device. The specific implementation is operating system and device specific. Refer to the POSIX fsync(2) documentation for more detail. No arguments other than a possible exception are given to the completion callback.

fs.ftruncate(fd[, len], callback)#
History
fd <integer>
len <integer> Default: 0
callback <Function>
err <Error>
Truncates the file descriptor. No arguments other than a possible exception are given to the completion callback.

See the POSIX ftruncate(2) documentation for more detail.

If the file referred to by the file descriptor was larger than len bytes, only the first len bytes will be retained in the file.

For example, the following program retains only the first four bytes of the file:

import { open, close, ftruncate } from 'node:fs';

function closeFd(fd) {
  close(fd, (err) => {
    if (err) throw err;
  });
}

open('temp.txt', 'r+', (err, fd) => {
  if (err) throw err;

  try {
    ftruncate(fd, 4, (err) => {
      closeFd(fd);
      if (err) throw err;
    });
  } catch (err) {
    closeFd(fd);
    if (err) throw err;
  }
}); COPY
If the file previously was shorter than len bytes, it is extended, and the extended part is filled with null bytes ('\0'):

If len is negative then 0 will be used.

fs.futimes(fd, atime, mtime, callback)#
History
fd <integer>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
callback <Function>
err <Error>
Change the file system timestamps of the object referenced by the supplied file descriptor. See fs.utimes().

fs.glob(pattern[, options], callback)#
History
Stability: 1 - Experimental
pattern <string> | <string[]>

options <Object>

cwd <string> current working directory. Default: process.cwd()
exclude <Function> Function to filter out files/directories. Return true to exclude the item, false to include it. Default: undefined.
withFileTypes <boolean> true if the glob should return paths as Dirents, false otherwise. Default: false.
callback <Function>

err <Error>
Retrieves the files matching the specified pattern.

const { glob } = require('node:fs');

glob('**/*.js', (err, matches) => {
  if (err) throw err;
  console.log(matches);
});COPY
fs.lchmod(path, mode, callback)#
History
path <string> | <Buffer> | <URL>
mode <integer>
callback <Function>
err <Error> | <AggregateError>
Changes the permissions on a symbolic link. No arguments other than a possible exception are given to the completion callback.

This method is only implemented on macOS.

See the POSIX lchmod(2) documentation for more detail.

fs.lchown(path, uid, gid, callback)#
History
path <string> | <Buffer> | <URL>
uid <integer>
gid <integer>
callback <Function>
err <Error>
Set the owner of the symbolic link. No arguments other than a possible exception are given to the completion callback.

See the POSIX lchown(2) documentation for more detail.

fs.lutimes(path, atime, mtime, callback)#
History
path <string> | <Buffer> | <URL>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
callback <Function>
err <Error>
Changes the access and modification times of a file in the same way as fs.utimes(), with the difference that if the path refers to a symbolic link, then the link is not dereferenced: instead, the timestamps of the symbolic link itself are changed.

No arguments other than a possible exception are given to the completion callback.

fs.link(existingPath, newPath, callback)#
History
existingPath <string> | <Buffer> | <URL>
newPath <string> | <Buffer> | <URL>
callback <Function>
err <Error>
Creates a new link from the existingPath to the newPath. See the POSIX link(2) documentation for more detail. No arguments other than a possible exception are given to the completion callback.

fs.lstat(path[, options], callback)#
History
path <string> | <Buffer> | <URL>
options <Object>
bigint <boolean> Whether the numeric values in the returned <fs.Stats> object should be bigint. Default: false.
callback <Function>
err <Error>
stats <fs.Stats>
Retrieves the <fs.Stats> for the symbolic link referred to by the path. The callback gets two arguments (err, stats) where stats is a <fs.Stats> object. lstat() is identical to stat(), except that if path is a symbolic link, then the link itself is stat-ed, not the file that it refers to.

See the POSIX lstat(2) documentation for more details.

fs.mkdir(path[, options], callback)#
History
path <string> | <Buffer> | <URL>
options <Object> | <integer>
recursive <boolean> Default: false
mode <string> | <integer> Not supported on Windows. Default: 0o777.
callback <Function>
err <Error>
path <string> | <undefined> Present only if a directory is created with recursive set to true.
Asynchronously creates a directory.

The callback is given a possible exception and, if recursive is true, the first directory path created, (err[, path]). path can still be undefined when recursive is true, if no directory was created (for instance, if it was previously created).

The optional options argument can be an integer specifying mode (permission and sticky bits), or an object with a mode property and a recursive property indicating whether parent directories should be created. Calling fs.mkdir() when path is a directory that exists results in an error only when recursive is false. If recursive is false and the directory exists, an EEXIST error occurs.

import { mkdir } from 'node:fs';

// Create ./tmp/a/apple, regardless of whether ./tmp and ./tmp/a exist.
mkdir('./tmp/a/apple', { recursive: true }, (err) => {
  if (err) throw err;
}); COPY
On Windows, using fs.mkdir() on the root directory even with recursion will result in an error:

import { mkdir } from 'node:fs';

mkdir('/', { recursive: true }, (err) => {
  // => [Error: EPERM: operation not permitted, mkdir 'C:\']
}); COPY
See the POSIX mkdir(2) documentation for more details.

fs.mkdtemp(prefix[, options], callback)#
History
prefix <string> | <Buffer> | <URL>
options <string> | <Object>
encoding <string> Default: 'utf8'
callback <Function>
err <Error>
directory <string>
Creates a unique temporary directory.

Generates six random characters to be appended behind a required prefix to create a unique temporary directory. Due to platform inconsistencies, avoid trailing X characters in prefix. Some platforms, notably the BSDs, can return more than six random characters, and replace trailing X characters in prefix with random characters.

The created directory path is passed as a string to the callback's second parameter.

The optional options argument can be a string specifying an encoding, or an object with an encoding property specifying the character encoding to use.

import { mkdtemp } from 'node:fs';
import { join } from 'node:path';
import { tmpdir } from 'node:os';

mkdtemp(join(tmpdir(), 'foo-'), (err, directory) => {
  if (err) throw err;
  console.log(directory);
  // Prints: /tmp/foo-itXde2 or C:\Users\...\AppData\Local\Temp\foo-itXde2
}); COPY
The fs.mkdtemp() method will append the six randomly selected characters directly to the prefix string. For instance, given a directory /tmp, if the intention is to create a temporary directory within /tmp, the prefix must end with a trailing platform-specific path separator (require('node:path').sep).

import { tmpdir } from 'node:os';
import { mkdtemp } from 'node:fs';

// The parent directory for the new temporary directory
const tmpDir = tmpdir();

// This method is *INCORRECT*:
mkdtemp(tmpDir, (err, directory) => {
  if (err) throw err;
  console.log(directory);
  // Will print something similar to `/tmpabc123`.
  // A new temporary directory is created at the file system root
  // rather than *within* the /tmp directory.
});

// This method is *CORRECT*:
import { sep } from 'node:path';
mkdtemp(`${tmpDir}${sep}`, (err, directory) => {
  if (err) throw err;
  console.log(directory);
  // Will print something similar to `/tmp/abc123`.
  // A new temporary directory is created within
  // the /tmp directory.
}); COPY
fs.open(path[, flags[, mode]], callback)#
History
path <string> | <Buffer> | <URL>
flags <string> | <number> See support of file system flags. Default: 'r'.
mode <string> | <integer> Default: 0o666 (readable and writable)
callback <Function>
err <Error>
fd <integer>
Asynchronous file open. See the POSIX open(2) documentation for more details.

mode sets the file mode (permission and sticky bits), but only if the file was created. On Windows, only the write permission can be manipulated; see fs.chmod().

The callback gets two arguments (err, fd).

Some characters (< > : " / \ | ? *) are reserved under Windows as documented by Naming Files, Paths, and Namespaces. Under NTFS, if the filename contains a colon, Node.js will open a file system stream, as described by this MSDN page.

Functions based on fs.open() exhibit this behavior as well: fs.writeFile(), fs.readFile(), etc.

fs.openAsBlob(path[, options])#
Added in: v19.8.0
Stability: 1 - Experimental
path <string> | <Buffer> | <URL>
options <Object>
type <string> An optional mime type for the blob.
Returns: <Promise> Fulfills with a <Blob> upon success.
Returns a <Blob> whose data is backed by the given file.

The file must not be modified after the <Blob> is created. Any modifications will cause reading the <Blob> data to fail with a DOMException error. Synchronous stat operations on the file when the Blob is created, and before each read in order to detect whether the file data has been modified on disk.

const { openAsBlob } = require('node:fs');

(async () => {
  const blob = await openAsBlob('the.file.txt');
  const ab = await blob.arrayBuffer();
  blob.stream();
})();COPY
fs.opendir(path[, options], callback)#
History
path <string> | <Buffer> | <URL>
options <Object>
encoding <string> | <null> Default: 'utf8'
bufferSize <number> Number of directory entries that are buffered internally when reading from the directory. Higher values lead to better performance but higher memory usage. Default: 32
recursive <boolean> Default: false
callback <Function>
err <Error>
dir <fs.Dir>
Asynchronously open a directory. See the POSIX opendir(3) documentation for more details.

Creates an <fs.Dir>, which contains all further functions for reading from and cleaning up the directory.

The encoding option sets the encoding for the path while opening the directory and subsequent read operations.

fs.read(fd, buffer, offset, length, position, callback)#
History
fd <integer>
buffer <Buffer> | <TypedArray> | <DataView> The buffer that the data will be written to.
offset <integer> The position in buffer to write the data to.
length <integer> The number of bytes to read.
position <integer> | <bigint> | <null> Specifies where to begin reading from in the file. If position is null or -1 , data will be read from the current file position, and the file position will be updated. If position is a non-negative integer, the file position will be unchanged.
callback <Function>
err <Error>
bytesRead <integer>
buffer <Buffer>
Read data from the file specified by fd.

The callback is given the three arguments, (err, bytesRead, buffer).

If the file is not modified concurrently, the end-of-file is reached when the number of bytes read is zero.

If this method is invoked as its util.promisify()ed version, it returns a promise for an Object with bytesRead and buffer properties.

The fs.read() method reads data from the file specified by the file descriptor (fd). The length argument indicates the maximum number of bytes that Node.js will attempt to read from the kernel. However, the actual number of bytes read (bytesRead) can be lower than the specified length for various reasons.

For example:

If the file is shorter than the specified length, bytesRead will be set to the actual number of bytes read.
If the file encounters EOF (End of File) before the buffer could be filled, Node.js will read all available bytes until EOF is encountered, and the bytesRead parameter in the callback will indicate the actual number of bytes read, which may be less than the specified length.
If the file is on a slow network filesystem or encounters any other issue during reading, bytesRead can be lower than the specified length.
Therefore, when using fs.read(), it's important to check the bytesRead value to determine how many bytes were actually read from the file. Depending on your application logic, you may need to handle cases where bytesRead is lower than the specified length, such as by wrapping the read call in a loop if you require a minimum amount of bytes.

This behavior is similar to the POSIX preadv2 function.

fs.read(fd[, options], callback)#
History
fd <integer>
options <Object>
buffer <Buffer> | <TypedArray> | <DataView> Default: Buffer.alloc(16384)
offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <bigint> | <null> Default: null
callback <Function>
err <Error>
bytesRead <integer>
buffer <Buffer>
Similar to the fs.read() function, this version takes an optional options object. If no options object is specified, it will default with the above values.

fs.read(fd, buffer[, options], callback)#
Added in: v18.2.0, v16.17.0
fd <integer>
buffer <Buffer> | <TypedArray> | <DataView> The buffer that the data will be written to.
options <Object>
offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <bigint> Default: null
callback <Function>
err <Error>
bytesRead <integer>
buffer <Buffer>
Similar to the fs.read() function, this version takes an optional options object. If no options object is specified, it will default with the above values.

fs.readdir(path[, options], callback)#
History
path <string> | <Buffer> | <URL>
options <string> | <Object>
encoding <string> Default: 'utf8'
withFileTypes <boolean> Default: false
recursive <boolean> If true, reads the contents of a directory recursively. In recursive mode, it will list all files, sub files and directories. Default: false.
callback <Function>
err <Error>
files <string[]> | <Buffer[]> | <fs.Dirent[]>
Reads the contents of a directory. The callback gets two arguments (err, files) where files is an array of the names of the files in the directory excluding '.' and '..'.

See the POSIX readdir(3) documentation for more details.

The optional options argument can be a string specifying an encoding, or an object with an encoding property specifying the character encoding to use for the filenames passed to the callback. If the encoding is set to 'buffer', the filenames returned will be passed as <Buffer> objects.

If options.withFileTypes is set to true, the files array will contain <fs.Dirent> objects.

fs.readFile(path[, options], callback)#
History
path <string> | <Buffer> | <URL> | <integer> filename or file descriptor
options <Object> | <string>
encoding <string> | <null> Default: null
flag <string> See support of file system flags. Default: 'r'.
signal <AbortSignal> allows aborting an in-progress readFile
callback <Function>
err <Error> | <AggregateError>
data <string> | <Buffer>
Asynchronously reads the entire contents of a file.

import { readFile } from 'node:fs';

readFile('/etc/passwd', (err, data) => {
  if (err) throw err;
  console.log(data);
}); COPY
The callback is passed two arguments (err, data), where data is the contents of the file.

If no encoding is specified, then the raw buffer is returned.

If options is a string, then it specifies the encoding:

import { readFile } from 'node:fs';

readFile('/etc/passwd', 'utf8', callback); COPY
When the path is a directory, the behavior of fs.readFile() and fs.readFileSync() is platform-specific. On macOS, Linux, and Windows, an error will be returned. On FreeBSD, a representation of the directory's contents will be returned.

import { readFile } from 'node:fs';

// macOS, Linux, and Windows
readFile('<directory>', (err, data) => {
  // => [Error: EISDIR: illegal operation on a directory, read <directory>]
});

//  FreeBSD
readFile('<directory>', (err, data) => {
  // => null, <data>
}); COPY
It is possible to abort an ongoing request using an AbortSignal. If a request is aborted the callback is called with an AbortError:

import { readFile } from 'node:fs';

const controller = new AbortController();
const signal = controller.signal;
readFile(fileInfo[0].name, { signal }, (err, buf) => {
  // ...
});
// When you want to abort the request
controller.abort(); COPY
The fs.readFile() function buffers the entire file. To minimize memory costs, when possible prefer streaming via fs.createReadStream().

Aborting an ongoing request does not abort individual operating system requests but rather the internal buffering fs.readFile performs.

File descriptors#
Any specified file descriptor has to support reading.
If a file descriptor is specified as the path, it will not be closed automatically.
The reading will begin at the current position. For example, if the file already had 'Hello World' and six bytes are read with the file descriptor, the call to fs.readFile() with the same file descriptor, would give 'World', rather than 'Hello World'.
Performance Considerations#
The fs.readFile() method asynchronously reads the contents of a file into memory one chunk at a time, allowing the event loop to turn between each chunk. This allows the read operation to have less impact on other activity that may be using the underlying libuv thread pool but means that it will take longer to read a complete file into memory.

The additional read overhead can vary broadly on different systems and depends on the type of file being read. If the file type is not a regular file (a pipe for instance) and Node.js is unable to determine an actual file size, each read operation will load on 64 KiB of data. For regular files, each read will process 512 KiB of data.

For applications that require as-fast-as-possible reading of file contents, it is better to use fs.read() directly and for application code to manage reading the full contents of the file itself.

The Node.js GitHub issue #25741 provides more information and a detailed analysis on the performance of fs.readFile() for multiple file sizes in different Node.js versions.

fs.readlink(path[, options], callback)#
History
path <string> | <Buffer> | <URL>
options <string> | <Object>
encoding <string> Default: 'utf8'
callback <Function>
err <Error>
linkString <string> | <Buffer>
Reads the contents of the symbolic link referred to by path. The callback gets two arguments (err, linkString).

See the POSIX readlink(2) documentation for more details.

The optional options argument can be a string specifying an encoding, or an object with an encoding property specifying the character encoding to use for the link path passed to the callback. If the encoding is set to 'buffer', the link path returned will be passed as a <Buffer> object.

fs.readv(fd, buffers[, position], callback)#
History
fd <integer>
buffers <ArrayBufferView[]>
position <integer> | <null> Default: null
callback <Function>
err <Error>
bytesRead <integer>
buffers <ArrayBufferView[]>
Read from a file specified by fd and write to an array of ArrayBufferViews using readv().

position is the offset from the beginning of the file from where data should be read. If typeof position !== 'number', the data will be read from the current position.

The callback will be given three arguments: err, bytesRead, and buffers. bytesRead is how many bytes were read from the file.

If this method is invoked as its util.promisify()ed version, it returns a promise for an Object with bytesRead and buffers properties.

fs.realpath(path[, options], callback)#
History
path <string> | <Buffer> | <URL>
options <string> | <Object>
encoding <string> Default: 'utf8'
callback <Function>
err <Error>
resolvedPath <string> | <Buffer>
Asynchronously computes the canonical pathname by resolving ., .., and symbolic links.

A canonical pathname is not necessarily unique. Hard links and bind mounts can expose a file system entity through many pathnames.

This function behaves like realpath(3), with some exceptions:

No case conversion is performed on case-insensitive file systems.

The maximum number of symbolic links is platform-independent and generally (much) higher than what the native realpath(3) implementation supports.

The callback gets two arguments (err, resolvedPath). May use process.cwd to resolve relative paths.

Only paths that can be converted to UTF8 strings are supported.

The optional options argument can be a string specifying an encoding, or an object with an encoding property specifying the character encoding to use for the path passed to the callback. If the encoding is set to 'buffer', the path returned will be passed as a <Buffer> object.

If path resolves to a socket or a pipe, the function will return a system dependent name for that object.

A path that does not exist results in an ENOENT error. error.path is the absolute file path.

fs.realpath.native(path[, options], callback)#
History
path <string> | <Buffer> | <URL>
options <string> | <Object>
encoding <string> Default: 'utf8'
callback <Function>
err <Error>
resolvedPath <string> | <Buffer>
Asynchronous realpath(3).

The callback gets two arguments (err, resolvedPath).

Only paths that can be converted to UTF8 strings are supported.

The optional options argument can be a string specifying an encoding, or an object with an encoding property specifying the character encoding to use for the path passed to the callback. If the encoding is set to 'buffer', the path returned will be passed as a <Buffer> object.

On Linux, when Node.js is linked against musl libc, the procfs file system must be mounted on /proc in order for this function to work. Glibc does not have this restriction.

fs.rename(oldPath, newPath, callback)#
History
oldPath <string> | <Buffer> | <URL>
newPath <string> | <Buffer> | <URL>
callback <Function>
err <Error>
Asynchronously rename file at oldPath to the pathname provided as newPath. In the case that newPath already exists, it will be overwritten. If there is a directory at newPath, an error will be raised instead. No arguments other than a possible exception are given to the completion callback.

See also: rename(2).

import { rename } from 'node:fs';

rename('oldFile.txt', 'newFile.txt', (err) => {
  if (err) throw err;
  console.log('Rename complete!');
}); COPY
fs.rmdir(path[, options], callback)#
History
path <string> | <Buffer> | <URL>
options <Object>
maxRetries <integer> If an EBUSY, EMFILE, ENFILE, ENOTEMPTY, or EPERM error is encountered, Node.js retries the operation with a linear backoff wait of retryDelay milliseconds longer on each try. This option represents the number of retries. This option is ignored if the recursive option is not true. Default: 0.
recursive <boolean> If true, perform a recursive directory removal. In recursive mode, operations are retried on failure. Default: false. Deprecated.
retryDelay <integer> The amount of time in milliseconds to wait between retries. This option is ignored if the recursive option is not true. Default: 100.
callback <Function>
err <Error>
Asynchronous rmdir(2). No arguments other than a possible exception are given to the completion callback.

Using fs.rmdir() on a file (not a directory) results in an ENOENT error on Windows and an ENOTDIR error on POSIX.

To get a behavior similar to the rm -rf Unix command, use fs.rm() with options { recursive: true, force: true }.

fs.rm(path[, options], callback)#
History
path <string> | <Buffer> | <URL>
options <Object>
force <boolean> When true, exceptions will be ignored if path does not exist. Default: false.
maxRetries <integer> If an EBUSY, EMFILE, ENFILE, ENOTEMPTY, or EPERM error is encountered, Node.js will retry the operation with a linear backoff wait of retryDelay milliseconds longer on each try. This option represents the number of retries. This option is ignored if the recursive option is not true. Default: 0.
recursive <boolean> If true, perform a recursive removal. In recursive mode operations are retried on failure. Default: false.
retryDelay <integer> The amount of time in milliseconds to wait between retries. This option is ignored if the recursive option is not true. Default: 100.
callback <Function>
err <Error>
Asynchronously removes files and directories (modeled on the standard POSIX rm utility). No arguments other than a possible exception are given to the completion callback.

fs.stat(path[, options], callback)#
History
path <string> | <Buffer> | <URL>
options <Object>
bigint <boolean> Whether the numeric values in the returned <fs.Stats> object should be bigint. Default: false.
callback <Function>
err <Error>
stats <fs.Stats>
Asynchronous stat(2). The callback gets two arguments (err, stats) where stats is an <fs.Stats> object.

In case of an error, the err.code will be one of Common System Errors.

fs.stat() follows symbolic links. Use fs.lstat() to look at the links themselves.

Using fs.stat() to check for the existence of a file before calling fs.open(), fs.readFile(), or fs.writeFile() is not recommended. Instead, user code should open/read/write the file directly and handle the error raised if the file is not available.

To check if a file exists without manipulating it afterwards, fs.access() is recommended.

For example, given the following directory structure:

- txtDir
-- file.txt
- app.js COPY
The next program will check for the stats of the given paths:

import { stat } from 'node:fs';

const pathsToCheck = ['./txtDir', './txtDir/file.txt'];

for (let i = 0; i < pathsToCheck.length; i++) {
  stat(pathsToCheck[i], (err, stats) => {
    console.log(stats.isDirectory());
    console.log(stats);
  });
} COPY
The resulting output will resemble:

true
Stats {
  dev: 16777220,
  mode: 16877,
  nlink: 3,
  uid: 501,
  gid: 20,
  rdev: 0,
  blksize: 4096,
  ino: 14214262,
  size: 96,
  blocks: 0,
  atimeMs: 1561174653071.963,
  mtimeMs: 1561174614583.3518,
  ctimeMs: 1561174626623.5366,
  birthtimeMs: 1561174126937.2893,
  atime: 2019-06-22T03:37:33.072Z,
  mtime: 2019-06-22T03:36:54.583Z,
  ctime: 2019-06-22T03:37:06.624Z,
  birthtime: 2019-06-22T03:28:46.937Z
}
false
Stats {
  dev: 16777220,
  mode: 33188,
  nlink: 1,
  uid: 501,
  gid: 20,
  rdev: 0,
  blksize: 4096,
  ino: 14214074,
  size: 8,
  blocks: 8,
  atimeMs: 1561174616618.8555,
  mtimeMs: 1561174614584,
  ctimeMs: 1561174614583.8145,
  birthtimeMs: 1561174007710.7478,
  atime: 2019-06-22T03:36:56.619Z,
  mtime: 2019-06-22T03:36:54.584Z,
  ctime: 2019-06-22T03:36:54.584Z,
  birthtime: 2019-06-22T03:26:47.711Z
} COPY
fs.statfs(path[, options], callback)#
Added in: v19.6.0, v18.15.0
path <string> | <Buffer> | <URL>
options <Object>
bigint <boolean> Whether the numeric values in the returned <fs.StatFs> object should be bigint. Default: false.
callback <Function>
err <Error>
stats <fs.StatFs>
Asynchronous statfs(2). Returns information about the mounted file system which contains path. The callback gets two arguments (err, stats) where stats is an <fs.StatFs> object.

In case of an error, the err.code will be one of Common System Errors.

fs.symlink(target, path[, type], callback)#
History
target <string> | <Buffer> | <URL>
path <string> | <Buffer> | <URL>
type <string> | <null> Default: null
callback <Function>
err <Error>
Creates the link called path pointing to target. No arguments other than a possible exception are given to the completion callback.

See the POSIX symlink(2) documentation for more details.

The type argument is only available on Windows and ignored on other platforms. It can be set to 'dir', 'file', or 'junction'. If the type argument is not a string, Node.js will autodetect target type and use 'file' or 'dir'. If the target does not exist, 'file' will be used. Windows junction points require the destination path to be absolute. When using 'junction', the target argument will automatically be normalized to absolute path. Junction points on NTFS volumes can only point to directories.

Relative targets are relative to the link's parent directory.

import { symlink } from 'node:fs';

symlink('./mew', './mewtwo', callback); COPY
The above example creates a symbolic link mewtwo which points to mew in the same directory:

$ tree .
.
â”œâ”€â”€ mew
â””â”€â”€ mewtwo -> ./mew COPY
fs.truncate(path[, len], callback)#
History
path <string> | <Buffer> | <URL>
len <integer> Default: 0
callback <Function>
err <Error> | <AggregateError>
Truncates the file. No arguments other than a possible exception are given to the completion callback. A file descriptor can also be passed as the first argument. In this case, fs.ftruncate() is called.

const { truncate } = require('node:fs');
// Assuming that 'path/file.txt' is a regular file.
truncate('path/file.txt', (err) => {
  if (err) throw err;
  console.log('path/file.txt was truncated');
});COPY
Passing a file descriptor is deprecated and may result in an error being thrown in the future.

See the POSIX truncate(2) documentation for more details.

fs.unlink(path, callback)#
History
path <string> | <Buffer> | <URL>
callback <Function>
err <Error>
Asynchronously removes a file or symbolic link. No arguments other than a possible exception are given to the completion callback.

import { unlink } from 'node:fs';
// Assuming that 'path/file.txt' is a regular file.
unlink('path/file.txt', (err) => {
  if (err) throw err;
  console.log('path/file.txt was deleted');
}); COPY
fs.unlink() will not work on a directory, empty or otherwise. To remove a directory, use fs.rmdir().

See the POSIX unlink(2) documentation for more details.

fs.unwatchFile(filename[, listener])#
Added in: v0.1.31
filename <string> | <Buffer> | <URL>
listener <Function> Optional, a listener previously attached using fs.watchFile()
Stop watching for changes on filename. If listener is specified, only that particular listener is removed. Otherwise, all listeners are removed, effectively stopping watching of filename.

Calling fs.unwatchFile() with a filename that is not being watched is a no-op, not an error.

Using fs.watch() is more efficient than fs.watchFile() and fs.unwatchFile(). fs.watch() should be used instead of fs.watchFile() and fs.unwatchFile() when possible.

fs.utimes(path, atime, mtime, callback)#
History
path <string> | <Buffer> | <URL>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
callback <Function>
err <Error>
Change the file system timestamps of the object referenced by path.

The atime and mtime arguments follow these rules:

Values can be either numbers representing Unix epoch time in seconds, Dates, or a numeric string like '123456789.0'.
If the value can not be converted to a number, or is NaN, Infinity, or -Infinity, an Error will be thrown.
fs.watch(filename[, options][, listener])#
History
filename <string> | <Buffer> | <URL>
options <string> | <Object>
persistent <boolean> Indicates whether the process should continue to run as long as files are being watched. Default: true.
recursive <boolean> Indicates whether all subdirectories should be watched, or only the current directory. This applies when a directory is specified, and only on supported platforms (See caveats). Default: false.
encoding <string> Specifies the character encoding to be used for the filename passed to the listener. Default: 'utf8'.
signal <AbortSignal> allows closing the watcher with an AbortSignal.
listener <Function> | <undefined> Default: undefined
eventType <string>
filename <string> | <Buffer> | <null>
Returns: <fs.FSWatcher>
Watch for changes on filename, where filename is either a file or a directory.

The second argument is optional. If options is provided as a string, it specifies the encoding. Otherwise options should be passed as an object.

The listener callback gets two arguments (eventType, filename). eventType is either 'rename' or 'change', and filename is the name of the file which triggered the event.

On most platforms, 'rename' is emitted whenever a filename appears or disappears in the directory.

The listener callback is attached to the 'change' event fired by <fs.FSWatcher>, but it is not the same thing as the 'change' value of eventType.

If a signal is passed, aborting the corresponding AbortController will close the returned <fs.FSWatcher>.

Caveats#
The fs.watch API is not 100% consistent across platforms, and is unavailable in some situations.

On Windows, no events will be emitted if the watched directory is moved or renamed. An EPERM error is reported when the watched directory is deleted.

Availability#
This feature depends on the underlying operating system providing a way to be notified of file system changes.

On Linux systems, this uses inotify(7).
On BSD systems, this uses kqueue(2).
On macOS, this uses kqueue(2) for files and FSEvents for directories.
On SunOS systems (including Solaris and SmartOS), this uses event ports.
On Windows systems, this feature depends on ReadDirectoryChangesW.
On AIX systems, this feature depends on AHAFS, which must be enabled.
On IBM i systems, this feature is not supported.
If the underlying functionality is not available for some reason, then fs.watch() will not be able to function and may throw an exception. For example, watching files or directories can be unreliable, and in some cases impossible, on network file systems (NFS, SMB, etc) or host file systems when using virtualization software such as Vagrant or Docker.

It is still possible to use fs.watchFile(), which uses stat polling, but this method is slower and less reliable.

Inodes#
On Linux and macOS systems, fs.watch() resolves the path to an inode and watches the inode. If the watched path is deleted and recreated, it is assigned a new inode. The watch will emit an event for the delete but will continue watching the original inode. Events for the new inode will not be emitted. This is expected behavior.

AIX files retain the same inode for the lifetime of a file. Saving and closing a watched file on AIX will result in two notifications (one for adding new content, and one for truncation).

Filename argument#
Providing filename argument in the callback is only supported on Linux, macOS, Windows, and AIX. Even on supported platforms, filename is not always guaranteed to be provided. Therefore, don't assume that filename argument is always provided in the callback, and have some fallback logic if it is null.

import { watch } from 'node:fs';
watch('somedir', (eventType, filename) => {
  console.log(`event type is: ${eventType}`);
  if (filename) {
    console.log(`filename provided: ${filename}`);
  } else {
    console.log('filename not provided');
  }
}); COPY
fs.watchFile(filename[, options], listener)#
History
filename <string> | <Buffer> | <URL>
options <Object>
bigint <boolean> Default: false
persistent <boolean> Default: true
interval <integer> Default: 5007
listener <Function>
current <fs.Stats>
previous <fs.Stats>
Returns: <fs.StatWatcher>
Watch for changes on filename. The callback listener will be called each time the file is accessed.

The options argument may be omitted. If provided, it should be an object. The options object may contain a boolean named persistent that indicates whether the process should continue to run as long as files are being watched. The options object may specify an interval property indicating how often the target should be polled in milliseconds.

The listener gets two arguments the current stat object and the previous stat object:

import { watchFile } from 'node:fs';

watchFile('message.text', (curr, prev) => {
  console.log(`the current mtime is: ${curr.mtime}`);
  console.log(`the previous mtime was: ${prev.mtime}`);
}); COPY
These stat objects are instances of fs.Stat. If the bigint option is true, the numeric values in these objects are specified as BigInts.

To be notified when the file was modified, not just accessed, it is necessary to compare curr.mtimeMs and prev.mtimeMs.

When an fs.watchFile operation results in an ENOENT error, it will invoke the listener once, with all the fields zeroed (or, for dates, the Unix Epoch). If the file is created later on, the listener will be called again, with the latest stat objects. This is a change in functionality since v0.10.

Using fs.watch() is more efficient than fs.watchFile and fs.unwatchFile. fs.watch should be used instead of fs.watchFile and fs.unwatchFile when possible.

When a file being watched by fs.watchFile() disappears and reappears, then the contents of previous in the second callback event (the file's reappearance) will be the same as the contents of previous in the first callback event (its disappearance).

This happens when:

the file is deleted, followed by a restore
the file is renamed and then renamed a second time back to its original name
fs.write(fd, buffer, offset[, length[, position]], callback)#
History
fd <integer>
buffer <Buffer> | <TypedArray> | <DataView>
offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <null> Default: null
callback <Function>
err <Error>
bytesWritten <integer>
buffer <Buffer> | <TypedArray> | <DataView>
Write buffer to the file specified by fd.

offset determines the part of the buffer to be written, and length is an integer specifying the number of bytes to write.

position refers to the offset from the beginning of the file where this data should be written. If typeof position !== 'number', the data will be written at the current position. See pwrite(2).

The callback will be given three arguments (err, bytesWritten, buffer) where bytesWritten specifies how many bytes were written from buffer.

If this method is invoked as its util.promisify()ed version, it returns a promise for an Object with bytesWritten and buffer properties.

It is unsafe to use fs.write() multiple times on the same file without waiting for the callback. For this scenario, fs.createWriteStream() is recommended.

On Linux, positional writes don't work when the file is opened in append mode. The kernel ignores the position argument and always appends the data to the end of the file.

fs.write(fd, buffer[, options], callback)#
Added in: v18.3.0, v16.17.0
fd <integer>
buffer <Buffer> | <TypedArray> | <DataView>
options <Object>
offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> Default: null
callback <Function>
err <Error>
bytesWritten <integer>
buffer <Buffer> | <TypedArray> | <DataView>
Write buffer to the file specified by fd.

Similar to the above fs.write function, this version takes an optional options object. If no options object is specified, it will default with the above values.

fs.write(fd, string[, position[, encoding]], callback)#
History
fd <integer>
string <string>
position <integer> | <null> Default: null
encoding <string> Default: 'utf8'
callback <Function>
err <Error>
written <integer>
string <string>
Write string to the file specified by fd. If string is not a string, an exception is thrown.

position refers to the offset from the beginning of the file where this data should be written. If typeof position !== 'number' the data will be written at the current position. See pwrite(2).

encoding is the expected string encoding.

The callback will receive the arguments (err, written, string) where written specifies how many bytes the passed string required to be written. Bytes written is not necessarily the same as string characters written. See Buffer.byteLength.

It is unsafe to use fs.write() multiple times on the same file without waiting for the callback. For this scenario, fs.createWriteStream() is recommended.

On Linux, positional writes don't work when the file is opened in append mode. The kernel ignores the position argument and always appends the data to the end of the file.

On Windows, if the file descriptor is connected to the console (e.g. fd == 1 or stdout) a string containing non-ASCII characters will not be rendered properly by default, regardless of the encoding used. It is possible to configure the console to render UTF-8 properly by changing the active codepage with the chcp 65001 command. See the chcp docs for more details.

fs.writeFile(file, data[, options], callback)#
History
file <string> | <Buffer> | <URL> | <integer> filename or file descriptor
data <string> | <Buffer> | <TypedArray> | <DataView>
options <Object> | <string>
encoding <string> | <null> Default: 'utf8'
mode <integer> Default: 0o666
flag <string> See support of file system flags. Default: 'w'.
flush <boolean> If all data is successfully written to the file, and flush is true, fs.fsync() is used to flush the data. Default: false.
signal <AbortSignal> allows aborting an in-progress writeFile
callback <Function>
err <Error> | <AggregateError>
When file is a filename, asynchronously writes data to the file, replacing the file if it already exists. data can be a string or a buffer.

When file is a file descriptor, the behavior is similar to calling fs.write() directly (which is recommended). See the notes below on using a file descriptor.

The encoding option is ignored if data is a buffer.

The mode option only affects the newly created file. See fs.open() for more details.

import { writeFile } from 'node:fs';
import { Buffer } from 'node:buffer';

const data = new Uint8Array(Buffer.from('Hello Node.js'));
writeFile('message.txt', data, (err) => {
  if (err) throw err;
  console.log('The file has been saved!');
}); COPY
If options is a string, then it specifies the encoding:

import { writeFile } from 'node:fs';

writeFile('message.txt', 'Hello Node.js', 'utf8', callback); COPY
It is unsafe to use fs.writeFile() multiple times on the same file without waiting for the callback. For this scenario, fs.createWriteStream() is recommended.

Similarly to fs.readFile - fs.writeFile is a convenience method that performs multiple write calls internally to write the buffer passed to it. For performance sensitive code consider using fs.createWriteStream().

It is possible to use an <AbortSignal> to cancel an fs.writeFile(). Cancelation is "best effort", and some amount of data is likely still to be written.

import { writeFile } from 'node:fs';
import { Buffer } from 'node:buffer';

const controller = new AbortController();
const { signal } = controller;
const data = new Uint8Array(Buffer.from('Hello Node.js'));
writeFile('message.txt', data, { signal }, (err) => {
  // When a request is aborted - the callback is called with an AbortError
});
// When the request should be aborted
controller.abort(); COPY
Aborting an ongoing request does not abort individual operating system requests but rather the internal buffering fs.writeFile performs.

Using fs.writeFile() with file descriptors#
When file is a file descriptor, the behavior is almost identical to directly calling fs.write() like:

import { write } from 'node:fs';
import { Buffer } from 'node:buffer';

write(fd, Buffer.from(data, options.encoding), callback); COPY
The difference from directly calling fs.write() is that under some unusual conditions, fs.write() might write only part of the buffer and need to be retried to write the remaining data, whereas fs.writeFile() retries until the data is entirely written (or an error occurs).

The implications of this are a common source of confusion. In the file descriptor case, the file is not replaced! The data is not necessarily written to the beginning of the file, and the file's original data may remain before and/or after the newly written data.

For example, if fs.writeFile() is called twice in a row, first to write the string 'Hello', then to write the string ', World', the file would contain 'Hello, World', and might contain some of the file's original data (depending on the size of the original file, and the position of the file descriptor). If a file name had been used instead of a descriptor, the file would be guaranteed to contain only ', World'.

fs.writev(fd, buffers[, position], callback)#
History
fd <integer>
buffers <ArrayBufferView[]>
position <integer> | <null> Default: null
callback <Function>
err <Error>
bytesWritten <integer>
buffers <ArrayBufferView[]>
Write an array of ArrayBufferViews to the file specified by fd using writev().

position is the offset from the beginning of the file where this data should be written. If typeof position !== 'number', the data will be written at the current position.

The callback will be given three arguments: err, bytesWritten, and buffers. bytesWritten is how many bytes were written from buffers.

If this method is util.promisify()ed, it returns a promise for an Object with bytesWritten and buffers properties.

It is unsafe to use fs.writev() multiple times on the same file without waiting for the callback. For this scenario, use fs.createWriteStream().

On Linux, positional writes don't work when the file is opened in append mode. The kernel ignores the position argument and always appends the data to the end of the file.

Synchronous API#
The synchronous APIs perform all operations synchronously, blocking the event loop until the operation completes or fails.

fs.accessSync(path[, mode])#
History
path <string> | <Buffer> | <URL>
mode <integer> Default: fs.constants.F_OK
Synchronously tests a user's permissions for the file or directory specified by path. The mode argument is an optional integer that specifies the accessibility checks to be performed. mode should be either the value fs.constants.F_OK or a mask consisting of the bitwise OR of any of fs.constants.R_OK, fs.constants.W_OK, and fs.constants.X_OK (e.g. fs.constants.W_OK | fs.constants.R_OK). Check File access constants for possible values of mode.

If any of the accessibility checks fail, an Error will be thrown. Otherwise, the method will return undefined.

import { accessSync, constants } from 'node:fs';

try {
  accessSync('etc/passwd', constants.R_OK | constants.W_OK);
  console.log('can read/write');
} catch (err) {
  console.error('no access!');
} COPY
fs.appendFileSync(path, data[, options])#
History
path <string> | <Buffer> | <URL> | <number> filename or file descriptor
data <string> | <Buffer>
options <Object> | <string>
encoding <string> | <null> Default: 'utf8'
mode <integer> Default: 0o666
flag <string> See support of file system flags. Default: 'a'.
flush <boolean> If true, the underlying file descriptor is flushed prior to closing it. Default: false.
Synchronously append data to a file, creating the file if it does not yet exist. data can be a string or a <Buffer>.

The mode option only affects the newly created file. See fs.open() for more details.

import { appendFileSync } from 'node:fs';

try {
  appendFileSync('message.txt', 'data to append');
  console.log('The "data to append" was appended to file!');
} catch (err) {
  /* Handle the error */
} COPY
If options is a string, then it specifies the encoding:

import { appendFileSync } from 'node:fs';

appendFileSync('message.txt', 'data to append', 'utf8'); COPY
The path may be specified as a numeric file descriptor that has been opened for appending (using fs.open() or fs.openSync()). The file descriptor will not be closed automatically.

import { openSync, closeSync, appendFileSync } from 'node:fs';

let fd;

try {
  fd = openSync('message.txt', 'a');
  appendFileSync(fd, 'data to append', 'utf8');
} catch (err) {
  /* Handle the error */
} finally {
  if (fd !== undefined)
    closeSync(fd);
} COPY
fs.chmodSync(path, mode)#
History
path <string> | <Buffer> | <URL>
mode <string> | <integer>
For detailed information, see the documentation of the asynchronous version of this API: fs.chmod().

See the POSIX chmod(2) documentation for more detail.

fs.chownSync(path, uid, gid)#
History
path <string> | <Buffer> | <URL>
uid <integer>
gid <integer>
Synchronously changes owner and group of a file. Returns undefined. This is the synchronous version of fs.chown().

See the POSIX chown(2) documentation for more detail.

fs.closeSync(fd)#
Added in: v0.1.21
fd <integer>
Closes the file descriptor. Returns undefined.

Calling fs.closeSync() on any file descriptor (fd) that is currently in use through any other fs operation may lead to undefined behavior.

See the POSIX close(2) documentation for more detail.

fs.copyFileSync(src, dest[, mode])#
History
src <string> | <Buffer> | <URL> source filename to copy
dest <string> | <Buffer> | <URL> destination filename of the copy operation
mode <integer> modifiers for copy operation. Default: 0.
Synchronously copies src to dest. By default, dest is overwritten if it already exists. Returns undefined. Node.js makes no guarantees about the atomicity of the copy operation. If an error occurs after the destination file has been opened for writing, Node.js will attempt to remove the destination.

mode is an optional integer that specifies the behavior of the copy operation. It is possible to create a mask consisting of the bitwise OR of two or more values (e.g. fs.constants.COPYFILE_EXCL | fs.constants.COPYFILE_FICLONE).

fs.constants.COPYFILE_EXCL: The copy operation will fail if dest already exists.
fs.constants.COPYFILE_FICLONE: The copy operation will attempt to create a copy-on-write reflink. If the platform does not support copy-on-write, then a fallback copy mechanism is used.
fs.constants.COPYFILE_FICLONE_FORCE: The copy operation will attempt to create a copy-on-write reflink. If the platform does not support copy-on-write, then the operation will fail.
import { copyFileSync, constants } from 'node:fs';

// destination.txt will be created or overwritten by default.
copyFileSync('source.txt', 'destination.txt');
console.log('source.txt was copied to destination.txt');

// By using COPYFILE_EXCL, the operation will fail if destination.txt exists.
copyFileSync('source.txt', 'destination.txt', constants.COPYFILE_EXCL); COPY
fs.cpSync(src, dest[, options])#
History
src <string> | <URL> source path to copy.
dest <string> | <URL> destination path to copy to.
options <Object>
dereference <boolean> dereference symlinks. Default: false.
errorOnExist <boolean> when force is false, and the destination exists, throw an error. Default: false.
filter <Function> Function to filter copied files/directories. Return true to copy the item, false to ignore it. When ignoring a directory, all of its contents will be skipped as well. Default: undefined
src <string> source path to copy.
dest <string> destination path to copy to.
Returns: <boolean> Any non-Promise value that is coercible to boolean.
force <boolean> overwrite existing file or directory. The copy operation will ignore errors if you set this to false and the destination exists. Use the errorOnExist option to change this behavior. Default: true.
mode <integer> modifiers for copy operation. Default: 0. See mode flag of fs.copyFileSync().
preserveTimestamps <boolean> When true timestamps from src will be preserved. Default: false.
recursive <boolean> copy directories recursively Default: false
verbatimSymlinks <boolean> When true, path resolution for symlinks will be skipped. Default: false
Synchronously copies the entire directory structure from src to dest, including subdirectories and files.

When copying a directory to another directory, globs are not supported and behavior is similar to cp dir1/ dir2/.

fs.existsSync(path)#
History
path <string> | <Buffer> | <URL>
Returns: <boolean>
Returns true if the path exists, false otherwise.

For detailed information, see the documentation of the asynchronous version of this API: fs.exists().

fs.exists() is deprecated, but fs.existsSync() is not. The callback parameter to fs.exists() accepts parameters that are inconsistent with other Node.js callbacks. fs.existsSync() does not use a callback.

import { existsSync } from 'node:fs';

if (existsSync('/etc/passwd'))
  console.log('The path exists.'); COPY
fs.fchmodSync(fd, mode)#
Added in: v0.4.7
fd <integer>
mode <string> | <integer>
Sets the permissions on the file. Returns undefined.

See the POSIX fchmod(2) documentation for more detail.

fs.fchownSync(fd, uid, gid)#
Added in: v0.4.7
fd <integer>
uid <integer> The file's new owner's user id.
gid <integer> The file's new group's group id.
Sets the owner of the file. Returns undefined.

See the POSIX fchown(2) documentation for more detail.

fs.fdatasyncSync(fd)#
Added in: v0.1.96
fd <integer>
Forces all currently queued I/O operations associated with the file to the operating system's synchronized I/O completion state. Refer to the POSIX fdatasync(2) documentation for details. Returns undefined.

fs.fstatSync(fd[, options])#
History
fd <integer>
options <Object>
bigint <boolean> Whether the numeric values in the returned <fs.Stats> object should be bigint. Default: false.
Returns: <fs.Stats>
Retrieves the <fs.Stats> for the file descriptor.

See the POSIX fstat(2) documentation for more detail.

fs.fsyncSync(fd)#
Added in: v0.1.96
fd <integer>
Request that all data for the open file descriptor is flushed to the storage device. The specific implementation is operating system and device specific. Refer to the POSIX fsync(2) documentation for more detail. Returns undefined.

fs.ftruncateSync(fd[, len])#
Added in: v0.8.6
fd <integer>
len <integer> Default: 0
Truncates the file descriptor. Returns undefined.

For detailed information, see the documentation of the asynchronous version of this API: fs.ftruncate().

fs.futimesSync(fd, atime, mtime)#
History
fd <integer>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
Synchronous version of fs.futimes(). Returns undefined.

fs.globSync(pattern[, options])#
History
Stability: 1 - Experimental
pattern <string> | <string[]>
options <Object>
cwd <string> current working directory. Default: process.cwd()
exclude <Function> Function to filter out files/directories. Return true to exclude the item, false to include it. Default: undefined.
withFileTypes <boolean> true if the glob should return paths as Dirents, false otherwise. Default: false.
Returns: <string[]> paths of files that match the pattern.
const { globSync } = require('node:fs');

console.log(globSync('**/*.js'));COPY
fs.lchmodSync(path, mode)#
Deprecated since: v0.4.7
path <string> | <Buffer> | <URL>
mode <integer>
Changes the permissions on a symbolic link. Returns undefined.

This method is only implemented on macOS.

See the POSIX lchmod(2) documentation for more detail.

fs.lchownSync(path, uid, gid)#
History
path <string> | <Buffer> | <URL>
uid <integer> The file's new owner's user id.
gid <integer> The file's new group's group id.
Set the owner for the path. Returns undefined.

See the POSIX lchown(2) documentation for more details.

fs.lutimesSync(path, atime, mtime)#
Added in: v14.5.0, v12.19.0
path <string> | <Buffer> | <URL>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
Change the file system timestamps of the symbolic link referenced by path. Returns undefined, or throws an exception when parameters are incorrect or the operation fails. This is the synchronous version of fs.lutimes().

fs.linkSync(existingPath, newPath)#
History
existingPath <string> | <Buffer> | <URL>
newPath <string> | <Buffer> | <URL>
Creates a new link from the existingPath to the newPath. See the POSIX link(2) documentation for more detail. Returns undefined.

fs.lstatSync(path[, options])#
History
path <string> | <Buffer> | <URL>
options <Object>
bigint <boolean> Whether the numeric values in the returned <fs.Stats> object should be bigint. Default: false.
throwIfNoEntry <boolean> Whether an exception will be thrown if no file system entry exists, rather than returning undefined. Default: true.
Returns: <fs.Stats>
Retrieves the <fs.Stats> for the symbolic link referred to by path.

See the POSIX lstat(2) documentation for more details.

fs.mkdirSync(path[, options])#
History
path <string> | <Buffer> | <URL>
options <Object> | <integer>
recursive <boolean> Default: false
mode <string> | <integer> Not supported on Windows. Default: 0o777.
Returns: <string> | <undefined>
Synchronously creates a directory. Returns undefined, or if recursive is true, the first directory path created. This is the synchronous version of fs.mkdir().

See the POSIX mkdir(2) documentation for more details.

fs.mkdtempSync(prefix[, options])#
History
prefix <string> | <Buffer> | <URL>
options <string> | <Object>
encoding <string> Default: 'utf8'
Returns: <string>
Returns the created directory path.

For detailed information, see the documentation of the asynchronous version of this API: fs.mkdtemp().

The optional options argument can be a string specifying an encoding, or an object with an encoding property specifying the character encoding to use.

fs.opendirSync(path[, options])#
History
path <string> | <Buffer> | <URL>
options <Object>
encoding <string> | <null> Default: 'utf8'
bufferSize <number> Number of directory entries that are buffered internally when reading from the directory. Higher values lead to better performance but higher memory usage. Default: 32
recursive <boolean> Default: false
Returns: <fs.Dir>
Synchronously open a directory. See opendir(3).

Creates an <fs.Dir>, which contains all further functions for reading from and cleaning up the directory.

The encoding option sets the encoding for the path while opening the directory and subsequent read operations.

fs.openSync(path[, flags[, mode]])#
History
path <string> | <Buffer> | <URL>
flags <string> | <number> Default: 'r'. See support of file system flags.
mode <string> | <integer> Default: 0o666
Returns: <number>
Returns an integer representing the file descriptor.

For detailed information, see the documentation of the asynchronous version of this API: fs.open().

fs.readdirSync(path[, options])#
History
path <string> | <Buffer> | <URL>
options <string> | <Object>
encoding <string> Default: 'utf8'
withFileTypes <boolean> Default: false
recursive <boolean> If true, reads the contents of a directory recursively. In recursive mode, it will list all files, sub files, and directories. Default: false.
Returns: <string[]> | <Buffer[]> | <fs.Dirent[]>
Reads the contents of the directory.

See the POSIX readdir(3) documentation for more details.

The optional options argument can be a string specifying an encoding, or an object with an encoding property specifying the character encoding to use for the filenames returned. If the encoding is set to 'buffer', the filenames returned will be passed as <Buffer> objects.

If options.withFileTypes is set to true, the result will contain <fs.Dirent> objects.

fs.readFileSync(path[, options])#
History
path <string> | <Buffer> | <URL> | <integer> filename or file descriptor
options <Object> | <string>
encoding <string> | <null> Default: null
flag <string> See support of file system flags. Default: 'r'.
Returns: <string> | <Buffer>
Returns the contents of the path.

For detailed information, see the documentation of the asynchronous version of this API: fs.readFile().

If the encoding option is specified then this function returns a string. Otherwise it returns a buffer.

Similar to fs.readFile(), when the path is a directory, the behavior of fs.readFileSync() is platform-specific.

import { readFileSync } from 'node:fs';

// macOS, Linux, and Windows
readFileSync('<directory>');
// => [Error: EISDIR: illegal operation on a directory, read <directory>]

//  FreeBSD
readFileSync('<directory>'); // => <data> COPY
fs.readlinkSync(path[, options])#
History
path <string> | <Buffer> | <URL>
options <string> | <Object>
encoding <string> Default: 'utf8'
Returns: <string> | <Buffer>
Returns the symbolic link's string value.

See the POSIX readlink(2) documentation for more details.

The optional options argument can be a string specifying an encoding, or an object with an encoding property specifying the character encoding to use for the link path returned. If the encoding is set to 'buffer', the link path returned will be passed as a <Buffer> object.

fs.readSync(fd, buffer, offset, length[, position])#
History
fd <integer>
buffer <Buffer> | <TypedArray> | <DataView>
offset <integer>
length <integer>
position <integer> | <bigint> | <null> Default: null
Returns: <number>
Returns the number of bytesRead.

For detailed information, see the documentation of the asynchronous version of this API: fs.read().

fs.readSync(fd, buffer[, options])#
History
fd <integer>
buffer <Buffer> | <TypedArray> | <DataView>
options <Object>
offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <bigint> | <null> Default: null
Returns: <number>
Returns the number of bytesRead.

Similar to the above fs.readSync function, this version takes an optional options object. If no options object is specified, it will default with the above values.

For detailed information, see the documentation of the asynchronous version of this API: fs.read().

fs.readvSync(fd, buffers[, position])#
Added in: v13.13.0, v12.17.0
fd <integer>
buffers <ArrayBufferView[]>
position <integer> | <null> Default: null
Returns: <number> The number of bytes read.
For detailed information, see the documentation of the asynchronous version of this API: fs.readv().

fs.realpathSync(path[, options])#
History
path <string> | <Buffer> | <URL>
options <string> | <Object>
encoding <string> Default: 'utf8'
Returns: <string> | <Buffer>
Returns the resolved pathname.

For detailed information, see the documentation of the asynchronous version of this API: fs.realpath().

fs.realpathSync.native(path[, options])#
Added in: v9.2.0
path <string> | <Buffer> | <URL>
options <string> | <Object>
encoding <string> Default: 'utf8'
Returns: <string> | <Buffer>
Synchronous realpath(3).

Only paths that can be converted to UTF8 strings are supported.

The optional options argument can be a string specifying an encoding, or an object with an encoding property specifying the character encoding to use for the path returned. If the encoding is set to 'buffer', the path returned will be passed as a <Buffer> object.

On Linux, when Node.js is linked against musl libc, the procfs file system must be mounted on /proc in order for this function to work. Glibc does not have this restriction.

fs.renameSync(oldPath, newPath)#
History
oldPath <string> | <Buffer> | <URL>
newPath <string> | <Buffer> | <URL>
Renames the file from oldPath to newPath. Returns undefined.

See the POSIX rename(2) documentation for more details.

fs.rmdirSync(path[, options])#
History
path <string> | <Buffer> | <URL>
options <Object>
maxRetries <integer> If an EBUSY, EMFILE, ENFILE, ENOTEMPTY, or EPERM error is encountered, Node.js retries the operation with a linear backoff wait of retryDelay milliseconds longer on each try. This option represents the number of retries. This option is ignored if the recursive option is not true. Default: 0.
recursive <boolean> If true, perform a recursive directory removal. In recursive mode, operations are retried on failure. Default: false. Deprecated.
retryDelay <integer> The amount of time in milliseconds to wait between retries. This option is ignored if the recursive option is not true. Default: 100.
Synchronous rmdir(2). Returns undefined.

Using fs.rmdirSync() on a file (not a directory) results in an ENOENT error on Windows and an ENOTDIR error on POSIX.

To get a behavior similar to the rm -rf Unix command, use fs.rmSync() with options { recursive: true, force: true }.

fs.rmSync(path[, options])#
History
path <string> | <Buffer> | <URL>
options <Object>
force <boolean> When true, exceptions will be ignored if path does not exist. Default: false.
maxRetries <integer> If an EBUSY, EMFILE, ENFILE, ENOTEMPTY, or EPERM error is encountered, Node.js will retry the operation with a linear backoff wait of retryDelay milliseconds longer on each try. This option represents the number of retries. This option is ignored if the recursive option is not true. Default: 0.
recursive <boolean> If true, perform a recursive directory removal. In recursive mode operations are retried on failure. Default: false.
retryDelay <integer> The amount of time in milliseconds to wait between retries. This option is ignored if the recursive option is not true. Default: 100.
Synchronously removes files and directories (modeled on the standard POSIX rm utility). Returns undefined.

fs.statSync(path[, options])#
History
path <string> | <Buffer> | <URL>
options <Object>
bigint <boolean> Whether the numeric values in the returned <fs.Stats> object should be bigint. Default: false.
throwIfNoEntry <boolean> Whether an exception will be thrown if no file system entry exists, rather than returning undefined. Default: true.
Returns: <fs.Stats>
Retrieves the <fs.Stats> for the path.

fs.statfsSync(path[, options])#
Added in: v19.6.0, v18.15.0
path <string> | <Buffer> | <URL>
options <Object>
bigint <boolean> Whether the numeric values in the returned <fs.StatFs> object should be bigint. Default: false.
Returns: <fs.StatFs>
Synchronous statfs(2). Returns information about the mounted file system which contains path.

In case of an error, the err.code will be one of Common System Errors.

fs.symlinkSync(target, path[, type])#
History
target <string> | <Buffer> | <URL>
path <string> | <Buffer> | <URL>
type <string> | <null> Default: null
Returns undefined.

For detailed information, see the documentation of the asynchronous version of this API: fs.symlink().

fs.truncateSync(path[, len])#
Added in: v0.8.6
path <string> | <Buffer> | <URL>
len <integer> Default: 0
Truncates the file. Returns undefined. A file descriptor can also be passed as the first argument. In this case, fs.ftruncateSync() is called.

Passing a file descriptor is deprecated and may result in an error being thrown in the future.

fs.unlinkSync(path)#
History
path <string> | <Buffer> | <URL>
Synchronous unlink(2). Returns undefined.

fs.utimesSync(path, atime, mtime)#
History
path <string> | <Buffer> | <URL>
atime <number> | <string> | <Date>
mtime <number> | <string> | <Date>
Returns undefined.

For detailed information, see the documentation of the asynchronous version of this API: fs.utimes().

fs.writeFileSync(file, data[, options])#
History
file <string> | <Buffer> | <URL> | <integer> filename or file descriptor
data <string> | <Buffer> | <TypedArray> | <DataView>
options <Object> | <string>
encoding <string> | <null> Default: 'utf8'
mode <integer> Default: 0o666
flag <string> See support of file system flags. Default: 'w'.
flush <boolean> If all data is successfully written to the file, and flush is true, fs.fsyncSync() is used to flush the data.
Returns undefined.

The mode option only affects the newly created file. See fs.open() for more details.

For detailed information, see the documentation of the asynchronous version of this API: fs.writeFile().

fs.writeSync(fd, buffer, offset[, length[, position]])#
History
fd <integer>
buffer <Buffer> | <TypedArray> | <DataView>
offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> | <null> Default: null
Returns: <number> The number of bytes written.
For detailed information, see the documentation of the asynchronous version of this API: fs.write(fd, buffer...).

fs.writeSync(fd, buffer[, options])#
Added in: v18.3.0, v16.17.0
fd <integer>
buffer <Buffer> | <TypedArray> | <DataView>
options <Object>
offset <integer> Default: 0
length <integer> Default: buffer.byteLength - offset
position <integer> Default: null
Returns: <number> The number of bytes written.
For detailed information, see the documentation of the asynchronous version of this API: fs.write(fd, buffer...).

fs.writeSync(fd, string[, position[, encoding]])#
History
fd <integer>
string <string>
position <integer> | <null> Default: null
encoding <string> Default: 'utf8'
Returns: <number> The number of bytes written.
For detailed information, see the documentation of the asynchronous version of this API: fs.write(fd, string...).

fs.writevSync(fd, buffers[, position])#
Added in: v12.9.0
fd <integer>
buffers <ArrayBufferView[]>
position <integer> | <null> Default: null
Returns: <number> The number of bytes written.
For detailed information, see the documentation of the asynchronous version of this API: fs.writev().

Common Objects#
The common objects are shared by all of the file system API variants (promise, callback, and synchronous).

Class: fs.Dir#
Added in: v12.12.0
A class representing a directory stream.

Created by fs.opendir(), fs.opendirSync(), or fsPromises.opendir().

import { opendir } from 'node:fs/promises';

try {
  const dir = await opendir('./');
  for await (const dirent of dir)
    console.log(dirent.name);
} catch (err) {
  console.error(err);
} COPY
When using the async iterator, the <fs.Dir> object will be automatically closed after the iterator exits.

dir.close()#
Added in: v12.12.0
Returns: <Promise>
Asynchronously close the directory's underlying resource handle. Subsequent reads will result in errors.

A promise is returned that will be fulfilled after the resource has been closed.

dir.close(callback)#
History
callback <Function>
err <Error>
Asynchronously close the directory's underlying resource handle. Subsequent reads will result in errors.

The callback will be called after the resource handle has been closed.

dir.closeSync()#
Added in: v12.12.0
Synchronously close the directory's underlying resource handle. Subsequent reads will result in errors.

dir.path#
Added in: v12.12.0
<string>
The read-only path of this directory as was provided to fs.opendir(), fs.opendirSync(), or fsPromises.opendir().

dir.read()#
Added in: v12.12.0
Returns: <Promise> Fulfills with a <fs.Dirent> | <null>
Asynchronously read the next directory entry via readdir(3) as an <fs.Dirent>.

A promise is returned that will be fulfilled with an <fs.Dirent>, or null if there are no more directory entries to read.

Directory entries returned by this function are in no particular order as provided by the operating system's underlying directory mechanisms. Entries added or removed while iterating over the directory might not be included in the iteration results.

dir.read(callback)#
Added in: v12.12.0
callback <Function>
err <Error>
dirent <fs.Dirent> | <null>
Asynchronously read the next directory entry via readdir(3) as an <fs.Dirent>.

After the read is completed, the callback will be called with an <fs.Dirent>, or null if there are no more directory entries to read.

Directory entries returned by this function are in no particular order as provided by the operating system's underlying directory mechanisms. Entries added or removed while iterating over the directory might not be included in the iteration results.

dir.readSync()#
Added in: v12.12.0
Returns: <fs.Dirent> | <null>
Synchronously read the next directory entry as an <fs.Dirent>. See the POSIX readdir(3) documentation for more detail.

If there are no more directory entries to read, null will be returned.

Directory entries returned by this function are in no particular order as provided by the operating system's underlying directory mechanisms. Entries added or removed while iterating over the directory might not be included in the iteration results.

dir[Symbol.asyncIterator]()#
Added in: v12.12.0
Returns: <AsyncIterator> An AsyncIterator of <fs.Dirent>
Asynchronously iterates over the directory until all entries have been read. Refer to the POSIX readdir(3) documentation for more detail.

Entries returned by the async iterator are always an <fs.Dirent>. The null case from dir.read() is handled internally.

See <fs.Dir> for an example.

Directory entries returned by this iterator are in no particular order as provided by the operating system's underlying directory mechanisms. Entries added or removed while iterating over the directory might not be included in the iteration results.

Class: fs.Dirent#
Added in: v10.10.0
A representation of a directory entry, which can be a file or a subdirectory within the directory, as returned by reading from an <fs.Dir>. The directory entry is a combination of the file name and file type pairs.

Additionally, when fs.readdir() or fs.readdirSync() is called with the withFileTypes option set to true, the resulting array is filled with <fs.Dirent> objects, rather than strings or <Buffer>s.

dirent.isBlockDevice()#
Added in: v10.10.0
Returns: <boolean>
Returns true if the <fs.Dirent> object describes a block device.

dirent.isCharacterDevice()#
Added in: v10.10.0
Returns: <boolean>
Returns true if the <fs.Dirent> object describes a character device.

dirent.isDirectory()#
Added in: v10.10.0
Returns: <boolean>
Returns true if the <fs.Dirent> object describes a file system directory.

dirent.isFIFO()#
Added in: v10.10.0
Returns: <boolean>
Returns true if the <fs.Dirent> object describes a first-in-first-out (FIFO) pipe.

dirent.isFile()#
Added in: v10.10.0
Returns: <boolean>
Returns true if the <fs.Dirent> object describes a regular file.

dirent.isSocket()#
Added in: v10.10.0
Returns: <boolean>
Returns true if the <fs.Dirent> object describes a socket.

dirent.isSymbolicLink()#
Added in: v10.10.0
Returns: <boolean>
Returns true if the <fs.Dirent> object describes a symbolic link.

dirent.name#
Added in: v10.10.0
<string> | <Buffer>
The file name that this <fs.Dirent> object refers to. The type of this value is determined by the options.encoding passed to fs.readdir() or fs.readdirSync().

dirent.parentPath#
Added in: v21.4.0, v20.12.0, v18.20.0
Stability: 1 â€“ Experimental
<string>
The path to the parent directory of the file this <fs.Dirent> object refers to.

dirent.path#
Added in: v20.1.0, v18.17.0Deprecated since: v21.5.0, v20.12.0, v18.20.0
Stability: 0 - Deprecated: Use dirent.parentPath instead.
<string>
Alias for dirent.parentPath.

Class: fs.FSWatcher#
Added in: v0.5.8
Extends <EventEmitter>
A successful call to fs.watch() method will return a new <fs.FSWatcher> object.

All <fs.FSWatcher> objects emit a 'change' event whenever a specific watched file is modified.

Event: 'change'#
Added in: v0.5.8
eventType <string> The type of change event that has occurred
filename <string> | <Buffer> The filename that changed (if relevant/available)
Emitted when something changes in a watched directory or file. See more details in fs.watch().

The filename argument may not be provided depending on operating system support. If filename is provided, it will be provided as a <Buffer> if fs.watch() is called with its encoding option set to 'buffer', otherwise filename will be a UTF-8 string.

import { watch } from 'node:fs';
// Example when handled through fs.watch() listener
watch('./tmp', { encoding: 'buffer' }, (eventType, filename) => {
  if (filename) {
    console.log(filename);
    // Prints: <Buffer ...>
  }
}); COPY
Event: 'close'#
Added in: v10.0.0
Emitted when the watcher stops watching for changes. The closed <fs.FSWatcher> object is no longer usable in the event handler.

Event: 'error'#
Added in: v0.5.8
error <Error>
Emitted when an error occurs while watching the file. The errored <fs.FSWatcher> object is no longer usable in the event handler.

watcher.close()#
Added in: v0.5.8
Stop watching for changes on the given <fs.FSWatcher>. Once stopped, the <fs.FSWatcher> object is no longer usable.

watcher.ref()#
Added in: v14.3.0, v12.20.0
Returns: <fs.FSWatcher>
When called, requests that the Node.js event loop not exit so long as the <fs.FSWatcher> is active. Calling watcher.ref() multiple times will have no effect.

By default, all <fs.FSWatcher> objects are "ref'ed", making it normally unnecessary to call watcher.ref() unless watcher.unref() had been called previously.

watcher.unref()#
Added in: v14.3.0, v12.20.0
Returns: <fs.FSWatcher>
When called, the active <fs.FSWatcher> object will not require the Node.js event loop to remain active. If there is no other activity keeping the event loop running, the process may exit before the <fs.FSWatcher> object's callback is invoked. Calling watcher.unref() multiple times will have no effect.

Class: fs.StatWatcher#
Added in: v14.3.0, v12.20.0
Extends <EventEmitter>
A successful call to fs.watchFile() method will return a new <fs.StatWatcher> object.

watcher.ref()#
Added in: v14.3.0, v12.20.0
Returns: <fs.StatWatcher>
When called, requests that the Node.js event loop not exit so long as the <fs.StatWatcher> is active. Calling watcher.ref() multiple times will have no effect.

By default, all <fs.StatWatcher> objects are "ref'ed", making it normally unnecessary to call watcher.ref() unless watcher.unref() had been called previously.

watcher.unref()#
Added in: v14.3.0, v12.20.0
Returns: <fs.StatWatcher>
When called, the active <fs.StatWatcher> object will not require the Node.js event loop to remain active. If there is no other activity keeping the event loop running, the process may exit before the <fs.StatWatcher> object's callback is invoked. Calling watcher.unref() multiple times will have no effect.

Class: fs.ReadStream#
Added in: v0.1.93
Extends: <stream.Readable>
Instances of <fs.ReadStream> are created and returned using the fs.createReadStream() function.

Event: 'close'#
Added in: v0.1.93
Emitted when the <fs.ReadStream>'s underlying file descriptor has been closed.

Event: 'open'#
Added in: v0.1.93
fd <integer> Integer file descriptor used by the <fs.ReadStream>.
Emitted when the <fs.ReadStream>'s file descriptor has been opened.

Event: 'ready'#
Added in: v9.11.0
Emitted when the <fs.ReadStream> is ready to be used.

Fires immediately after 'open'.

readStream.bytesRead#
Added in: v6.4.0
<number>
The number of bytes that have been read so far.

readStream.path#
Added in: v0.1.93
<string> | <Buffer>
The path to the file the stream is reading from as specified in the first argument to fs.createReadStream(). If path is passed as a string, then readStream.path will be a string. If path is passed as a <Buffer>, then readStream.path will be a <Buffer>. If fd is specified, then readStream.path will be undefined.

readStream.pending#
Added in: v11.2.0, v10.16.0
<boolean>
This property is true if the underlying file has not been opened yet, i.e. before the 'ready' event is emitted.

Class: fs.Stats#
History
A <fs.Stats> object provides information about a file.

Objects returned from fs.stat(), fs.lstat(), fs.fstat(), and their synchronous counterparts are of this type. If bigint in the options passed to those methods is true, the numeric values will be bigint instead of number, and the object will contain additional nanosecond-precision properties suffixed with Ns. Stat objects are not to be created directly using the new keyword.

Stats {
  dev: 2114,
  ino: 48064969,
  mode: 33188,
  nlink: 1,
  uid: 85,
  gid: 100,
  rdev: 0,
  size: 527,
  blksize: 4096,
  blocks: 8,
  atimeMs: 1318289051000.1,
  mtimeMs: 1318289051000.1,
  ctimeMs: 1318289051000.1,
  birthtimeMs: 1318289051000.1,
  atime: Mon, 10 Oct 2011 23:24:11 GMT,
  mtime: Mon, 10 Oct 2011 23:24:11 GMT,
  ctime: Mon, 10 Oct 2011 23:24:11 GMT,
  birthtime: Mon, 10 Oct 2011 23:24:11 GMT } COPY
bigint version:

BigIntStats {
  dev: 2114n,
  ino: 48064969n,
  mode: 33188n,
  nlink: 1n,
  uid: 85n,
  gid: 100n,
  rdev: 0n,
  size: 527n,
  blksize: 4096n,
  blocks: 8n,
  atimeMs: 1318289051000n,
  mtimeMs: 1318289051000n,
  ctimeMs: 1318289051000n,
  birthtimeMs: 1318289051000n,
  atimeNs: 1318289051000000000n,
  mtimeNs: 1318289051000000000n,
  ctimeNs: 1318289051000000000n,
  birthtimeNs: 1318289051000000000n,
  atime: Mon, 10 Oct 2011 23:24:11 GMT,
  mtime: Mon, 10 Oct 2011 23:24:11 GMT,
  ctime: Mon, 10 Oct 2011 23:24:11 GMT,
  birthtime: Mon, 10 Oct 2011 23:24:11 GMT } COPY
stats.isBlockDevice()#
Added in: v0.1.10
Returns: <boolean>
Returns true if the <fs.Stats> object describes a block device.

stats.isCharacterDevice()#
Added in: v0.1.10
Returns: <boolean>
Returns true if the <fs.Stats> object describes a character device.

stats.isDirectory()#
Added in: v0.1.10
Returns: <boolean>
Returns true if the <fs.Stats> object describes a file system directory.

If the <fs.Stats> object was obtained from calling fs.lstat() on a symbolic link which resolves to a directory, this method will return false. This is because fs.lstat() returns information about a symbolic link itself and not the path it resolves to.

stats.isFIFO()#
Added in: v0.1.10
Returns: <boolean>
Returns true if the <fs.Stats> object describes a first-in-first-out (FIFO) pipe.

stats.isFile()#
Added in: v0.1.10
Returns: <boolean>
Returns true if the <fs.Stats> object describes a regular file.

stats.isSocket()#
Added in: v0.1.10
Returns: <boolean>
Returns true if the <fs.Stats> object describes a socket.

stats.isSymbolicLink()#
Added in: v0.1.10
Returns: <boolean>
Returns true if the <fs.Stats> object describes a symbolic link.

This method is only valid when using fs.lstat().

stats.dev#
<number> | <bigint>
The numeric identifier of the device containing the file.

stats.ino#
<number> | <bigint>
The file system specific "Inode" number for the file.

stats.mode#
<number> | <bigint>
A bit-field describing the file type and mode.

stats.nlink#
<number> | <bigint>
The number of hard-links that exist for the file.

stats.uid#
<number> | <bigint>
The numeric user identifier of the user that owns the file (POSIX).

stats.gid#
<number> | <bigint>
The numeric group identifier of the group that owns the file (POSIX).

stats.rdev#
<number> | <bigint>
A numeric device identifier if the file represents a device.

stats.size#
<number> | <bigint>
The size of the file in bytes.

If the underlying file system does not support getting the size of the file, this will be 0.

stats.blksize#
<number> | <bigint>
The file system block size for i/o operations.

stats.blocks#
<number> | <bigint>
The number of blocks allocated for this file.

stats.atimeMs#
Added in: v8.1.0
<number> | <bigint>
The timestamp indicating the last time this file was accessed expressed in milliseconds since the POSIX Epoch.

stats.mtimeMs#
Added in: v8.1.0
<number> | <bigint>
The timestamp indicating the last time this file was modified expressed in milliseconds since the POSIX Epoch.

stats.ctimeMs#
Added in: v8.1.0
<number> | <bigint>
The timestamp indicating the last time the file status was changed expressed in milliseconds since the POSIX Epoch.

stats.birthtimeMs#
Added in: v8.1.0
<number> | <bigint>
The timestamp indicating the creation time of this file expressed in milliseconds since the POSIX Epoch.

stats.atimeNs#
Added in: v12.10.0
<bigint>
Only present when bigint: true is passed into the method that generates the object. The timestamp indicating the last time this file was accessed expressed in nanoseconds since the POSIX Epoch.

stats.mtimeNs#
Added in: v12.10.0
<bigint>
Only present when bigint: true is passed into the method that generates the object. The timestamp indicating the last time this file was modified expressed in nanoseconds since the POSIX Epoch.

stats.ctimeNs#
Added in: v12.10.0
<bigint>
Only present when bigint: true is passed into the method that generates the object. The timestamp indicating the last time the file status was changed expressed in nanoseconds since the POSIX Epoch.

stats.birthtimeNs#
Added in: v12.10.0
<bigint>
Only present when bigint: true is passed into the method that generates the object. The timestamp indicating the creation time of this file expressed in nanoseconds since the POSIX Epoch.

stats.atime#
Added in: v0.11.13
<Date>
The timestamp indicating the last time this file was accessed.

stats.mtime#
Added in: v0.11.13
<Date>
The timestamp indicating the last time this file was modified.

stats.ctime#
Added in: v0.11.13
<Date>
The timestamp indicating the last time the file status was changed.

stats.birthtime#
Added in: v0.11.13
<Date>
The timestamp indicating the creation time of this file.

Stat time values#
The atimeMs, mtimeMs, ctimeMs, birthtimeMs properties are numeric values that hold the corresponding times in milliseconds. Their precision is platform specific. When bigint: true is passed into the method that generates the object, the properties will be bigints, otherwise they will be numbers.

The atimeNs, mtimeNs, ctimeNs, birthtimeNs properties are bigints that hold the corresponding times in nanoseconds. They are only present when bigint: true is passed into the method that generates the object. Their precision is platform specific.

atime, mtime, ctime, and birthtime are Date object alternate representations of the various times. The Date and number values are not connected. Assigning a new number value, or mutating the Date value, will not be reflected in the corresponding alternate representation.

The times in the stat object have the following semantics:

atime "Access Time": Time when file data last accessed. Changed by the mknod(2), utimes(2), and read(2) system calls.
mtime "Modified Time": Time when file data last modified. Changed by the mknod(2), utimes(2), and write(2) system calls.
ctime "Change Time": Time when file status was last changed (inode data modification). Changed by the chmod(2), chown(2), link(2), mknod(2), rename(2), unlink(2), utimes(2), read(2), and write(2) system calls.
birthtime "Birth Time": Time of file creation. Set once when the file is created. On file systems where birthtime is not available, this field may instead hold either the ctime or 1970-01-01T00:00Z (ie, Unix epoch timestamp 0). This value may be greater than atime or mtime in this case. On Darwin and other FreeBSD variants, also set if the atime is explicitly set to an earlier value than the current birthtime using the utimes(2) system call.
Prior to Node.js 0.12, the ctime held the birthtime on Windows systems. As of 0.12, ctime is not "creation time", and on Unix systems, it never was.

Class: fs.StatFs#
Added in: v19.6.0, v18.15.0
Provides information about a mounted file system.

Objects returned from fs.statfs() and its synchronous counterpart are of this type. If bigint in the options passed to those methods is true, the numeric values will be bigint instead of number.

StatFs {
  type: 1397114950,
  bsize: 4096,
  blocks: 121938943,
  bfree: 61058895,
  bavail: 61058895,
  files: 999,
  ffree: 1000000
} COPY
bigint version:

StatFs {
  type: 1397114950n,
  bsize: 4096n,
  blocks: 121938943n,
  bfree: 61058895n,
  bavail: 61058895n,
  files: 999n,
  ffree: 1000000n
} COPY
statfs.bavail#
Added in: v19.6.0, v18.15.0
<number> | <bigint>
Free blocks available to unprivileged users.

statfs.bfree#
Added in: v19.6.0, v18.15.0
<number> | <bigint>
Free blocks in file system.

statfs.blocks#
Added in: v19.6.0, v18.15.0
<number> | <bigint>
Total data blocks in file system.

statfs.bsize#
Added in: v19.6.0, v18.15.0
<number> | <bigint>
Optimal transfer block size.

statfs.ffree#
Added in: v19.6.0, v18.15.0
<number> | <bigint>
Free file nodes in file system.

statfs.files#
Added in: v19.6.0, v18.15.0
<number> | <bigint>
Total file nodes in file system.

statfs.type#
Added in: v19.6.0, v18.15.0
<number> | <bigint>
Type of file system.

Class: fs.WriteStream#
Added in: v0.1.93
Extends <stream.Writable>
Instances of <fs.WriteStream> are created and returned using the fs.createWriteStream() function.

Event: 'close'#
Added in: v0.1.93
Emitted when the <fs.WriteStream>'s underlying file descriptor has been closed.

Event: 'open'#
Added in: v0.1.93
fd <integer> Integer file descriptor used by the <fs.WriteStream>.
Emitted when the <fs.WriteStream>'s file is opened.

Event: 'ready'#
Added in: v9.11.0
Emitted when the <fs.WriteStream> is ready to be used.

Fires immediately after 'open'.

writeStream.bytesWritten#
Added in: v0.4.7
The number of bytes written so far. Does not include data that is still queued for writing.

writeStream.close([callback])#
Added in: v0.9.4
callback <Function>
err <Error>
Closes writeStream. Optionally accepts a callback that will be executed once the writeStream is closed.

writeStream.path#
Added in: v0.1.93
The path to the file the stream is writing to as specified in the first argument to fs.createWriteStream(). If path is passed as a string, then writeStream.path will be a string. If path is passed as a <Buffer>, then writeStream.path will be a <Buffer>.

writeStream.pending#
Added in: v11.2.0
<boolean>
This property is true if the underlying file has not been opened yet, i.e. before the 'ready' event is emitted.

fs.constants#
<Object>
Returns an object containing commonly used constants for file system operations.

FS constants#
The following constants are exported by fs.constants and fsPromises.constants.

Not every constant will be available on every operating system; this is especially important for Windows, where many of the POSIX specific definitions are not available. For portable applications it is recommended to check for their presence before use.

To use more than one constant, use the bitwise OR | operator.

Example:

import { open, constants } from 'node:fs';

const {
  O_RDWR,
  O_CREAT,
  O_EXCL,
} = constants;

open('/path/to/my/file', O_RDWR | O_CREAT | O_EXCL, (err, fd) => {
  // ...
}); COPY
File access constants#
The following constants are meant for use as the mode parameter passed to fsPromises.access(), fs.access(), and fs.accessSync().

Constant	Description
F_OK	Flag indicating that the file is visible to the calling process. This is useful for determining if a file exists, but says nothing about rwx permissions. Default if no mode is specified.
R_OK	Flag indicating that the file can be read by the calling process.
W_OK	Flag indicating that the file can be written by the calling process.
X_OK	Flag indicating that the file can be executed by the calling process. This has no effect on Windows (will behave like fs.constants.F_OK).
The definitions are also available on Windows.

File copy constants#
The following constants are meant for use with fs.copyFile().

Constant	Description
COPYFILE_EXCL	If present, the copy operation will fail with an error if the destination path already exists.
COPYFILE_FICLONE	If present, the copy operation will attempt to create a copy-on-write reflink. If the underlying platform does not support copy-on-write, then a fallback copy mechanism is used.
COPYFILE_FICLONE_FORCE	If present, the copy operation will attempt to create a copy-on-write reflink. If the underlying platform does not support copy-on-write, then the operation will fail with an error.
The definitions are also available on Windows.

File open constants#
The following constants are meant for use with fs.open().

Constant	Description
O_RDONLY	Flag indicating to open a file for read-only access.
O_WRONLY	Flag indicating to open a file for write-only access.
O_RDWR	Flag indicating to open a file for read-write access.
O_CREAT	Flag indicating to create the file if it does not already exist.
O_EXCL	Flag indicating that opening a file should fail if the O_CREAT flag is set and the file already exists.
O_NOCTTY	Flag indicating that if path identifies a terminal device, opening the path shall not cause that terminal to become the controlling terminal for the process (if the process does not already have one).
O_TRUNC	Flag indicating that if the file exists and is a regular file, and the file is opened successfully for write access, its length shall be truncated to zero.
O_APPEND	Flag indicating that data will be appended to the end of the file.
O_DIRECTORY	Flag indicating that the open should fail if the path is not a directory.
O_NOATIME	Flag indicating reading accesses to the file system will no longer result in an update to the atime information associated with the file. This flag is available on Linux operating systems only.
O_NOFOLLOW	Flag indicating that the open should fail if the path is a symbolic link.
O_SYNC	Flag indicating that the file is opened for synchronized I/O with write operations waiting for file integrity.
O_DSYNC	Flag indicating that the file is opened for synchronized I/O with write operations waiting for data integrity.
O_SYMLINK	Flag indicating to open the symbolic link itself rather than the resource it is pointing to.
O_DIRECT	When set, an attempt will be made to minimize caching effects of file I/O.
O_NONBLOCK	Flag indicating to open the file in nonblocking mode when possible.
UV_FS_O_FILEMAP	When set, a memory file mapping is used to access the file. This flag is available on Windows operating systems only. On other operating systems, this flag is ignored.
On Windows, only O_APPEND, O_CREAT, O_EXCL, O_RDONLY, O_RDWR, O_TRUNC, O_WRONLY, and UV_FS_O_FILEMAP are available.

File type constants#
The following constants are meant for use with the <fs.Stats> object's mode property for determining a file's type.

Constant	Description
S_IFMT	Bit mask used to extract the file type code.
S_IFREG	File type constant for a regular file.
S_IFDIR	File type constant for a directory.
S_IFCHR	File type constant for a character-oriented device file.
S_IFBLK	File type constant for a block-oriented device file.
S_IFIFO	File type constant for a FIFO/pipe.
S_IFLNK	File type constant for a symbolic link.
S_IFSOCK	File type constant for a socket.
On Windows, only S_IFCHR, S_IFDIR, S_IFLNK, S_IFMT, and S_IFREG, are available.

File mode constants#
The following constants are meant for use with the <fs.Stats> object's mode property for determining the access permissions for a file.

Constant	Description
S_IRWXU	File mode indicating readable, writable, and executable by owner.
S_IRUSR	File mode indicating readable by owner.
S_IWUSR	File mode indicating writable by owner.
S_IXUSR	File mode indicating executable by owner.
S_IRWXG	File mode indicating readable, writable, and executable by group.
S_IRGRP	File mode indicating readable by group.
S_IWGRP	File mode indicating writable by group.
S_IXGRP	File mode indicating executable by group.
S_IRWXO	File mode indicating readable, writable, and executable by others.
S_IROTH	File mode indicating readable by others.
S_IWOTH	File mode indicating writable by others.
S_IXOTH	File mode indicating executable by others.
On Windows, only S_IRUSR and S_IWUSR are available.

Notes#
Ordering of callback and promise-based operations#
Because they are executed asynchronously by the underlying thread pool, there is no guaranteed ordering when using either the callback or promise-based methods.

For example, the following is prone to error because the fs.stat() operation might complete before the fs.rename() operation:

const fs = require('node:fs');

fs.rename('/tmp/hello', '/tmp/world', (err) => {
  if (err) throw err;
  console.log('renamed complete');
});
fs.stat('/tmp/world', (err, stats) => {
  if (err) throw err;
  console.log(`stats: ${JSON.stringify(stats)}`);
}); COPY
It is important to correctly order the operations by awaiting the results of one before invoking the other:

const { rename, stat } = require('node:fs/promises');

(async function(oldPath, newPath) {
  try {
    await rename(oldPath, newPath);
    const stats = await stat(newPath);
    console.log(`stats: ${JSON.stringify(stats)}`);
  } catch (error) {
    console.error('there was an error:', error.message);
  }
})('/tmp/hello', '/tmp/world');COPY
Or, when using the callback APIs, move the fs.stat() call into the callback of the fs.rename() operation:

const { rename, stat } = require('node:fs/promises');

rename('/tmp/hello', '/tmp/world', (err) => {
  if (err) throw err;
  stat('/tmp/world', (err, stats) => {
    if (err) throw err;
    console.log(`stats: ${JSON.stringify(stats)}`);
  });
});COPY
File paths#
Most fs operations accept file paths that may be specified in the form of a string, a <Buffer>, or a <URL> object using the file: protocol.

String paths#
String paths are interpreted as UTF-8 character sequences identifying the absolute or relative filename. Relative paths will be resolved relative to the current working directory as determined by calling process.cwd().

Example using an absolute path on POSIX:

import { open } from 'node:fs/promises';

let fd;
try {
  fd = await open('/open/some/file.txt', 'r');
  // Do something with the file
} finally {
  await fd?.close();
} COPY
Example using a relative path on POSIX (relative to process.cwd()):

import { open } from 'node:fs/promises';

let fd;
try {
  fd = await open('file.txt', 'r');
  // Do something with the file
} finally {
  await fd?.close();
} COPY
File URL paths#
Added in: v7.6.0
For most node:fs module functions, the path or filename argument may be passed as a <URL> object using the file: protocol.

import { readFileSync } from 'node:fs';

readFileSync(new URL('file:///tmp/hello')); COPY
file: URLs are always absolute paths.

Platform-specific considerations#
On Windows, file: <URL>s with a host name convert to UNC paths, while file: <URL>s with drive letters convert to local absolute paths. file: <URL>s with no host name and no drive letter will result in an error:

import { readFileSync } from 'node:fs';
// On Windows :

// - WHATWG file URLs with hostname convert to UNC path
// file://hostname/p/a/t/h/file => \\hostname\p\a\t\h\file
readFileSync(new URL('file://hostname/p/a/t/h/file'));

// - WHATWG file URLs with drive letters convert to absolute path
// file:///C:/tmp/hello => C:\tmp\hello
readFileSync(new URL('file:///C:/tmp/hello'));

// - WHATWG file URLs without hostname must have a drive letters
readFileSync(new URL('file:///notdriveletter/p/a/t/h/file'));
readFileSync(new URL('file:///c/p/a/t/h/file'));
// TypeError [ERR_INVALID_FILE_URL_PATH]: File URL path must be absolute COPY
file: <URL>s with drive letters must use : as a separator just after the drive letter. Using another separator will result in an error.

On all other platforms, file: <URL>s with a host name are unsupported and will result in an error:

import { readFileSync } from 'node:fs';
// On other platforms:

// - WHATWG file URLs with hostname are unsupported
// file://hostname/p/a/t/h/file => throw!
readFileSync(new URL('file://hostname/p/a/t/h/file'));
// TypeError [ERR_INVALID_FILE_URL_PATH]: must be absolute

// - WHATWG file URLs convert to absolute path
// file:///tmp/hello => /tmp/hello
readFileSync(new URL('file:///tmp/hello')); COPY
A file: <URL> having encoded slash characters will result in an error on all platforms:

import { readFileSync } from 'node:fs';

// On Windows
readFileSync(new URL('file:///C:/p/a/t/h/%2F'));
readFileSync(new URL('file:///C:/p/a/t/h/%2f'));
/* TypeError [ERR_INVALID_FILE_URL_PATH]: File URL path must not include encoded
\ or / characters */

// On POSIX
readFileSync(new URL('file:///p/a/t/h/%2F'));
readFileSync(new URL('file:///p/a/t/h/%2f'));
/* TypeError [ERR_INVALID_FILE_URL_PATH]: File URL path must not include encoded
/ characters */ COPY
On Windows, file: <URL>s having encoded backslash will result in an error:

import { readFileSync } from 'node:fs';

// On Windows
readFileSync(new URL('file:///C:/path/%5C'));
readFileSync(new URL('file:///C:/path/%5c'));
/* TypeError [ERR_INVALID_FILE_URL_PATH]: File URL path must not include encoded
\ or / characters */ COPY
Buffer paths#
Paths specified using a <Buffer> are useful primarily on certain POSIX operating systems that treat file paths as opaque byte sequences. On such systems, it is possible for a single file path to contain sub-sequences that use multiple character encodings. As with string paths, <Buffer> paths may be relative or absolute:

Example using an absolute path on POSIX:

import { open } from 'node:fs/promises';
import { Buffer } from 'node:buffer';

let fd;
try {
  fd = await open(Buffer.from('/open/some/file.txt'), 'r');
  // Do something with the file
} finally {
  await fd?.close();
} COPY
Per-drive working directories on Windows#
On Windows, Node.js follows the concept of per-drive working directory. This behavior can be observed when using a drive path without a backslash. For example fs.readdirSync('C:\\') can potentially return a different result than fs.readdirSync('C:'). For more information, see this MSDN page.

File descriptors#
On POSIX systems, for every process, the kernel maintains a table of currently open files and resources. Each open file is assigned a simple numeric identifier called a file descriptor. At the system-level, all file system operations use these file descriptors to identify and track each specific file. Windows systems use a different but conceptually similar mechanism for tracking resources. To simplify things for users, Node.js abstracts away the differences between operating systems and assigns all open files a numeric file descriptor.

The callback-based fs.open(), and synchronous fs.openSync() methods open a file and allocate a new file descriptor. Once allocated, the file descriptor may be used to read data from, write data to, or request information about the file.

Operating systems limit the number of file descriptors that may be open at any given time so it is critical to close the descriptor when operations are completed. Failure to do so will result in a memory leak that will eventually cause an application to crash.

import { open, close, fstat } from 'node:fs';

function closeFd(fd) {
  close(fd, (err) => {
    if (err) throw err;
  });
}

open('/open/some/file.txt', 'r', (err, fd) => {
  if (err) throw err;
  try {
    fstat(fd, (err, stat) => {
      if (err) {
        closeFd(fd);
        throw err;
      }

      // use stat

      closeFd(fd);
    });
  } catch (err) {
    closeFd(fd);
    throw err;
  }
}); COPY
The promise-based APIs use a <FileHandle> object in place of the numeric file descriptor. These objects are better managed by the system to ensure that resources are not leaked. However, it is still required that they are closed when operations are completed:

import { open } from 'node:fs/promises';

let file;
try {
  file = await open('/open/some/file.txt', 'r');
  const stat = await file.stat();
  // use stat
} finally {
  await file.close();
} COPY
Threadpool usage#
All callback and promise-based file system APIs (with the exception of fs.FSWatcher()) use libuv's threadpool. This can have surprising and negative performance implications for some applications. See the UV_THREADPOOL_SIZE documentation for more information.

File system flags#
The following flags are available wherever the flag option takes a string.

'a': Open file for appending. The file is created if it does not exist.

'ax': Like 'a' but fails if the path exists.

'a+': Open file for reading and appending. The file is created if it does not exist.

'ax+': Like 'a+' but fails if the path exists.

'as': Open file for appending in synchronous mode. The file is created if it does not exist.

'as+': Open file for reading and appending in synchronous mode. The file is created if it does not exist.

'r': Open file for reading. An exception occurs if the file does not exist.

'rs': Open file for reading in synchronous mode. An exception occurs if the file does not exist.

'r+': Open file for reading and writing. An exception occurs if the file does not exist.

'rs+': Open file for reading and writing in synchronous mode. Instructs the operating system to bypass the local file system cache.

This is primarily useful for opening files on NFS mounts as it allows skipping the potentially stale local cache. It has a very real impact on I/O performance so using this flag is not recommended unless it is needed.

This doesn't turn fs.open() or fsPromises.open() into a synchronous blocking call. If synchronous operation is desired, something like fs.openSync() should be used.

'w': Open file for writing. The file is created (if it does not exist) or truncated (if it exists).

'wx': Like 'w' but fails if the path exists.

'w+': Open file for reading and writing. The file is created (if it does not exist) or truncated (if it exists).

'wx+': Like 'w+' but fails if the path exists.

flag can also be a number as documented by open(2); commonly used constants are available from fs.constants. On Windows, flags are translated to their equivalent ones where applicable, e.g. O_WRONLY to FILE_GENERIC_WRITE, or O_EXCL|O_CREAT to CREATE_NEW, as accepted by CreateFileW.

The exclusive flag 'x' (O_EXCL flag in open(2)) causes the operation to return an error if the path already exists. On POSIX, if the path is a symbolic link, using O_EXCL returns an error even if the link is to a path that does not exist. The exclusive flag might not work with network file systems.

On Linux, positional writes don't work when the file is opened in append mode. The kernel ignores the position argument and always appends the data to the end of the file.

Modifying a file rather than replacing it may require the flag option to be set to 'r+' rather than the default 'w'.

The behavior of some flags are platform-specific. As such, opening a directory on macOS and Linux with the 'a+' flag, as in the example below, will return an error. In contrast, on Windows and FreeBSD, a file descriptor or a FileHandle will be returned.

// macOS and Linux
fs.open('<directory>', 'a+', (err, fd) => {
  // => [Error: EISDIR: illegal operation on a directory, open <directory>]
});

// Windows and FreeBSD
fs.open('<directory>', 'a+', (err, fd) => {
  // => null, <fd>
}); COPY
On Windows, opening an existing hidden file using the 'w' flag (either through fs.open(), fs.writeFile(), or fsPromises.open()) will fail with EPERM. Existing hidden files can be opened for writing with the 'r+' flag.

A call to fs.ftruncate() or filehandle.truncate() can be used to reset the file contents.

Skip to main content
Skip to search
Skip to select language
Get real-time assistance with your coding queries. Try AI Help now!

References
Guides
Plus
Curriculum
Blog
Tools
NEW
Search MDN
â€„â€„â€„

SEARCH

Theme
Log in
Sign up for free
References
JavaScript
Reference
Standard built-in objects
Promise

English (US)
Filter sidebar
Filter
Standard built-in objects
Promise
Constructor
Promise() constructor
Static methods
Promise.all()
Promise.allSettled()
Promise.any()
Promise.race()
Promise.reject()
Promise.resolve()
Promise.withResolvers()
Static properties
Promise[Symbol.species]
Instance methods
Promise.prototype.catch()
Promise.prototype.finally()
Promise.prototype.then()
Inheritance
Object/Function
Static methods
Static properties
Instance methods
Instance properties
In this article
Description
Constructor
Static properties
Static methods
Instance properties
Instance methods
Examples
Specifications
Browser compatibility
See also
Promise
Baseline Widely available
The Promise object represents the eventual completion (or failure) of an asynchronous operation and its resulting value.

To learn about the way promises work and how you can use them, we advise you to read Using promises first.

Description
A Promise is a proxy for a value not necessarily known when the promise is created. It allows you to associate handlers with an asynchronous action's eventual success value or failure reason. This lets asynchronous methods return values like synchronous methods: instead of immediately returning the final value, the asynchronous method returns a promise to supply the value at some point in the future.

A Promise is in one of these states:

pending: initial state, neither fulfilled nor rejected.
fulfilled: meaning that the operation was completed successfully.
rejected: meaning that the operation failed.
The eventual state of a pending promise can either be fulfilled with a value or rejected with a reason (error). When either of these options occur, the associated handlers queued up by a promise's then method are called. If the promise has already been fulfilled or rejected when a corresponding handler is attached, the handler will be called, so there is no race condition between an asynchronous operation completing and its handlers being attached.

A promise is said to be settled if it is either fulfilled or rejected, but not pending.

Flowchart showing how the Promise state transitions between pending, fulfilled, and rejected via then/catch handlers. A pending promise can become either fulfilled or rejected. If fulfilled, the "on fulfillment" handler, or first parameter of the then() method, is executed and carries out further asynchronous actions. If rejected, the error handler, either passed as the second parameter of the then() method or as the sole parameter of the catch() method, gets executed.
You will also hear the term resolved used with promises â€” this means that the promise is settled or "locked-in" to match the eventual state of another promise, and further resolving or rejecting it has no effect. The States and fates document from the original Promise proposal contains more details about promise terminology. Colloquially, "resolved" promises are often equivalent to "fulfilled" promises, but as illustrated in "States and fates", resolved promises can be pending or rejected as well. For example:

JS
Copy to Clipboard
new Promise((resolveOuter) => {
  resolveOuter(
    new Promise((resolveInner) => {
      setTimeout(resolveInner, 1000);
    }),
  );
});
This promise is already resolved at the time when it's created (because the resolveOuter is called synchronously), but it is resolved with another promise, and therefore won't be fulfilled until 1 second later, when the inner promise fulfills. In practice, the "resolution" is often done behind the scenes and not observable, and only its fulfillment or rejection are.

Note: Several other languages have mechanisms for lazy evaluation and deferring a computation, which they also call "promises", e.g. Scheme. Promises in JavaScript represent processes that are already happening, which can be chained with callback functions. If you are looking to lazily evaluate an expression, consider using a function with no arguments e.g. f = () => expression to create the lazily-evaluated expression, and f() to evaluate the expression immediately.

Promise itself has no first-class protocol for cancellation, but you may be able to directly cancel the underlying asynchronous operation, typically using AbortController.

Chained Promises
The promise methods then(), catch(), and finally() are used to associate further action with a promise that becomes settled. The then() method takes up to two arguments; the first argument is a callback function for the fulfilled case of the promise, and the second argument is a callback function for the rejected case. The catch() and finally() methods call then() internally and make error handling less verbose. For example, a catch() is really just a then() without passing the fulfillment handler. As these methods return promises, they can be chained. For example:

JS
Copy to Clipboard
const myPromise = new Promise((resolve, reject) => {
  setTimeout(() => {
    resolve("foo");
  }, 300);
});

myPromise
  .then(handleFulfilledA, handleRejectedA)
  .then(handleFulfilledB, handleRejectedB)
  .then(handleFulfilledC, handleRejectedC);
We will use the following terminology: initial promise is the promise on which then is called; new promise is the promise returned by then. The two callbacks passed to then are called fulfillment handler and rejection handler, respectively.

The settled state of the initial promise determines which handler to execute.

If the initial promise is fulfilled, the fulfillment handler is called with the fulfillment value.
If the initial promise is rejected, the rejection handler is called with the rejection reason.
The completion of the handler function determines the settled state of the new promise.

If the handler function returns a thenable value, the new promise settles in the same state as the returned promise.
If the handler function returns a non-thenable value, the new promise is fulfilled with the returned value.
If the handler function throws an error, the new promise is rejected with the thrown error.
If the initial promise has no corresponding handler attached, the new promise will settle to the same state as the initial promise â€” that is, without a rejection handler, a rejected promise stays rejected with the same reason.
For example, in the code above, if myPromise rejects, handleRejectedA will be called, and if handleRejectedA completes normally (without throwing or returning a rejected promise), the promise returned by the first then will be fulfilled instead of staying rejected. Therefore, if an error must be handled immediately, but we want to maintain the error state down the chain, we must throw an error of some type in the rejection handler. On the other hand, in the absence of an immediate need, it is simpler to leave out error handling until the final catch() handler.

JS
Copy to Clipboard
myPromise
  .then(handleFulfilledA)
  .then(handleFulfilledB)
  .then(handleFulfilledC)
  .catch(handleRejectedAny);
Using arrow functions for the callback functions, implementation of the promise chain might look something like this:

JS
Copy to Clipboard
myPromise
  .then((value) => `${value} and bar`)
  .then((value) => `${value} and bar again`)
  .then((value) => `${value} and again`)
  .then((value) => `${value} and again`)
  .then((value) => {
    console.log(value);
  })
  .catch((err) => {
    console.error(err);
  });
Note: For faster execution, all synchronous actions should preferably be done within one handler, otherwise it would take several ticks to execute all handlers in sequence.

JavaScript maintains a job queue. Each time, JavaScript picks a job from the queue and executes it to completion. The jobs are defined by the executor of the Promise() constructor, the handlers passed to then, or any platform API that returns a promise. The promises in a chain represent the dependency relationship between these jobs. When a promise settles, the respective handlers associated with it are added to the back of the job queue.

A promise can participate in more than one chain. For the following code, the fulfillment of promiseA will cause both handleFulfilled1 and handleFulfilled2 to be added to the job queue. Because handleFulfilled1 is registered first, it will be invoked first.

JS
Copy to Clipboard
const promiseA = new Promise(myExecutorFunc);
const promiseB = promiseA.then(handleFulfilled1, handleRejected1);
const promiseC = promiseA.then(handleFulfilled2, handleRejected2);
An action can be assigned to an already settled promise. In this case, the action is added immediately to the back of the job queue and will be performed when all existing jobs are completed. Therefore, an action for an already "settled" promise will occur only after the current synchronous code completes and at least one loop-tick has passed. This guarantees that promise actions are asynchronous.

JS
Copy to Clipboard
const promiseA = new Promise((resolve, reject) => {
  resolve(777);
});
// At this point, "promiseA" is already settled.
promiseA.then((val) => console.log("asynchronous logging has val:", val));
console.log("immediate logging");

// produces output in this order:
// immediate logging
// asynchronous logging has val: 777
Thenables
The JavaScript ecosystem had made multiple Promise implementations long before it became part of the language. Despite being represented differently internally, at the minimum, all Promise-like objects implement the Thenable interface. A thenable implements the .then() method, which is called with two callbacks: one for when the promise is fulfilled, one for when it's rejected. Promises are thenables as well.

To interoperate with the existing Promise implementations, the language allows using thenables in place of promises. For example, Promise.resolve will not only resolve promises, but also trace thenables.

JS
Copy to Clipboard
const aThenable = {
  then(onFulfilled, onRejected) {
    onFulfilled({
      // The thenable is fulfilled with another thenable
      then(onFulfilled, onRejected) {
        onFulfilled(42);
      },
    });
  },
};

Promise.resolve(aThenable); // A promise fulfilled with 42
Promise concurrency
The Promise class offers four static methods to facilitate async task concurrency:

Promise.all()
Fulfills when all of the promises fulfill; rejects when any of the promises rejects.

Promise.allSettled()
Fulfills when all promises settle.

Promise.any()
Fulfills when any of the promises fulfills; rejects when all of the promises reject.

Promise.race()
Settles when any of the promises settles. In other words, fulfills when any of the promises fulfills; rejects when any of the promises rejects.

All these methods take an iterable of promises (thenables, to be exact) and return a new promise. They all support subclassing, which means they can be called on subclasses of Promise, and the result will be a promise of the subclass type. To do so, the subclass's constructor must implement the same signature as the Promise() constructor â€” accepting a single executor function that can be called with the resolve and reject callbacks as parameters. The subclass must also have a resolve static method that can be called like Promise.resolve() to resolve values to promises.

Note that JavaScript is single-threaded by nature, so at a given instant, only one task will be executing, although control can shift between different promises, making execution of the promises appear concurrent. Parallel execution in JavaScript can only be achieved through worker threads.

Constructor
Promise()
Creates a new Promise object. The constructor is primarily used to wrap functions that do not already support promises.

Static properties
Promise[Symbol.species]
Returns the constructor used to construct return values from promise methods.

Static methods
Promise.all()
Takes an iterable of promises as input and returns a single Promise. This returned promise fulfills when all of the input's promises fulfill (including when an empty iterable is passed), with an array of the fulfillment values. It rejects when any of the input's promises reject, with this first rejection reason.

Promise.allSettled()
Takes an iterable of promises as input and returns a single Promise. This returned promise fulfills when all of the input's promises settle (including when an empty iterable is passed), with an array of objects that describe the outcome of each promise.

Promise.any()
Takes an iterable of promises as input and returns a single Promise. This returned promise fulfills when any of the input's promises fulfill, with this first fulfillment value. It rejects when all of the input's promises reject (including when an empty iterable is passed), with an AggregateError containing an array of rejection reasons.

Promise.race()
Takes an iterable of promises as input and returns a single Promise. This returned promise settles with the eventual state of the first promise that settles.

Promise.reject()
Returns a new Promise object that is rejected with the given reason.

Promise.resolve()
Returns a Promise object that is resolved with the given value. If the value is a thenable (i.e. has a then method), the returned promise will "follow" that thenable, adopting its eventual state; otherwise, the returned promise will be fulfilled with the value.

Promise.withResolvers()
Returns an object containing a new Promise object and two functions to resolve or reject it, corresponding to the two parameters passed to the executor of the Promise() constructor.

Instance properties
These properties are defined on Promise.prototype and shared by all Promise instances.

Promise.prototype.constructor
The constructor function that created the instance object. For Promise instances, the initial value is the Promise constructor.

Promise.prototype[Symbol.toStringTag]
The initial value of the [Symbol.toStringTag] property is the string "Promise". This property is used in Object.prototype.toString().

Instance methods
Promise.prototype.catch()
Appends a rejection handler callback to the promise, and returns a new promise resolving to the return value of the callback if it is called, or to its original fulfillment value if the promise is instead fulfilled.

Promise.prototype.finally()
Appends a handler to the promise, and returns a new promise that is resolved when the original promise is resolved. The handler is called when the promise is settled, whether fulfilled or rejected.

Promise.prototype.then()
Appends fulfillment and rejection handlers to the promise, and returns a new promise resolving to the return value of the called handler, or to its original settled value if the promise was not handled (i.e. if the relevant handler onFulfilled or onRejected is not a function).

Examples
Basic Example
JS
Copy to Clipboard
const myFirstPromise = new Promise((resolve, reject) => {
  // We call resolve(...) when what we were doing asynchronously was successful, and reject(...) when it failed.
  // In this example, we use setTimeout(...) to simulate async code.
  // In reality, you will probably be using something like XHR or an HTML API.
  setTimeout(() => {
    resolve("Success!"); // Yay! Everything went well!
  }, 250);
});

myFirstPromise.then((successMessage) => {
  // successMessage is whatever we passed in the resolve(...) function above.
  // It doesn't have to be a string, but if it is only a succeed message, it probably will be.
  console.log(`Yay! ${successMessage}`);
});
Example with diverse situations
This example shows diverse techniques for using Promise capabilities and diverse situations that can occur. To understand this, start by scrolling to the bottom of the code block, and examine the promise chain. Upon provision of an initial promise, a chain of promises can follow. The chain is composed of .then() calls, and typically (but not necessarily) has a single .catch() at the end, optionally followed by .finally(). In this example, the promise chain is initiated by a custom-written new Promise() construct; but in actual practice, promise chains more typically start with an API function (written by someone else) that returns a promise.

The example function tetheredGetNumber() shows that a promise generator will utilize reject() while setting up an asynchronous call, or within the call-back, or both. The function promiseGetWord() illustrates how an API function might generate and return a promise in a self-contained manner.

Note that the function troubleWithGetNumber() ends with a throw. That is forced because a promise chain goes through all the .then() promises, even after an error, and without the throw, the error would seem "fixed". This is a hassle, and for this reason, it is common to omit onRejected throughout the chain of .then() promises, and just have a single onRejected in the final catch().

This code can be run under NodeJS. Comprehension is enhanced by seeing the errors actually occur. To force more errors, change the threshold values.

JS
Copy to Clipboard
// To experiment with error handling, "threshold" values cause errors randomly
const THRESHOLD_A = 8; // can use zero 0 to guarantee error

function tetheredGetNumber(resolve, reject) {
  setTimeout(() => {
    const randomInt = Date.now();
    const value = randomInt % 10;
    if (value < THRESHOLD_A) {
      resolve(value);
    } else {
      reject(`Too large: ${value}`);
    }
  }, 500);
}

function determineParity(value) {
  const isOdd = value % 2 === 1;
  return { value, isOdd };
}

function troubleWithGetNumber(reason) {
  const err = new Error("Trouble getting number", { cause: reason });
  console.error(err);
  throw err;
}

function promiseGetWord(parityInfo) {
  return new Promise((resolve, reject) => {
    const { value, isOdd } = parityInfo;
    if (value >= THRESHOLD_A - 1) {
      reject(`Still too large: ${value}`);
    } else {
      parityInfo.wordEvenOdd = isOdd ? "odd" : "even";
      resolve(parityInfo);
    }
  });
}

new Promise(tetheredGetNumber)
  .then(determineParity, troubleWithGetNumber)
  .then(promiseGetWord)
  .then((info) => {
    console.log(`Got: ${info.value}, ${info.wordEvenOdd}`);
    return info;
  })
  .catch((reason) => {
    if (reason.cause) {
      console.error("Had previously handled error");
    } else {
      console.error(`Trouble with promiseGetWord(): ${reason}`);
    }
  })
  .finally((info) => console.log("All done"));
Advanced Example
This small example shows the mechanism of a Promise. The testPromise() method is called each time the <button> is clicked. It creates a promise that will be fulfilled, using setTimeout(), to the promise count (number starting from 1) every 1-3 seconds, at random. The Promise() constructor is used to create the promise.

The fulfillment of the promise is logged, via a fulfill callback set using p1.then(). A few logs show how the synchronous part of the method is decoupled from the asynchronous completion of the promise.

By clicking the button several times in a short amount of time, you'll even see the different promises being fulfilled one after another.

HTML
HTML
Play
Copy to Clipboard
<button id="make-promise">Make a promise!</button>
<div id="log"></div>
JavaScript
JS
Play
Copy to Clipboard
"use strict";

let promiseCount = 0;

function testPromise() {
  const thisPromiseCount = ++promiseCount;
  const log = document.getElementById("log");
  // begin
  log.insertAdjacentHTML("beforeend", `${thisPromiseCount}) Started<br>`);
  // We make a new promise: we promise a numeric count of this promise,
  // starting from 1 (after waiting 3s)
  const p1 = new Promise((resolve, reject) => {
    // The executor function is called with the ability
    // to resolve or reject the promise
    log.insertAdjacentHTML(
      "beforeend",
      `${thisPromiseCount}) Promise constructor<br>`,
    );
    // This is only an example to create asynchronism
    setTimeout(
      () => {
        // We fulfill the promise
        resolve(thisPromiseCount);
      },
      Math.random() * 2000 + 1000,
    );
  });

  // We define what to do when the promise is resolved with the then() call,
  // and what to do when the promise is rejected with the catch() call
  p1.then((val) => {
    // Log the fulfillment value
    log.insertAdjacentHTML("beforeend", `${val}) Promise fulfilled<br>`);
  }).catch((reason) => {
    // Log the rejection reason
    console.log(`Handle rejected promise (${reason}) here.`);
  });
  // end
  log.insertAdjacentHTML("beforeend", `${thisPromiseCount}) Promise made<br>`);
}

const btn = document.getElementById("make-promise");
btn.addEventListener("click", testPromise);
Result
Play

Loading an image with XHR
Another simple example using Promise and XMLHttpRequest to load an image is available at the MDN GitHub js-examples repository. You can also see it in action. Each step is commented on and allows you to follow the Promise and XHR architecture closely.

Incumbent settings object tracking
A settings object is an environment that provides additional information when JavaScript code is running. This includes the realm and module map, as well as HTML specific information such as the origin. The incumbent settings object is tracked in order to ensure that the browser knows which one to use for a given piece of user code.

To better picture this, we can take a closer look at how the realm might be an issue. A realm can be roughly thought of as the global object. What is unique about realms is that they hold all of the necessary information to run JavaScript code. This includes objects like Array and Error. Each settings object has its own "copy" of these and they are not shared. That can cause some unexpected behavior in relation to promises. In order to get around this, we track something called the incumbent settings object. This represents information specific to the context of the user code responsible for a certain function call.

To illustrate this a bit further we can take a look at how an <iframe> embedded in a document communicates with its host. Since all web APIs are aware of the incumbent settings object, the following will work in all browsers:

HTML
Copy to Clipboard
<!doctype html> <iframe></iframe>
<!-- we have a realm here -->
<script>
  // we have a realm here as well
  const bound = frames[0].postMessage.bind(frames[0], "some data", "*");
  // bound is a built-in function â€” there is no user
  // code on the stack, so which realm do we use?
  setTimeout(bound);
  // this still works, because we use the youngest
  // realm (the incumbent) on the stack
</script>
The same concept applies to promises. If we modify the above example a little bit, we get this:

HTML
Copy to Clipboard
<!doctype html> <iframe></iframe>
<!-- we have a realm here -->
<script>
  // we have a realm here as well
  const bound = frames[0].postMessage.bind(frames[0], "some data", "*");
  // bound is a built in function â€” there is no user
  // code on the stack â€” which realm do we use?
  Promise.resolve(undefined).then(bound);
  // this still works, because we use the youngest
  // realm (the incumbent) on the stack
</script>
If we change this so that the <iframe> in the document is listening to post messages, we can observe the effect of the incumbent settings object:

HTML
Copy to Clipboard
<!-- y.html -->
<!doctype html>
<iframe src="x.html"></iframe>
<script>
  const bound = frames[0].postMessage.bind(frames[0], "some data", "*");
  Promise.resolve(undefined).then(bound);
</script>
HTML
Copy to Clipboard
<!-- x.html -->
<!doctype html>
<script>
  window.addEventListener(
    "message",
    (event) => {
      document.querySelector("#text").textContent = "hello";
      // this code will only run in browsers that track the incumbent settings object
      console.log(event);
    },
    false,
  );
</script>
In the above example, the inner text of the <iframe> will be updated only if the incumbent settings object is tracked. This is because without tracking the incumbent, we may end up using the wrong environment to send the message.

Note: Currently, incumbent realm tracking is fully implemented in Firefox, and has partial implementations in Chrome and Safari.

Specifications
Specification
ECMAScript Language Specification
# sec-promise-objects
Browser compatibility
Report problems with this compatibility data on GitHub
desktop	mobile	server
Chrome
Edge
Firefox
Opera
Safari
Chrome Android
Firefox for Android
Opera Android
Safari on iOS
Samsung Internet
WebView Android
Deno
Node.js
Promise

32
Toggle history	
12
Toggle history	
29
Toggle history	
19
Toggle history	
8
Toggle history	
32
Toggle history	
29
Toggle history	
19
Toggle history	
8
Toggle history	
2.0
Toggle history	
4.4.3
Toggle history	
1.0
Toggle history	
0.12.0
Toggle history
@@species

51
Toggle history	
79
Toggle history	
48
Toggle history	
38
Toggle history	
10
Toggle history	
51
Toggle history	
48
Toggle history	
41
Toggle history	
10
Toggle history	
5.0
Toggle history	
51
Toggle history	
1.0
Toggle history	
6.5.0
Toggle history
Promise() constructor

32
Toggle history	
12
Toggle history	
29
footnote
Toggle history	
19
Toggle history	
8
footnote
Toggle history	
32
Toggle history	
29
footnote
Toggle history	
19
Toggle history	
8
footnote
Toggle history	
2.0
Toggle history	
4.4.3
Toggle history	
1.0
Toggle history	
0.12.0
footnote
Toggle history
all()

32
Toggle history	
12
Toggle history	
29
Toggle history	
19
Toggle history	
8
Toggle history	
32
Toggle history	
29
Toggle history	
19
Toggle history	
8
Toggle history	
2.0
Toggle history	
4.4.3
Toggle history	
1.0
Toggle history	
0.12.0
Toggle history
allSettled()

76
Toggle history	
79
Toggle history	
71
Toggle history	
63
Toggle history	
13
Toggle history	
76
Toggle history	
79
Toggle history	
54
Toggle history	
13
Toggle history	
12.0
Toggle history	
76
Toggle history	
1.0
Toggle history	
12.9.0
Toggle history
any

85
Toggle history	
85
Toggle history	
79
Toggle history	
71
Toggle history	
14
Toggle history	
85
Toggle history	
79
Toggle history	
60
Toggle history	
14
Toggle history	
14.0
Toggle history	
85
Toggle history	
1.2
Toggle history	
15.0.0
Toggle history
catch()

32
Toggle history	
12
Toggle history	
29
Toggle history	
19
Toggle history	
8
Toggle history	
32
Toggle history	
29
Toggle history	
19
Toggle history	
8
Toggle history	
2.0
Toggle history	
4.4.3
Toggle history	
1.0
Toggle history	
0.12.0
Toggle history
finally()

63
Toggle history	
18
Toggle history	
58
Toggle history	
50
Toggle history	
11.1
Toggle history	
63
Toggle history	
58
Toggle history	
46
Toggle history	
11.3
Toggle history	
8.0
Toggle history	
63
Toggle history	
1.0
Toggle history	
10.0.0
Toggle history
Incumbent settings object tracking

No
Toggle history	
No
Toggle history	
50
Toggle history	
No
Toggle history	
No
Toggle history	
No
Toggle history	
50
Toggle history	
No
Toggle history	
No
Toggle history	
No
Toggle history	
No
Toggle history	
No
Toggle history	
No
Toggle history
race()

32
Toggle history	
12
Toggle history	
29
Toggle history	
19
Toggle history	
8
Toggle history	
32
Toggle history	
29
Toggle history	
19
Toggle history	
8
Toggle history	
2.0
Toggle history	
4.4.3
Toggle history	
1.0
Toggle history	
0.12.0
Toggle history
reject()

32
Toggle history	
12
Toggle history	
29
Toggle history	
19
Toggle history	
8
Toggle history	
32
Toggle history	
29
Toggle history	
19
Toggle history	
8
Toggle history	
2.0
Toggle history	
4.4.3
Toggle history	
1.0
Toggle history	
0.12.0
Toggle history
resolve()

32
Toggle history	
12
Toggle history	
29
Toggle history	
19
Toggle history	
8
Toggle history	
32
Toggle history	
29
Toggle history	
19
Toggle history	
8
Toggle history	
2.0
Toggle history	
4.4.3
Toggle history	
1.0
Toggle history	
0.12.0
Toggle history
then()

32
Toggle history	
12
Toggle history	
29
Toggle history	
19
Toggle history	
8
Toggle history	
32
Toggle history	
29
Toggle history	
19
Toggle history	
8
Toggle history	
2.0
Toggle history	
4.4.3
Toggle history	
1.0
Toggle history	
0.12.0
Toggle history
withResolvers

119
Toggle history	
119
Toggle history	
121
Toggle history	
105
Toggle history	
17.4
Toggle history	
119
Toggle history	
121
Toggle history	
79
Toggle history	
17.4
Toggle history	
25.0
Toggle history	
119
Toggle history	
1.38
Toggle history	
22.0.0
Toggle history
Legend
Tip: you can click/tap on a cell for more information.

Full support
Full support
No support
No support
See implementation notes.
See also
Polyfill of Promise in core-js
Using promises guide
Promises/A+ specification
JavaScript Promises: an introduction on web.dev (2013)
Callbacks, Promises, and Coroutines: Asynchronous Programming Patterns in JavaScript slide show by Domenic Denicola (2011)
Help improve MDN

Was this page helpful to you?

Yes

No
Learn how to contribute.
This page was last modified on Jul 15, 2024 by MDN contributors.

View this page on GitHub â€¢ Report a problem with this content
Your blueprint for a better internet.

MDN on Mastodon
MDN on X (formerly Twitter)
MDN on GitHub
MDN Blog RSS Feed
MDN
About
Blog
Careers
Advertise with us
Support
Product help
Report an issue
Our communities
MDN Community
MDN Forum
MDN Chat
Developers
Web Technologies
Learn Web Development
MDN Plus
Hacks Blog
Website Privacy Notice
Cookies
Legal
Community Participation Guidelines
Visit Mozilla Corporationâ€™s not-for-profit parent, the Mozilla Foundation.
Portions of this content are Â©1998â€“2024 by individual mozilla.org contributors. Content available under a Creative Commons license.


import DatasetController from '../core/core.datasetController.js';
import {
  _arrayUnique, isArray, isNullOrUndef,
  valueOrDefault, resolveObjectKey, sign, defined
} from '../helpers/index.js';

function getAllScaleValues(scale, type) {
  if (!scale._cache.$bar) {
    const visibleMetas = scale.getMatchingVisibleMetas(type);
    let values = [];

    for (let i = 0, ilen = visibleMetas.length; i < ilen; i++) {
      values = values.concat(visibleMetas[i].controller.getAllParsedValues(scale));
    }
    scale._cache.$bar = _arrayUnique(values.sort((a, b) => a - b));
  }
  return scale._cache.$bar;
}

/**
 * Computes the "optimal" sample size to maintain bars equally sized while preventing overlap.
 * @private
 */
function computeMinSampleSize(meta) {
  const scale = meta.iScale;
  const values = getAllScaleValues(scale, meta.type);
  let min = scale._length;
  let i, ilen, curr, prev;
  const updateMinAndPrev = () => {
    if (curr === 32767 || curr === -32768) {
      // Ignore truncated pixels
      return;
    }
    if (defined(prev)) {
      // curr - prev === 0 is ignored
      min = Math.min(min, Math.abs(curr - prev) || min);
    }
    prev = curr;
  };

  for (i = 0, ilen = values.length; i < ilen; ++i) {
    curr = scale.getPixelForValue(values[i]);
    updateMinAndPrev();
  }

  prev = undefined;
  for (i = 0, ilen = scale.ticks.length; i < ilen; ++i) {
    curr = scale.getPixelForTick(i);
    updateMinAndPrev();
  }

  return min;
}

/**
 * Computes an "ideal" category based on the absolute bar thickness or, if undefined or null,
 * uses the smallest interval (see computeMinSampleSize) that prevents bar overlapping. This
 * mode currently always generates bars equally sized (until we introduce scriptable options?).
 * @private
 */
function computeFitCategoryTraits(index, ruler, options, stackCount) {
  const thickness = options.barThickness;
  let size, ratio;

  if (isNullOrUndef(thickness)) {
    size = ruler.min * options.categoryPercentage;
    ratio = options.barPercentage;
  } else {
    // When bar thickness is enforced, category and bar percentages are ignored.
    // Note(SB): we could add support for relative bar thickness (e.g. barThickness: '50%')
    // and deprecate barPercentage since this value is ignored when thickness is absolute.
    size = thickness * stackCount;
    ratio = 1;
  }

  return {
    chunk: size / stackCount,
    ratio,
    start: ruler.pixels[index] - (size / 2)
  };
}

/**
 * Computes an "optimal" category that globally arranges bars side by side (no gap when
 * percentage options are 1), based on the previous and following categories. This mode
 * generates bars with different widths when data are not evenly spaced.
 * @private
 */
function computeFlexCategoryTraits(index, ruler, options, stackCount) {
  const pixels = ruler.pixels;
  const curr = pixels[index];
  let prev = index > 0 ? pixels[index - 1] : null;
  let next = index < pixels.length - 1 ? pixels[index + 1] : null;
  const percent = options.categoryPercentage;

  if (prev === null) {
    // first data: its size is double based on the next point or,
    // if it's also the last data, we use the scale size.
    prev = curr - (next === null ? ruler.end - ruler.start : next - curr);
  }

  if (next === null) {
    // last data: its size is also double based on the previous point.
    next = curr + curr - prev;
  }

  const start = curr - (curr - Math.min(prev, next)) / 2 * percent;
  const size = Math.abs(next - prev) / 2 * percent;

  return {
    chunk: size / stackCount,
    ratio: options.barPercentage,
    start
  };
}

function parseFloatBar(entry, item, vScale, i) {
  const startValue = vScale.parse(entry[0], i);
  const endValue = vScale.parse(entry[1], i);
  const min = Math.min(startValue, endValue);
  const max = Math.max(startValue, endValue);
  let barStart = min;
  let barEnd = max;

  if (Math.abs(min) > Math.abs(max)) {
    barStart = max;
    barEnd = min;
  }

  // Store `barEnd` (furthest away from origin) as parsed value,
  // to make stacking straight forward
  item[vScale.axis] = barEnd;

  item._custom = {
    barStart,
    barEnd,
    start: startValue,
    end: endValue,
    min,
    max
  };
}

function parseValue(entry, item, vScale, i) {
  if (isArray(entry)) {
    parseFloatBar(entry, item, vScale, i);
  } else {
    item[vScale.axis] = vScale.parse(entry, i);
  }
  return item;
}

function parseArrayOrPrimitive(meta, data, start, count) {
  const iScale = meta.iScale;
  const vScale = meta.vScale;
  const labels = iScale.getLabels();
  const singleScale = iScale === vScale;
  const parsed = [];
  let i, ilen, item, entry;

  for (i = start, ilen = start + count; i < ilen; ++i) {
    entry = data[i];
    item = {};
    item[iScale.axis] = singleScale || iScale.parse(labels[i], i);
    parsed.push(parseValue(entry, item, vScale, i));
  }
  return parsed;
}

function isFloatBar(custom) {
  return custom && custom.barStart !== undefined && custom.barEnd !== undefined;
}

function barSign(size, vScale, actualBase) {
  if (size !== 0) {
    return sign(size);
  }
  return (vScale.isHorizontal() ? 1 : -1) * (vScale.min >= actualBase ? 1 : -1);
}

function borderProps(properties) {
  let reverse, start, end, top, bottom;
  if (properties.horizontal) {
    reverse = properties.base > properties.x;
    start = 'left';
    end = 'right';
  } else {
    reverse = properties.base < properties.y;
    start = 'bottom';
    end = 'top';
  }
  if (reverse) {
    top = 'end';
    bottom = 'start';
  } else {
    top = 'start';
    bottom = 'end';
  }
  return {start, end, reverse, top, bottom};
}

function setBorderSkipped(properties, options, stack, index) {
  let edge = options.borderSkipped;
  const res = {};

  if (!edge) {
    properties.borderSkipped = res;
    return;
  }

  if (edge === true) {
    properties.borderSkipped = {top: true, right: true, bottom: true, left: true};
    return;
  }

  const {start, end, reverse, top, bottom} = borderProps(properties);

  if (edge === 'middle' && stack) {
    properties.enableBorderRadius = true;
    if ((stack._top || 0) === index) {
      edge = top;
    } else if ((stack._bottom || 0) === index) {
      edge = bottom;
    } else {
      res[parseEdge(bottom, start, end, reverse)] = true;
      edge = top;
    }
  }

  res[parseEdge(edge, start, end, reverse)] = true;
  properties.borderSkipped = res;
}

function parseEdge(edge, a, b, reverse) {
  if (reverse) {
    edge = swap(edge, a, b);
    edge = startEnd(edge, b, a);
  } else {
    edge = startEnd(edge, a, b);
  }
  return edge;
}

function swap(orig, v1, v2) {
  return orig === v1 ? v2 : orig === v2 ? v1 : orig;
}

function startEnd(v, start, end) {
  return v === 'start' ? start : v === 'end' ? end : v;
}

function setInflateAmount(properties, {inflateAmount}, ratio) {
  properties.inflateAmount = inflateAmount === 'auto'
    ? ratio === 1 ? 0.33 : 0
    : inflateAmount;
}

export default class BarController extends DatasetController {

  static id = 'bar';

  /**
   * @type {any}
   */
  static defaults = {
    datasetElementType: false,
    dataElementType: 'bar',

    categoryPercentage: 0.8,
    barPercentage: 0.9,
    grouped: true,

    animations: {
      numbers: {
        type: 'number',
        properties: ['x', 'y', 'base', 'width', 'height']
      }
    }
  };

  /**
   * @type {any}
   */
  static overrides = {
    scales: {
      _index_: {
        type: 'category',
        offset: true,
        grid: {
          offset: true
        }
      },
      _value_: {
        type: 'linear',
        beginAtZero: true,
      }
    }
  };


  /**
	 * Overriding primitive data parsing since we support mixed primitive/array
	 * data for float bars
	 * @protected
	 */
  parsePrimitiveData(meta, data, start, count) {
    return parseArrayOrPrimitive(meta, data, start, count);
  }

  /**
	 * Overriding array data parsing since we support mixed primitive/array
	 * data for float bars
	 * @protected
	 */
  parseArrayData(meta, data, start, count) {
    return parseArrayOrPrimitive(meta, data, start, count);
  }

  /**
	 * Overriding object data parsing since we support mixed primitive/array
	 * value-scale data for float bars
	 * @protected
	 */
  parseObjectData(meta, data, start, count) {
    const {iScale, vScale} = meta;
    const {xAxisKey = 'x', yAxisKey = 'y'} = this._parsing;
    const iAxisKey = iScale.axis === 'x' ? xAxisKey : yAxisKey;
    const vAxisKey = vScale.axis === 'x' ? xAxisKey : yAxisKey;
    const parsed = [];
    let i, ilen, item, obj;
    for (i = start, ilen = start + count; i < ilen; ++i) {
      obj = data[i];
      item = {};
      item[iScale.axis] = iScale.parse(resolveObjectKey(obj, iAxisKey), i);
      parsed.push(parseValue(resolveObjectKey(obj, vAxisKey), item, vScale, i));
    }
    return parsed;
  }

  /**
	 * @protected
	 */
  updateRangeFromParsed(range, scale, parsed, stack) {
    super.updateRangeFromParsed(range, scale, parsed, stack);
    const custom = parsed._custom;
    if (custom && scale === this._cachedMeta.vScale) {
      // float bar: only one end of the bar is considered by `super`
      range.min = Math.min(range.min, custom.min);
      range.max = Math.max(range.max, custom.max);
    }
  }

  /**
	 * @return {number|boolean}
	 * @protected
	 */
  getMaxOverflow() {
    return 0;
  }

  /**
	 * @protected
	 */
  getLabelAndValue(index) {
    const meta = this._cachedMeta;
    const {iScale, vScale} = meta;
    const parsed = this.getParsed(index);
    const custom = parsed._custom;
    const value = isFloatBar(custom)
      ? '[' + custom.start + ', ' + custom.end + ']'
      : '' + vScale.getLabelForValue(parsed[vScale.axis]);

    return {
      label: '' + iScale.getLabelForValue(parsed[iScale.axis]),
      value
    };
  }

  initialize() {
    this.enableOptionSharing = true;

    super.initialize();

    const meta = this._cachedMeta;
    meta.stack = this.getDataset().stack;
  }

  update(mode) {
    const meta = this._cachedMeta;
    this.updateElements(meta.data, 0, meta.data.length, mode);
  }

  updateElements(bars, start, count, mode) {
    const reset = mode === 'reset';
    const {index, _cachedMeta: {vScale}} = this;
    const base = vScale.getBasePixel();
    const horizontal = vScale.isHorizontal();
    const ruler = this._getRuler();
    const {sharedOptions, includeOptions} = this._getSharedOptions(start, mode);

    for (let i = start; i < start + count; i++) {
      const parsed = this.getParsed(i);
      const vpixels = reset || isNullOrUndef(parsed[vScale.axis]) ? {base, head: base} : this._calculateBarValuePixels(i);
      const ipixels = this._calculateBarIndexPixels(i, ruler);
      const stack = (parsed._stacks || {})[vScale.axis];

      const properties = {
        horizontal,
        base: vpixels.base,
        enableBorderRadius: !stack || isFloatBar(parsed._custom) || (index === stack._top || index === stack._bottom),
        x: horizontal ? vpixels.head : ipixels.center,
        y: horizontal ? ipixels.center : vpixels.head,
        height: horizontal ? ipixels.size : Math.abs(vpixels.size),
        width: horizontal ? Math.abs(vpixels.size) : ipixels.size
      };

      if (includeOptions) {
        properties.options = sharedOptions || this.resolveDataElementOptions(i, bars[i].active ? 'active' : mode);
      }
      const options = properties.options || bars[i].options;
      setBorderSkipped(properties, options, stack, index);
      setInflateAmount(properties, options, ruler.ratio);
      this.updateElement(bars[i], i, properties, mode);
    }
  }

  /**
	 * Returns the stacks based on groups and bar visibility.
	 * @param {number} [last] - The dataset index
	 * @param {number} [dataIndex] - The data index of the ruler
	 * @returns {string[]} The list of stack IDs
	 * @private
	 */
  _getStacks(last, dataIndex) {
    const {iScale} = this._cachedMeta;
    const metasets = iScale.getMatchingVisibleMetas(this._type)
      .filter(meta => meta.controller.options.grouped);
    const stacked = iScale.options.stacked;
    const stacks = [];

    const skipNull = (meta) => {
      const parsed = meta.controller.getParsed(dataIndex);
      const val = parsed && parsed[meta.vScale.axis];

      if (isNullOrUndef(val) || isNaN(val)) {
        return true;
      }
    };

    for (const meta of metasets) {
      if (dataIndex !== undefined && skipNull(meta)) {
        continue;
      }

      // stacked   | meta.stack
      //           | found | not found | undefined
      // false     |   x   |     x     |     x
      // true      |       |     x     |
      // undefined |       |     x     |     x
      if (stacked === false || stacks.indexOf(meta.stack) === -1 ||
				(stacked === undefined && meta.stack === undefined)) {
        stacks.push(meta.stack);
      }
      if (meta.index === last) {
        break;
      }
    }

    // No stacks? that means there is no visible data. Let's still initialize an `undefined`
    // stack where possible invisible bars will be located.
    // https://github.com/chartjs/Chart.js/issues/6368
    if (!stacks.length) {
      stacks.push(undefined);
    }

    return stacks;
  }

  /**
	 * Returns the effective number of stacks based on groups and bar visibility.
	 * @private
	 */
  _getStackCount(index) {
    return this._getStacks(undefined, index).length;
  }

  /**
	 * Returns the stack index for the given dataset based on groups and bar visibility.
	 * @param {number} [datasetIndex] - The dataset index
	 * @param {string} [name] - The stack name to find
   * @param {number} [dataIndex]
	 * @returns {number} The stack index
	 * @private
	 */
  _getStackIndex(datasetIndex, name, dataIndex) {
    const stacks = this._getStacks(datasetIndex, dataIndex);
    const index = (name !== undefined)
      ? stacks.indexOf(name)
      : -1; // indexOf returns -1 if element is not present

    return (index === -1)
      ? stacks.length - 1
      : index;
  }

  /**
	 * @private
	 */
  _getRuler() {
    const opts = this.options;
    const meta = this._cachedMeta;
    const iScale = meta.iScale;
    const pixels = [];
    let i, ilen;

    for (i = 0, ilen = meta.data.length; i < ilen; ++i) {
      pixels.push(iScale.getPixelForValue(this.getParsed(i)[iScale.axis], i));
    }

    const barThickness = opts.barThickness;
    const min = barThickness || computeMinSampleSize(meta);

    return {
      min,
      pixels,
      start: iScale._startPixel,
      end: iScale._endPixel,
      stackCount: this._getStackCount(),
      scale: iScale,
      grouped: opts.grouped,
      // bar thickness ratio used for non-grouped bars
      ratio: barThickness ? 1 : opts.categoryPercentage * opts.barPercentage
    };
  }

  /**
	 * Note: pixel values are not clamped to the scale area.
	 * @private
	 */
  _calculateBarValuePixels(index) {
    const {_cachedMeta: {vScale, _stacked, index: datasetIndex}, options: {base: baseValue, minBarLength}} = this;
    const actualBase = baseValue || 0;
    const parsed = this.getParsed(index);
    const custom = parsed._custom;
    const floating = isFloatBar(custom);
    let value = parsed[vScale.axis];
    let start = 0;
    let length = _stacked ? this.applyStack(vScale, parsed, _stacked) : value;
    let head, size;

    if (length !== value) {
      start = length - value;
      length = value;
    }

    if (floating) {
      value = custom.barStart;
      length = custom.barEnd - custom.barStart;
      // bars crossing origin are not stacked
      if (value !== 0 && sign(value) !== sign(custom.barEnd)) {
        start = 0;
      }
      start += value;
    }

    const startValue = !isNullOrUndef(baseValue) && !floating ? baseValue : start;
    let base = vScale.getPixelForValue(startValue);

    if (this.chart.getDataVisibility(index)) {
      head = vScale.getPixelForValue(start + length);
    } else {
      // When not visible, no height
      head = base;
    }

    size = head - base;

    if (Math.abs(size) < minBarLength) {
      size = barSign(size, vScale, actualBase) * minBarLength;
      if (value === actualBase) {
        base -= size / 2;
      }
      const startPixel = vScale.getPixelForDecimal(0);
      const endPixel = vScale.getPixelForDecimal(1);
      const min = Math.min(startPixel, endPixel);
      const max = Math.max(startPixel, endPixel);
      base = Math.max(Math.min(base, max), min);
      head = base + size;

      if (_stacked && !floating) {
        // visual data coordinates after applying minBarLength
        parsed._stacks[vScale.axis]._visualValues[datasetIndex] = vScale.getValueForPixel(head) - vScale.getValueForPixel(base);
      }
    }

    if (base === vScale.getPixelForValue(actualBase)) {
      const halfGrid = sign(size) * vScale.getLineWidthForValue(actualBase) / 2;
      base += halfGrid;
      size -= halfGrid;
    }

    return {
      size,
      base,
      head,
      center: head + size / 2
    };
  }

  /**
	 * @private
	 */
  _calculateBarIndexPixels(index, ruler) {
    const scale = ruler.scale;
    const options = this.options;
    const skipNull = options.skipNull;
    const maxBarThickness = valueOrDefault(options.maxBarThickness, Infinity);
    let center, size;
    if (ruler.grouped) {
      const stackCount = skipNull ? this._getStackCount(index) : ruler.stackCount;
      const range = options.barThickness === 'flex'
        ? computeFlexCategoryTraits(index, ruler, options, stackCount)
        : computeFitCategoryTraits(index, ruler, options, stackCount);

      const stackIndex = this._getStackIndex(this.index, this._cachedMeta.stack, skipNull ? index : undefined);
      center = range.start + (range.chunk * stackIndex) + (range.chunk / 2);
      size = Math.min(maxBarThickness, range.chunk * range.ratio);
    } else {
      // For non-grouped bar charts, exact pixel values are used
      center = scale.getPixelForValue(this.getParsed(index)[scale.axis], index);
      size = Math.min(maxBarThickness, ruler.min * ruler.ratio);
    }

    return {
      base: center - size / 2,
      head: center + size / 2,
      center,
      size
    };
  }

  draw() {
    const meta = this._cachedMeta;
    const vScale = meta.vScale;
    const rects = meta.data;
    const ilen = rects.length;
    let i = 0;

    for (; i < ilen; ++i) {
      if (this.getParsed(i)[vScale.axis] !== null && !rects[i].hidden) {
        rects[i].draw(this._ctx);
      }
    }
  }

}
/* eslint-disable react/button-has-type */
import { useState } from 'react';
import { useAPI } from 'hooks/use-api';
import { usePageData } from 'hooks/use-page-data';
import { getIndexPageData } from 'api/index-page/get-index-page-data';

export function IndexPage() {
  const [data, setData] = useState([]);
  const [showMore, setShowMore] = useState(false);
  // usePageData Example
  const { reload, pending } = usePageData({
    disabled: false,
    dataCached: true,
    expireTime: 5000,
    apiMethod: getIndexPageData,
    apiData: {
      // ... your API data
      albumId: 1,
      name: 'ramin' // example: remove on inputTransformer
    },
    onSuccess: (response) => setData(response)
    // onError: (error) => console.log('PAGE ERROR:', error)
  });

  // useAPI Example
  const { request, pending: loading } = useAPI({
    apiMethod: getIndexPageData,
    requestDataOnLoad: { albumId: 2 },
    // onError: (error) => console.log('API ERROR:', error),
    onSuccess: (response) => setData(response)
  });

  const apiRequest = () => request();
  const showMoreData = () => setShowMore(true);

  return (
    <div dir='ltr' className='flex flex-col items-center'>
      <h1 className='font-extrabold text-3xl my-5 animate__animated animate__bounce'>
        Index Page
      </h1>

      {/* For reCall & call API */}
      <div className='flex items-center gap-x-4'>
        <button
          className='bg-green-600 text-gray-50 px-3 py-2 rounded-md'
          onClick={reload}
        >
          Load Request API (albumId = 1)
        </button>
        <button
          className='bg-cyan-600 text-gray-50 px-3 py-2 rounded-md'
          onClick={apiRequest}
        >
          Other API Request (albumId = 2)
        </button>
      </div>

      {pending && (
        <div className='w-full my-4 text-center mt-9 text-cyan-700'>LOADING ...</div>
      )}

      <ul className='mx-auto max-w-xl mt-5'>
        {Array.isArray(data) &&
          data?.slice(0, showMore ? data?.length : 3)?.map((item: any, index) => (
            <li
              key={item.url}
              className='flex items-start mb-4 bg-gray-100 p-5 rounded-lg'
            >
              <img className='mr-4 rounded' width={120} src={item.url} alt={item.title} />
              <div className='pt-4'>
                <h3 className='mb-1 font-bold'>
                  {index + 1} - {item.title}
                </h3>
                <p className='text-cyan-600 font-bold'>Album Name: {item.album}</p>
              </div>
            </li>
          ))}
      </ul>

      {loading && (
        <div className='w-full my-4 text-center mt-9 text-cyan-700'>LOADING ...</div>
      )}

      {!showMore && data?.length > 0 && (
        <button
          onClick={showMoreData}
          className='bg-gray-600 mb-10 text-gray-50 px-3 py-2 rounded-md'
        >
          Show More
        </button>
      )}
    </div>
  );
}
Node.js
About this documentation
Usage and example
Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Corepack
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib
Code repository and issue tracker
Node.js v22.4.1  Table of contents  Index  Other versions  Options
Table of contents
Path
Windows vs. POSIX
path.basename(path[, suffix])
path.delimiter
path.dirname(path)
path.extname(path)
path.format(pathObject)
path.isAbsolute(path)
path.join([...paths])
path.normalize(path)
path.parse(path)
path.posix
path.relative(from, to)
path.resolve([...paths])
path.sep
path.toNamespacedPath(path)
path.win32
Path#
Stability: 2 - Stable
Source Code: lib/path.js

The node:path module provides utilities for working with file and directory paths. It can be accessed using:

const path = require('node:path'); COPY
Windows vs. POSIX#
The default operation of the node:path module varies based on the operating system on which a Node.js application is running. Specifically, when running on a Windows operating system, the node:path module will assume that Windows-style paths are being used.

So using path.basename() might yield different results on POSIX and Windows:

On POSIX:

path.basename('C:\\temp\\myfile.html');
// Returns: 'C:\\temp\\myfile.html' COPY
On Windows:

path.basename('C:\\temp\\myfile.html');
// Returns: 'myfile.html' COPY
To achieve consistent results when working with Windows file paths on any operating system, use path.win32:

On POSIX and Windows:

path.win32.basename('C:\\temp\\myfile.html');
// Returns: 'myfile.html' COPY
To achieve consistent results when working with POSIX file paths on any operating system, use path.posix:

On POSIX and Windows:

path.posix.basename('/tmp/myfile.html');
// Returns: 'myfile.html' COPY
On Windows Node.js follows the concept of per-drive working directory. This behavior can be observed when using a drive path without a backslash. For example, path.resolve('C:\\') can potentially return a different result than path.resolve('C:'). For more information, see this MSDN page.

path.basename(path[, suffix])#
History
path <string>
suffix <string> An optional suffix to remove
Returns: <string>
The path.basename() method returns the last portion of a path, similar to the Unix basename command. Trailing directory separators are ignored.

path.basename('/foo/bar/baz/asdf/quux.html');
// Returns: 'quux.html'

path.basename('/foo/bar/baz/asdf/quux.html', '.html');
// Returns: 'quux' COPY
Although Windows usually treats file names, including file extensions, in a case-insensitive manner, this function does not. For example, C:\\foo.html and C:\\foo.HTML refer to the same file, but basename treats the extension as a case-sensitive string:

path.win32.basename('C:\\foo.html', '.html');
// Returns: 'foo'

path.win32.basename('C:\\foo.HTML', '.html');
// Returns: 'foo.HTML' COPY
A TypeError is thrown if path is not a string or if suffix is given and is not a string.

path.delimiter#
Added in: v0.9.3
<string>
Provides the platform-specific path delimiter:

; for Windows
: for POSIX
For example, on POSIX:

console.log(process.env.PATH);
// Prints: '/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin'

process.env.PATH.split(path.delimiter);
// Returns: ['/usr/bin', '/bin', '/usr/sbin', '/sbin', '/usr/local/bin'] COPY
On Windows:

console.log(process.env.PATH);
// Prints: 'C:\Windows\system32;C:\Windows;C:\Program Files\node\'

process.env.PATH.split(path.delimiter);
// Returns ['C:\\Windows\\system32', 'C:\\Windows', 'C:\\Program Files\\node\\'] COPY
path.dirname(path)#
History
path <string>
Returns: <string>
The path.dirname() method returns the directory name of a path, similar to the Unix dirname command. Trailing directory separators are ignored, see path.sep.

path.dirname('/foo/bar/baz/asdf/quux');
// Returns: '/foo/bar/baz/asdf' COPY
A TypeError is thrown if path is not a string.

path.extname(path)#
History
path <string>
Returns: <string>
The path.extname() method returns the extension of the path, from the last occurrence of the . (period) character to end of string in the last portion of the path. If there is no . in the last portion of the path, or if there are no . characters other than the first character of the basename of path (see path.basename()) , an empty string is returned.

path.extname('index.html');
// Returns: '.html'

path.extname('index.coffee.md');
// Returns: '.md'

path.extname('index.');
// Returns: '.'

path.extname('index');
// Returns: ''

path.extname('.index');
// Returns: ''

path.extname('.index.md');
// Returns: '.md' COPY
A TypeError is thrown if path is not a string.

path.format(pathObject)#
History
pathObject <Object> Any JavaScript object having the following properties:
dir <string>
root <string>
base <string>
name <string>
ext <string>
Returns: <string>
The path.format() method returns a path string from an object. This is the opposite of path.parse().

When providing properties to the pathObject remember that there are combinations where one property has priority over another:

pathObject.root is ignored if pathObject.dir is provided
pathObject.ext and pathObject.name are ignored if pathObject.base exists
For example, on POSIX:

// If `dir`, `root` and `base` are provided,
// `${dir}${path.sep}${base}`
// will be returned. `root` is ignored.
path.format({
  root: '/ignored',
  dir: '/home/user/dir',
  base: 'file.txt',
});
// Returns: '/home/user/dir/file.txt'

// `root` will be used if `dir` is not specified.
// If only `root` is provided or `dir` is equal to `root` then the
// platform separator will not be included. `ext` will be ignored.
path.format({
  root: '/',
  base: 'file.txt',
  ext: 'ignored',
});
// Returns: '/file.txt'

// `name` + `ext` will be used if `base` is not specified.
path.format({
  root: '/',
  name: 'file',
  ext: '.txt',
});
// Returns: '/file.txt'

// The dot will be added if it is not specified in `ext`.
path.format({
  root: '/',
  name: 'file',
  ext: 'txt',
});
// Returns: '/file.txt' COPY
On Windows:

path.format({
  dir: 'C:\\path\\dir',
  base: 'file.txt',
});
// Returns: 'C:\\path\\dir\\file.txt' COPY
path.isAbsolute(path)#
Added in: v0.11.2
path <string>
Returns: <boolean>
The path.isAbsolute() method determines if path is an absolute path.

If the given path is a zero-length string, false will be returned.

For example, on POSIX:

path.isAbsolute('/foo/bar'); // true
path.isAbsolute('/baz/..');  // true
path.isAbsolute('qux/');     // false
path.isAbsolute('.');        // false COPY
On Windows:

path.isAbsolute('//server');    // true
path.isAbsolute('\\\\server');  // true
path.isAbsolute('C:/foo/..');   // true
path.isAbsolute('C:\\foo\\..'); // true
path.isAbsolute('bar\\baz');    // false
path.isAbsolute('bar/baz');     // false
path.isAbsolute('.');           // false COPY
A TypeError is thrown if path is not a string.

path.join([...paths])#
Added in: v0.1.16
...paths <string> A sequence of path segments
Returns: <string>
The path.join() method joins all given path segments together using the platform-specific separator as a delimiter, then normalizes the resulting path.

Zero-length path segments are ignored. If the joined path string is a zero-length string then '.' will be returned, representing the current working directory.

path.join('/foo', 'bar', 'baz/asdf', 'quux', '..');
// Returns: '/foo/bar/baz/asdf'

path.join('foo', {}, 'bar');
// Throws 'TypeError: Path must be a string. Received {}' COPY
A TypeError is thrown if any of the path segments is not a string.

path.normalize(path)#
Added in: v0.1.23
path <string>
Returns: <string>
The path.normalize() method normalizes the given path, resolving '..' and '.' segments.

When multiple, sequential path segment separation characters are found (e.g. / on POSIX and either \ or / on Windows), they are replaced by a single instance of the platform-specific path segment separator (/ on POSIX and \ on Windows). Trailing separators are preserved.

If the path is a zero-length string, '.' is returned, representing the current working directory.

On POSIX, the types of normalization applied by this function do not strictly adhere to the POSIX specification. For example, this function will replace two leading forward slashes with a single slash as if it was a regular absolute path, whereas a few POSIX systems assign special meaning to paths beginning with exactly two forward slashes. Similarly, other substitutions performed by this function, such as removing .. segments, may change how the underlying system resolves the path.

For example, on POSIX:

path.normalize('/foo/bar//baz/asdf/quux/..');
// Returns: '/foo/bar/baz/asdf' COPY
On Windows:

path.normalize('C:\\temp\\\\foo\\bar\\..\\');
// Returns: 'C:\\temp\\foo\\' COPY
Since Windows recognizes multiple path separators, both separators will be replaced by instances of the Windows preferred separator (\):

path.win32.normalize('C:////temp\\\\/\\/\\/foo/bar');
// Returns: 'C:\\temp\\foo\\bar' COPY
A TypeError is thrown if path is not a string.

path.parse(path)#
Added in: v0.11.15
path <string>
Returns: <Object>
The path.parse() method returns an object whose properties represent significant elements of the path. Trailing directory separators are ignored, see path.sep.

The returned object will have the following properties:

dir <string>
root <string>
base <string>
name <string>
ext <string>
For example, on POSIX:

path.parse('/home/user/dir/file.txt');
// Returns:
// { root: '/',
//   dir: '/home/user/dir',
//   base: 'file.txt',
//   ext: '.txt',
//   name: 'file' } COPY
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          dir        â”‚    base    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¬              â”œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¤
â”‚ root â”‚              â”‚ name â”‚ ext â”‚
"  /    home/user/dir / file  .txt "
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
(All spaces in the "" line should be ignored. They are purely for formatting.) COPY
On Windows:

path.parse('C:\\path\\dir\\file.txt');
// Returns:
// { root: 'C:\\',
//   dir: 'C:\\path\\dir',
//   base: 'file.txt',
//   ext: '.txt',
//   name: 'file' } COPY
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          dir        â”‚    base    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¬              â”œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¤
â”‚ root â”‚              â”‚ name â”‚ ext â”‚
" C:\      path\dir   \ file  .txt "
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
(All spaces in the "" line should be ignored. They are purely for formatting.) COPY
A TypeError is thrown if path is not a string.

path.posix#
History
<Object>
The path.posix property provides access to POSIX specific implementations of the path methods.

The API is accessible via require('node:path').posix or require('node:path/posix').

path.relative(from, to)#
History
from <string>
to <string>
Returns: <string>
The path.relative() method returns the relative path from from to to based on the current working directory. If from and to each resolve to the same path (after calling path.resolve() on each), a zero-length string is returned.

If a zero-length string is passed as from or to, the current working directory will be used instead of the zero-length strings.

For example, on POSIX:

path.relative('/data/orandea/test/aaa', '/data/orandea/impl/bbb');
// Returns: '../../impl/bbb' COPY
On Windows:

path.relative('C:\\orandea\\test\\aaa', 'C:\\orandea\\impl\\bbb');
// Returns: '..\\..\\impl\\bbb' COPY
A TypeError is thrown if either from or to is not a string.

path.resolve([...paths])#
Added in: v0.3.4
...paths <string> A sequence of paths or path segments
Returns: <string>
The path.resolve() method resolves a sequence of paths or path segments into an absolute path.

The given sequence of paths is processed from right to left, with each subsequent path prepended until an absolute path is constructed. For instance, given the sequence of path segments: /foo, /bar, baz, calling path.resolve('/foo', '/bar', 'baz') would return /bar/baz because 'baz' is not an absolute path but '/bar' + '/' + 'baz' is.

If, after processing all given path segments, an absolute path has not yet been generated, the current working directory is used.

The resulting path is normalized and trailing slashes are removed unless the path is resolved to the root directory.

Zero-length path segments are ignored.

If no path segments are passed, path.resolve() will return the absolute path of the current working directory.

path.resolve('/foo/bar', './baz');
// Returns: '/foo/bar/baz'

path.resolve('/foo/bar', '/tmp/file/');
// Returns: '/tmp/file'

path.resolve('wwwroot', 'static_files/png/', '../gif/image.gif');
// If the current working directory is /home/myself/node,
// this returns '/home/myself/node/wwwroot/static_files/gif/image.gif' COPY
A TypeError is thrown if any of the arguments is not a string.

path.sep#
Added in: v0.7.9
<string>
Provides the platform-specific path segment separator:

\ on Windows
/ on POSIX
For example, on POSIX:

'foo/bar/baz'.split(path.sep);
// Returns: ['foo', 'bar', 'baz'] COPY
On Windows:

'foo\\bar\\baz'.split(path.sep);
// Returns: ['foo', 'bar', 'baz'] COPY
On Windows, both the forward slash (/) and backward slash (\) are accepted as path segment separators; however, the path methods only add backward slashes (\).

path.toNamespacedPath(path)#
Added in: v9.0.0
path <string>
Returns: <string>
On Windows systems only, returns an equivalent namespace-prefixed path for the given path. If path is not a string, path will be returned without modifications.

This method is meaningful only on Windows systems. On POSIX systems, the method is non-operational and always returns path without modifications.

path.win32#
History
<Object>
The path.win32 property provides access to Windows-specific implementations of the path methods.

The API is accessible via require('node:path').win32 or require('node:path/win32').

Node.js
About this documentation
Usage and example
Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Corepack
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib
Code repository and issue tracker
Node.js v22.4.1  Table of contents  Index  Other versions  Options
Table of contents
Cluster
How it works
Class: Worker
Event: 'disconnect'
Event: 'error'
Event: 'exit'
Event: 'listening'
Event: 'message'
Event: 'online'
worker.disconnect()
worker.exitedAfterDisconnect
worker.id
worker.isConnected()
worker.isDead()
worker.kill([signal])
worker.process
worker.send(message[, sendHandle[, options]][, callback])
Event: 'disconnect'
Event: 'exit'
Event: 'fork'
Event: 'listening'
Event: 'message'
Event: 'online'
Event: 'setup'
cluster.disconnect([callback])
cluster.fork([env])
cluster.isMaster
cluster.isPrimary
cluster.isWorker
cluster.schedulingPolicy
cluster.settings
cluster.setupMaster([settings])
cluster.setupPrimary([settings])
cluster.worker
cluster.workers
Cluster#
Stability: 2 - Stable
Source Code: lib/cluster.js

Clusters of Node.js processes can be used to run multiple instances of Node.js that can distribute workloads among their application threads. When process isolation is not needed, use the worker_threads module instead, which allows running multiple application threads within a single Node.js instance.

The cluster module allows easy creation of child processes that all share server ports.

const cluster = require('node:cluster');
const http = require('node:http');
const numCPUs = require('node:os').availableParallelism();
const process = require('node:process');

if (cluster.isPrimary) {
  console.log(`Primary ${process.pid} is running`);

  // Fork workers.
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on('exit', (worker, code, signal) => {
    console.log(`worker ${worker.process.pid} died`);
  });
} else {
  // Workers can share any TCP connection
  // In this case it is an HTTP server
  http.createServer((req, res) => {
    res.writeHead(200);
    res.end('hello world\n');
  }).listen(8000);

  console.log(`Worker ${process.pid} started`);
}COPY
Running Node.js will now share port 8000 between the workers:

$ node server.js
Primary 3596 is running
Worker 4324 started
Worker 4520 started
Worker 6056 started
Worker 5644 started COPY
On Windows, it is not yet possible to set up a named pipe server in a worker.

How it works#
The worker processes are spawned using the child_process.fork() method, so that they can communicate with the parent via IPC and pass server handles back and forth.

The cluster module supports two methods of distributing incoming connections.

The first one (and the default one on all platforms except Windows) is the round-robin approach, where the primary process listens on a port, accepts new connections and distributes them across the workers in a round-robin fashion, with some built-in smarts to avoid overloading a worker process.

The second approach is where the primary process creates the listen socket and sends it to interested workers. The workers then accept incoming connections directly.

The second approach should, in theory, give the best performance. In practice however, distribution tends to be very unbalanced due to operating system scheduler vagaries. Loads have been observed where over 70% of all connections ended up in just two processes, out of a total of eight.

Because server.listen() hands off most of the work to the primary process, there are three cases where the behavior between a normal Node.js process and a cluster worker differs:

server.listen({fd: 7}) Because the message is passed to the primary, file descriptor 7 in the parent will be listened on, and the handle passed to the worker, rather than listening to the worker's idea of what the number 7 file descriptor references.
server.listen(handle) Listening on handles explicitly will cause the worker to use the supplied handle, rather than talk to the primary process.
server.listen(0) Normally, this will cause servers to listen on a random port. However, in a cluster, each worker will receive the same "random" port each time they do listen(0). In essence, the port is random the first time, but predictable thereafter. To listen on a unique port, generate a port number based on the cluster worker ID.
Node.js does not provide routing logic. It is therefore important to design an application such that it does not rely too heavily on in-memory data objects for things like sessions and login.

Because workers are all separate processes, they can be killed or re-spawned depending on a program's needs, without affecting other workers. As long as there are some workers still alive, the server will continue to accept connections. If no workers are alive, existing connections will be dropped and new connections will be refused. Node.js does not automatically manage the number of workers, however. It is the application's responsibility to manage the worker pool based on its own needs.

Although a primary use case for the node:cluster module is networking, it can also be used for other use cases requiring worker processes.

Class: Worker#
Added in: v0.7.0
Extends: <EventEmitter>
A Worker object contains all public information and method about a worker. In the primary it can be obtained using cluster.workers. In a worker it can be obtained using cluster.worker.

Event: 'disconnect'#
Added in: v0.7.7
Similar to the cluster.on('disconnect') event, but specific to this worker.

cluster.fork().on('disconnect', () => {
  // Worker has disconnected
}); COPY
Event: 'error'#
Added in: v0.7.3
This event is the same as the one provided by child_process.fork().

Within a worker, process.on('error') may also be used.

Event: 'exit'#
Added in: v0.11.2
code <number> The exit code, if it exited normally.
signal <string> The name of the signal (e.g. 'SIGHUP') that caused the process to be killed.
Similar to the cluster.on('exit') event, but specific to this worker.

const cluster = require('node:cluster');

if (cluster.isPrimary) {
  const worker = cluster.fork();
  worker.on('exit', (code, signal) => {
    if (signal) {
      console.log(`worker was killed by signal: ${signal}`);
    } else if (code !== 0) {
      console.log(`worker exited with error code: ${code}`);
    } else {
      console.log('worker success!');
    }
  });
}COPY
Event: 'listening'#
Added in: v0.7.0
address <Object>
Similar to the cluster.on('listening') event, but specific to this worker.

cluster.fork().on('listening', (address) => {
  // Worker is listening
});COPY
It is not emitted in the worker.

Event: 'message'#
Added in: v0.7.0
message <Object>
handle <undefined> | <Object>
Similar to the 'message' event of cluster, but specific to this worker.

Within a worker, process.on('message') may also be used.

See process event: 'message'.

Here is an example using the message system. It keeps a count in the primary process of the number of HTTP requests received by the workers:

const cluster = require('node:cluster');
const http = require('node:http');
const process = require('node:process');

if (cluster.isPrimary) {

  // Keep track of http requests
  let numReqs = 0;
  setInterval(() => {
    console.log(`numReqs = ${numReqs}`);
  }, 1000);

  // Count requests
  function messageHandler(msg) {
    if (msg.cmd && msg.cmd === 'notifyRequest') {
      numReqs += 1;
    }
  }

  // Start workers and listen for messages containing notifyRequest
  const numCPUs = require('node:os').availableParallelism();
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  for (const id in cluster.workers) {
    cluster.workers[id].on('message', messageHandler);
  }

} else {

  // Worker processes have a http server.
  http.Server((req, res) => {
    res.writeHead(200);
    res.end('hello world\n');

    // Notify primary about the request
    process.send({ cmd: 'notifyRequest' });
  }).listen(8000);
}COPY
Event: 'online'#
Added in: v0.7.0
Similar to the cluster.on('online') event, but specific to this worker.

cluster.fork().on('online', () => {
  // Worker is online
}); COPY
It is not emitted in the worker.

worker.disconnect()#
History
Returns: <cluster.Worker> A reference to worker.
In a worker, this function will close all servers, wait for the 'close' event on those servers, and then disconnect the IPC channel.

In the primary, an internal message is sent to the worker causing it to call .disconnect() on itself.

Causes .exitedAfterDisconnect to be set.

After a server is closed, it will no longer accept new connections, but connections may be accepted by any other listening worker. Existing connections will be allowed to close as usual. When no more connections exist, see server.close(), the IPC channel to the worker will close allowing it to die gracefully.

The above applies only to server connections, client connections are not automatically closed by workers, and disconnect does not wait for them to close before exiting.

In a worker, process.disconnect exists, but it is not this function; it is disconnect().

Because long living server connections may block workers from disconnecting, it may be useful to send a message, so application specific actions may be taken to close them. It also may be useful to implement a timeout, killing a worker if the 'disconnect' event has not been emitted after some time.

if (cluster.isPrimary) {
  const worker = cluster.fork();
  let timeout;

  worker.on('listening', (address) => {
    worker.send('shutdown');
    worker.disconnect();
    timeout = setTimeout(() => {
      worker.kill();
    }, 2000);
  });

  worker.on('disconnect', () => {
    clearTimeout(timeout);
  });

} else if (cluster.isWorker) {
  const net = require('node:net');
  const server = net.createServer((socket) => {
    // Connections never end
  });

  server.listen(8000);

  process.on('message', (msg) => {
    if (msg === 'shutdown') {
      // Initiate graceful close of any connections to server
    }
  });
} COPY
worker.exitedAfterDisconnect#
Added in: v6.0.0
<boolean>
This property is true if the worker exited due to .disconnect(). If the worker exited any other way, it is false. If the worker has not exited, it is undefined.

The boolean worker.exitedAfterDisconnect allows distinguishing between voluntary and accidental exit, the primary may choose not to respawn a worker based on this value.

cluster.on('exit', (worker, code, signal) => {
  if (worker.exitedAfterDisconnect === true) {
    console.log('Oh, it was just voluntary â€“ no need to worry');
  }
});

// kill worker
worker.kill(); COPY
worker.id#
Added in: v0.8.0
<integer>
Each new worker is given its own unique id, this id is stored in the id.

While a worker is alive, this is the key that indexes it in cluster.workers.

worker.isConnected()#
Added in: v0.11.14
This function returns true if the worker is connected to its primary via its IPC channel, false otherwise. A worker is connected to its primary after it has been created. It is disconnected after the 'disconnect' event is emitted.

worker.isDead()#
Added in: v0.11.14
This function returns true if the worker's process has terminated (either because of exiting or being signaled). Otherwise, it returns false.

const cluster = require('node:cluster');
const http = require('node:http');
const numCPUs = require('node:os').availableParallelism();
const process = require('node:process');

if (cluster.isPrimary) {
  console.log(`Primary ${process.pid} is running`);

  // Fork workers.
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on('fork', (worker) => {
    console.log('worker is dead:', worker.isDead());
  });

  cluster.on('exit', (worker, code, signal) => {
    console.log('worker is dead:', worker.isDead());
  });
} else {
  // Workers can share any TCP connection. In this case, it is an HTTP server.
  http.createServer((req, res) => {
    res.writeHead(200);
    res.end(`Current process\n ${process.pid}`);
    process.kill(process.pid);
  }).listen(8000);
}COPY
worker.kill([signal])#
Added in: v0.9.12
signal <string> Name of the kill signal to send to the worker process. Default: 'SIGTERM'
This function will kill the worker. In the primary worker, it does this by disconnecting the worker.process, and once disconnected, killing with signal. In the worker, it does it by killing the process with signal.

The kill() function kills the worker process without waiting for a graceful disconnect, it has the same behavior as worker.process.kill().

This method is aliased as worker.destroy() for backwards compatibility.

In a worker, process.kill() exists, but it is not this function; it is kill().

worker.process#
Added in: v0.7.0
<ChildProcess>
All workers are created using child_process.fork(), the returned object from this function is stored as .process. In a worker, the global process is stored.

See: Child Process module.

Workers will call process.exit(0) if the 'disconnect' event occurs on process and .exitedAfterDisconnect is not true. This protects against accidental disconnection.

worker.send(message[, sendHandle[, options]][, callback])#
History
message <Object>
sendHandle <Handle>
options <Object> The options argument, if present, is an object used to parameterize the sending of certain types of handles. options supports the following properties:
keepOpen <boolean> A value that can be used when passing instances of net.Socket. When true, the socket is kept open in the sending process. Default: false.
callback <Function>
Returns: <boolean>
Send a message to a worker or primary, optionally with a handle.

In the primary, this sends a message to a specific worker. It is identical to ChildProcess.send().

In a worker, this sends a message to the primary. It is identical to process.send().

This example will echo back all messages from the primary:

if (cluster.isPrimary) {
  const worker = cluster.fork();
  worker.send('hi there');

} else if (cluster.isWorker) {
  process.on('message', (msg) => {
    process.send(msg);
  });
} COPY
Event: 'disconnect'#
Added in: v0.7.9
worker <cluster.Worker>
Emitted after the worker IPC channel has disconnected. This can occur when a worker exits gracefully, is killed, or is disconnected manually (such as with worker.disconnect()).

There may be a delay between the 'disconnect' and 'exit' events. These events can be used to detect if the process is stuck in a cleanup or if there are long-living connections.

cluster.on('disconnect', (worker) => {
  console.log(`The worker #${worker.id} has disconnected`);
}); COPY
Event: 'exit'#
Added in: v0.7.9
worker <cluster.Worker>
code <number> The exit code, if it exited normally.
signal <string> The name of the signal (e.g. 'SIGHUP') that caused the process to be killed.
When any of the workers die the cluster module will emit the 'exit' event.

This can be used to restart the worker by calling .fork() again.

cluster.on('exit', (worker, code, signal) => {
  console.log('worker %d died (%s). restarting...',
              worker.process.pid, signal || code);
  cluster.fork();
}); COPY
See child_process event: 'exit'.

Event: 'fork'#
Added in: v0.7.0
worker <cluster.Worker>
When a new worker is forked the cluster module will emit a 'fork' event. This can be used to log worker activity, and create a custom timeout.

const timeouts = [];
function errorMsg() {
  console.error('Something must be wrong with the connection ...');
}

cluster.on('fork', (worker) => {
  timeouts[worker.id] = setTimeout(errorMsg, 2000);
});
cluster.on('listening', (worker, address) => {
  clearTimeout(timeouts[worker.id]);
});
cluster.on('exit', (worker, code, signal) => {
  clearTimeout(timeouts[worker.id]);
  errorMsg();
}); COPY
Event: 'listening'#
Added in: v0.7.0
worker <cluster.Worker>
address <Object>
After calling listen() from a worker, when the 'listening' event is emitted on the server, a 'listening' event will also be emitted on cluster in the primary.

The event handler is executed with two arguments, the worker contains the worker object and the address object contains the following connection properties: address, port, and addressType. This is very useful if the worker is listening on more than one address.

cluster.on('listening', (worker, address) => {
  console.log(
    `A worker is now connected to ${address.address}:${address.port}`);
}); COPY
The addressType is one of:

4 (TCPv4)
6 (TCPv6)
-1 (Unix domain socket)
'udp4' or 'udp6' (UDPv4 or UDPv6)
Event: 'message'#
History
worker <cluster.Worker>
message <Object>
handle <undefined> | <Object>
Emitted when the cluster primary receives a message from any worker.

See child_process event: 'message'.

Event: 'online'#
Added in: v0.7.0
worker <cluster.Worker>
After forking a new worker, the worker should respond with an online message. When the primary receives an online message it will emit this event. The difference between 'fork' and 'online' is that fork is emitted when the primary forks a worker, and 'online' is emitted when the worker is running.

cluster.on('online', (worker) => {
  console.log('Yay, the worker responded after it was forked');
}); COPY
Event: 'setup'#
Added in: v0.7.1
settings <Object>
Emitted every time .setupPrimary() is called.

The settings object is the cluster.settings object at the time .setupPrimary() was called and is advisory only, since multiple calls to .setupPrimary() can be made in a single tick.

If accuracy is important, use cluster.settings.

cluster.disconnect([callback])#
Added in: v0.7.7
callback <Function> Called when all workers are disconnected and handles are closed.
Calls .disconnect() on each worker in cluster.workers.

When they are disconnected all internal handles will be closed, allowing the primary process to die gracefully if no other event is waiting.

The method takes an optional callback argument which will be called when finished.

This can only be called from the primary process.

cluster.fork([env])#
Added in: v0.6.0
env <Object> Key/value pairs to add to worker process environment.
Returns: <cluster.Worker>
Spawn a new worker process.

This can only be called from the primary process.

cluster.isMaster#
Added in: v0.8.1Deprecated since: v16.0.0
Stability: 0 - Deprecated
Deprecated alias for cluster.isPrimary.

cluster.isPrimary#
Added in: v16.0.0
<boolean>
True if the process is a primary. This is determined by the process.env.NODE_UNIQUE_ID. If process.env.NODE_UNIQUE_ID is undefined, then isPrimary is true.

cluster.isWorker#
Added in: v0.6.0
<boolean>
True if the process is not a primary (it is the negation of cluster.isPrimary).

cluster.schedulingPolicy#
Added in: v0.11.2
The scheduling policy, either cluster.SCHED_RR for round-robin or cluster.SCHED_NONE to leave it to the operating system. This is a global setting and effectively frozen once either the first worker is spawned, or .setupPrimary() is called, whichever comes first.

SCHED_RR is the default on all operating systems except Windows. Windows will change to SCHED_RR once libuv is able to effectively distribute IOCP handles without incurring a large performance hit.

cluster.schedulingPolicy can also be set through the NODE_CLUSTER_SCHED_POLICY environment variable. Valid values are 'rr' and 'none'.

cluster.settings#
History
<Object>
execArgv <string[]> List of string arguments passed to the Node.js executable. Default: process.execArgv.
exec <string> File path to worker file. Default: process.argv[1].
args <string[]> String arguments passed to worker. Default: process.argv.slice(2).
cwd <string> Current working directory of the worker process. Default: undefined (inherits from parent process).
serialization <string> Specify the kind of serialization used for sending messages between processes. Possible values are 'json' and 'advanced'. See Advanced serialization for child_process for more details. Default: false.
silent <boolean> Whether or not to send output to parent's stdio. Default: false.
stdio <Array> Configures the stdio of forked processes. Because the cluster module relies on IPC to function, this configuration must contain an 'ipc' entry. When this option is provided, it overrides silent. See child_process.spawn()'s stdio.
uid <number> Sets the user identity of the process. (See setuid(2).)
gid <number> Sets the group identity of the process. (See setgid(2).)
inspectPort <number> | <Function> Sets inspector port of worker. This can be a number, or a function that takes no arguments and returns a number. By default each worker gets its own port, incremented from the primary's process.debugPort.
windowsHide <boolean> Hide the forked processes console window that would normally be created on Windows systems. Default: false.
After calling .setupPrimary() (or .fork()) this settings object will contain the settings, including the default values.

This object is not intended to be changed or set manually.

cluster.setupMaster([settings])#
History
Stability: 0 - Deprecated
Deprecated alias for .setupPrimary().

cluster.setupPrimary([settings])#
Added in: v16.0.0
settings <Object> See cluster.settings.
setupPrimary is used to change the default 'fork' behavior. Once called, the settings will be present in cluster.settings.

Any settings changes only affect future calls to .fork() and have no effect on workers that are already running.

The only attribute of a worker that cannot be set via .setupPrimary() is the env passed to .fork().

The defaults above apply to the first call only; the defaults for later calls are the current values at the time of cluster.setupPrimary() is called.

const cluster = require('node:cluster');

cluster.setupPrimary({
  exec: 'worker.js',
  args: ['--use', 'https'],
  silent: true,
});
cluster.fork(); // https worker
cluster.setupPrimary({
  exec: 'worker.js',
  args: ['--use', 'http'],
});
cluster.fork(); // http workerCOPY
This can only be called from the primary process.

cluster.worker#
Added in: v0.7.0
<Object>
A reference to the current worker object. Not available in the primary process.

const cluster = require('node:cluster');

if (cluster.isPrimary) {
  console.log('I am primary');
  cluster.fork();
  cluster.fork();
} else if (cluster.isWorker) {
  console.log(`I am worker #${cluster.worker.id}`);
}COPY
cluster.workers#
Added in: v0.7.0
<Object>
A hash that stores the active worker objects, keyed by id field. This makes it easy to loop through all the workers. It is only available in the primary process.

A worker is removed from cluster.workers after the worker has disconnected and exited. The order between these two events cannot be determined in advance. However, it is guaranteed that the removal from the cluster.workers list happens before the last 'disconnect' or 'exit' event is emitted.

const cluster = require('node:cluster');

for (const worker of Object.values(cluster.workers)) {
  worker.send('big announcement to all workers');
}COPY